{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'ABI_LGBM_LIME.ipynb', 'ABI_LGB_binary_classification.ipynb', 'ABI_RF_LIME.ipynb', 'ABI_RF_SHAP.ipynb', 'ABI_XGB_LIME.ipynb', 'ABI_XGB_SHAP.ipynb', 'agaricus-lepiota.data', 'airlines.csv', 'airports.csv', 'example lightgbm.ipynb', 'flights.csv', 'flights_sample.csv', 'gbm_trials.csv', 'hyperparameter-optimization-master', 'MODEL INTERPRETER.ipynb', 'MODEL_SELECTION_TUNING.ipynb', 'MODEL_SELECTION_TUNING_TEST.ipynb', 'testing_ad.csv', 'testing_ad_labels.csv', 'training_ad.csv']\n"
     ]
    }
   ],
   "source": [
    "## importing the relevant packages:\n",
    "\n",
    "# clear the workspace\n",
    "%reset -f\n",
    "\n",
    "# print list of files in directory\n",
    "import os\n",
    "print(os.listdir())\n",
    "\n",
    "# print/display all plots inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# the base packages\n",
    "import collections # for the Counter function\n",
    "import csv # for reading/writing csv files\n",
    "import pandas as pd, numpy as np, time, gc, bisect\n",
    "\n",
    "# the various packages/modules used across processing (sklearn), modelling (lightgbm) and bayesian optimization (hyperopt, bayes_opt)\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.cross_validation import cross_val_score, StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.base import TransformerMixin\n",
    "from bayes_opt import BayesianOptimization\n",
    "from tqdm import tqdm\n",
    "from hyperopt import hp, tpe, STATUS_OK, fmin, Trials\n",
    "from hyperopt.fmin import fmin\n",
    "#from hyperopt.pyll.stochastic import sample\n",
    "\n",
    "# modelling algorithms\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Evaluation of the model\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "# Exporting packages for SHAP/LIME\n",
    "import shap\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "\n",
    "# define the global variables used later\n",
    "MAX_EVALS = 20 # number of iterations/parameter sets created towards tuning\n",
    "N_FOLDS = 5 # number of cv folds\n",
    "randomseed = 1 # the value for the random state used at various points in the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### MAIN CLASSES ####\n",
    "class DataFrameImputer(TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Impute missing values.\n",
    "\n",
    "        Columns of dtype object are imputed with the most frequent value \n",
    "        in column.\n",
    "\n",
    "        Columns of other types are imputed with mean of column.\n",
    "        \"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "        self.fill = pd.Series([X[c].value_counts().index[0] if X[c].dtype == np.dtype('O') else X[c].mean() for c in X], \n",
    "                              index=X.columns)\n",
    "#         self.fill = pd.Series(['No Data' if X[c].dtype == np.dtype('O') else X[c].mean() for c in X],\n",
    "#             index=X.columns)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.fill)\n",
    "    \n",
    "    def num_missing(self):\n",
    "        return sum(self.isnull())\n",
    "    \n",
    "    def imputer_mean(self, column):\n",
    "        x = Imputer(missing_values = 'NaN', strategy = 'mean', axis = 0)\n",
    "        return x.fit_transform(self[[column]]).ravel()\n",
    "    \n",
    "    def imputer_median(self, column):\n",
    "        x = Imputer(missing_values = 'NaN', strategy = 'median', axis = 0)\n",
    "        return x.fit_transform(self[[column]]).ravel()\n",
    "    \n",
    "    def imputer_mode(self, column):\n",
    "        x = Imputer(missing_values = 'NaN', strategy = 'most_frequent', axis = 0)\n",
    "        return x.fit_transform(self[[column]]).ravel()\n",
    "\n",
    "class prepare_data():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\" To prepare data,\n",
    "                1. read in data\n",
    "                2. pre-processing/cleaning\n",
    "                3. creating helper objects for later steps\n",
    "                4. processing for modelling\n",
    "        \"\"\"\n",
    "    \n",
    "    def labelEncoder(train_df, test_df, cat_columns):\n",
    "        categorical_names = {}\n",
    "        for feature in tqdm(cat_columns):\n",
    "            le = preprocessing.LabelEncoder()\n",
    "            le.fit(train_df[feature].astype(str))\n",
    "            train_df[feature] = le.transform(train_df[feature].astype(str))\n",
    "            test_df[feature] = test_df[feature].map(lambda i: 'No Data' if i not in le.classes_ else i)\n",
    "            le_classes = le.classes_.tolist()\n",
    "            bisect.insort_left(le_classes, 'No Data')\n",
    "            le.classes_ = le_classes\n",
    "            test_df[feature] = le.transform(test_df[feature].astype(str))\n",
    "            categorical_names[feature] = le.classes_\n",
    "        return train_df, test_df, categorical_names\n",
    "    \n",
    "    ## function to get frequency count of elements in a vector/list\n",
    "    def freq_count(input_vector):\n",
    "        return collections.Counter(input_vector)\n",
    "    \n",
    "    def categ_feats(train_df, test_df):\n",
    "        x = list(train_df.dtypes)\n",
    "        x_1 = [1 if x == 'O' else 0 for x in x]\n",
    "        categorical_idx = [i for i, x in enumerate(x_1) if x == 1]\n",
    "\n",
    "        # Get feature names and their values for categorical data (needed for LIME)\n",
    "        cat_columns = train_df.select_dtypes(include=['object']).columns.values\n",
    "        train, test, categorical_names = prepare_data.labelEncoder(train_df, test_df, cat_columns)\n",
    "\n",
    "        return train_df, test_df, categorical_names, categorical_idx\n",
    "\n",
    "    def create(input_file_path, input_file_path_2, response, cols_to_remove = ['id'], random_seed = 1234):\n",
    "        train = pd.read_csv(input_file_path, na_values=['No Data', ' '])\n",
    "        test = pd.read_csv(input_file_path_2, na_values=['No Data', ' '])\n",
    "        \n",
    "        train = pd.DataFrame(train)\n",
    "        test = pd.DataFrame(test)\n",
    "        \n",
    "        for col in cols_to_remove:\n",
    "            train.drop([col], axis = 1, inplace = True)\n",
    "        test = pd.DataFrame(data = test[train.columns])\n",
    "        \n",
    "        print(train.shape, '\\n')\n",
    "        train.dropna(thresh=0.6*(train.shape[0]), axis=1, inplace = True)\n",
    "        train.dropna(thresh=0.5*(train.shape[1]), axis=0, inplace = True)\n",
    "        print(train.shape, '\\n')\n",
    "        test = test[train.columns]\n",
    "        \n",
    "        #print(train.apply(DataFrameImputer.num_missing, axis=0), '\\n')\n",
    "        imputer_object = DataFrameImputer()\n",
    "        imputer_object.fit(train)\n",
    "        train = imputer_object.transform(train)\n",
    "        test = imputer_object.transform(test)\n",
    "        \n",
    "        print(prepare_data.freq_count(train[response]), '\\n')\n",
    "\n",
    "        y_train = train[response].values\n",
    "        X_train = train.drop([response], axis = 1)\n",
    "        y_test = test[response].values\n",
    "        X_test = test.drop([response], axis = 1)\n",
    "        \n",
    "        X_train, X_test, categ_names, categ_idx = prepare_data.categ_feats(X_train, X_test)\n",
    "\n",
    "        ##  segment for usage if doing the train/test split ##\n",
    "        #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = random_seed)\n",
    "        #feature_names_train = list(X_train.columns.values)\n",
    "        #num_feature = X_train.shape[1]\n",
    "        #X_train = pd.DataFrame(data=X_train, columns=feature_names_train)\n",
    "        #X_test = pd.DataFrame(data=X_test, columns=feature_names_train)\n",
    "        #return X_train, X_test, y_train, y_test, feature_names_train, categ_names, categ_idx, num_feature\n",
    "        \n",
    "        X_train = pd.DataFrame(data=X_train, columns=X_train.columns.values)\n",
    "        X_test = pd.DataFrame(data=X_test, columns=X_test.columns.values)\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7080, 57) \n",
      "\n",
      "(6778, 42) \n",
      "\n",
      "Counter({0: 5890, 1: 888}) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:01<00:00, 20.67it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = prepare_data.create(input_file_path='training_ad.csv', input_file_path_2='testing_ad.csv',\n",
    "                                            response = 'label',\n",
    "                                cols_to_remove = ['global id', 'ethnicity', 'original hire date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6778, 41)\n",
      "(5788, 41)\n",
      "(6778,)\n",
      "(5788,)\n",
      "Counter({0: 5890, 1: 888})\n",
      "Counter({0: 5624, 1: 164})\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(collections.Counter(y_train))\n",
    "print(collections.Counter(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "\n",
    "# Apply SMOTE + Tomek links\n",
    "# sm = SMOTETomek(random_state=0)\n",
    "feat_names = X_train.columns.values\n",
    "# X_train, y_train = sm.fit_sample(X_train, y_train)\n",
    "# X_train = pd.DataFrame(data=X_train, columns=feat_names)\n",
    "\n",
    "smote_enn = SMOTEENN(random_state=0)\n",
    "X_train, y_train = smote_enn.fit_sample(X_train, y_train)\n",
    "X_train = pd.DataFrame(data=X_train,columns=feat_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "## xgboost class for tuning\n",
    "\n",
    "class xgboost_model():\n",
    "    \n",
    "    def __init__():\n",
    "        \"\"\" this class initializes some functions used in the xgboost pipeline \"\"\"\n",
    "    \n",
    "    def xgb_score(params):\n",
    "        global ITERATION\n",
    "        ITERATION += 1\n",
    "        \n",
    "        randomseed = 1\n",
    "        \n",
    "        #params['max_depth'] = int(float(params['max_depth']))\n",
    "        # Make sure parameters that need to be integers are integers\n",
    "        for parameter_name in ['max_depth']:\n",
    "            params[parameter_name] = int(params[parameter_name])\n",
    "        \n",
    "        clf = xgb.XGBClassifier(n_estimators = 1000,\n",
    "                                base_score = params['base_score'],\n",
    "                                colsample_bytree = params['colsample_bytree'],\n",
    "                               learning_rate = params['learning_rate'],\n",
    "                                max_depth = params['max_depth'],\n",
    "                                min_child_weight = params['min_child_weight'],\n",
    "                                subsample = params['subsample'],\n",
    "                               gamma = params['gamma'],\n",
    "                               reg_lambda = params['reg_lambda'], \n",
    "                                scale_pos_weight = 3, silent = False, seed = randomseed)\n",
    "        X = pd.DataFrame(X_train).values\n",
    "        Xcv = X_test.values\n",
    "        eval_set  = [(X, y_train), (Xcv, y_test)]\n",
    "\n",
    "        clf.fit(X, y_train,\n",
    "                eval_set = eval_set, eval_metric = 'auc',\n",
    "                early_stopping_rounds = 20, verbose = False)\n",
    "        num_rounds = clf.best_iteration\n",
    "        bst_score = clf.best_score\n",
    "\n",
    "        pred = clf.predict_proba(Xcv)[:, 1]\n",
    "        predict = np.where(pred > params['base_score'], 1, 0)\n",
    "        auc_score = roc_auc_score(y_test, pred)\n",
    "        recall_score = sklearn.metrics.recall_score(y_pred=predict, y_true=y_test)\n",
    "        #print('recall score is: ', recall_score)\n",
    "        #print('The AUC for iteration ', ITERATION, ' is {:.4f}.'.format(auc_score), '\\n')\n",
    "        \n",
    "        return {'loss': (1 - recall_score), 'status': STATUS_OK, 'params': params, 'num_boost': num_rounds, 'bst_score': bst_score}\n",
    "    \n",
    "    def optimize(X_train, y_train, X_test, y_test):\n",
    "        # Keep track of evals\n",
    "        global ITERATION\n",
    "        ITERATION = 0\n",
    "        \n",
    "        global trials\n",
    "        trials = Trials()\n",
    "        \n",
    "        space = {\n",
    "            'base_score' : hp.quniform('base_score', 0.4, 0.6, 0.01),\n",
    "             'learning_rate' : hp.quniform('learning_rate', 0.001, 0.2, 0.05),\n",
    "             #'max_depth' : hp.choice('max_depth', np.arange(3, 8, dtype=int)),\n",
    "            'max_depth' : hp.quniform('max_depth', 2, 8, 1),\n",
    "             'min_child_weight' : hp.quniform('min_child_weight', 1, 4, 1),\n",
    "             'subsample' : hp.quniform('subsample', 0.4, 0.8, 0.05),\n",
    "             'gamma' : hp.quniform('gamma', 0.25, 1, 0.05),\n",
    "            'reg_lambda' : hp.uniform ('reg_lambda', 0, 1),\n",
    "             'colsample_bytree' : hp.quniform('colsample_bytree', 0.4, 0.8, 0.05)\n",
    "        }\n",
    "        \n",
    "        best = fmin(xgboost_model.xgb_score, space, algo=tpe.suggest, trials=trials, max_evals=MAX_EVALS,\n",
    "                    rstate=np.random.RandomState(randomseed))\n",
    "        best = trials.best_trial['result']['params']\n",
    "        num_rounds = trials.best_trial['result']['num_boost']\n",
    "        \n",
    "        return trials, best, num_rounds\n",
    "    \n",
    "    def xgb_train(best_params, num_rounds):\n",
    "        model = xgb.XGBClassifier(silent = False, seed = randomseed, n_estimators=num_rounds+1)\n",
    "        model.set_params(**best_params)\n",
    "        model.fit(X_train, y_train, eval_metric = \"auc\", verbose = True)\n",
    "        return model\n",
    "    \n",
    "    def xgb_predict(X_test, y_test, model, mode = \"validate\"):\n",
    "        pred = model.predict_proba(X_test)[:, 1]\n",
    "        predict = np.where(pred > 0.45, 1, 0)\n",
    "        \n",
    "        if mode == \"validate\":\n",
    "            recall_score = sklearn.metrics.recall_score(y_pred=predict, y_true=y_test)\n",
    "            print('recall score is: ', recall_score)\n",
    "            auc_score = roc_auc_score(y_test, pred)\n",
    "            print('accuracy score: ', sklearn.metrics.accuracy_score(y_true=y_test, y_pred=predict))\n",
    "            print('The final AUC after taking the best params and num_rounds when it stopped is {:.4f}.'.format(auc_score), '\\n')\n",
    "            return pred, predict\n",
    "        else:\n",
    "            return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7804878048780488 \n",
      "\n",
      "recall score is:  0.524390243902439\n",
      "accuracy score:  0.5763648928818245\n",
      "The final AUC after taking the best params and num_rounds when it stopped is 0.5600. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "trials, best, num_rounds = xgboost_model.optimize(X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test)\n",
    "print(1 - trials.average_best_error(), '\\n')\n",
    "\n",
    "model = xgboost_model.xgb_train(best, num_rounds)\n",
    "\n",
    "pred, predict = xgboost_model.xgb_predict(X_test=X_test, model=model, y_test=y_test, mode='validate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-238-e88b384cd7a9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_importance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_num_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "xgb.plot_importance(booster=model, max_num_features=15, show_values=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lightgbm class for tuning\n",
    "\n",
    "class lightgbm_model():\n",
    "    \n",
    "    def __init__():\n",
    "        \"\"\" this class initializes some functions used in the lightgbm pipeline \"\"\"\n",
    "        \n",
    "    def lgbm_score(params):        \n",
    "        global ITERATION\n",
    "        ITERATION += 1\n",
    "        \n",
    "        # Retrieve the subsample if present otherwise set to 1.0\n",
    "        subsample = params['boosting_type'].get('subsample', 1.0)\n",
    "        # Extract the boosting type\n",
    "        params['boosting_type'] = params['boosting_type']['boosting_type']\n",
    "        params['subsample'] = subsample\n",
    "\n",
    "        # Make sure parameters that need to be integers are integers\n",
    "        for parameter_name in ['num_leaves', 'subsample_for_bin', 'min_child_samples']:\n",
    "            params[parameter_name] = int(params[parameter_name])\n",
    "        \n",
    "        start = timer()\n",
    "        # Perform n_folds cross validation\n",
    "        cv_results = lgb.cv(params, train_set, num_boost_round = 1000, nfold = N_FOLDS, \n",
    "                            early_stopping_rounds = 25, metrics = 'auc', seed = randomseed)\n",
    "        run_time = timer() - start\n",
    "\n",
    "        # Extract the best score\n",
    "        best_score = np.max(cv_results['auc-mean'])\n",
    "        # Loss must be minimized\n",
    "        loss = 1 - best_score\n",
    "\n",
    "        # Boosting rounds that returned the highest cv score\n",
    "        n_estimators = int(np.argmax(cv_results['auc-mean']) + 1)\n",
    "\n",
    "        # Dictionary with information for evaluation\n",
    "        return {'loss': loss, 'params': params, 'iteration': ITERATION,\n",
    "                'estimators': n_estimators, \n",
    "                'train_time': run_time, 'status': STATUS_OK}\n",
    "    \n",
    "    def optimize():\n",
    "        # Keep track of evals\n",
    "        global ITERATION\n",
    "        ITERATION = 0\n",
    "        \n",
    "        global trials\n",
    "        trials = Trials()\n",
    "        \n",
    "        space = {\n",
    "            'boosting_type': hp.choice('boosting_type', [{'boosting_type': 'gbdt', 'subsample': hp.uniform('gdbt_subsample', 0.6, 0.9)}, \n",
    "                                                         {'boosting_type': 'dart', 'subsample': hp.uniform('dart_subsample', 0.6, 0.9)},\n",
    "                                                         {'boosting_type': 'goss', 'subsample': 1.0}]),\n",
    "            'num_leaves': hp.quniform('num_leaves', 30, 500, 1),\n",
    "            'learning_rate': hp.loguniform('learning_rate', np.log(0.001), np.log(0.2)),\n",
    "            'subsample_for_bin': hp.quniform('subsample_for_bin', 20000, 300000, 20000),\n",
    "            'min_child_samples': hp.quniform('min_child_samples', 5, 10, 1),\n",
    "            'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.0),\n",
    "            'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0),\n",
    "            'colsample_bytree': hp.uniform('colsample_by_tree', 0.6, 0.8)\n",
    "        }\n",
    "        \n",
    "        # Run optimization\n",
    "        best = fmin(fn = lightgbm_model.lgbm_score, space = space, algo = tpe.suggest, \n",
    "            max_evals = MAX_EVALS, trials = trials, rstate = np.random.RandomState(randomseed))\n",
    "        best = trials.best_trial['result']['params']\n",
    "        nestimators = trials.best_trial['result']['estimators']\n",
    "        return best, trials, nestimators\n",
    "    \n",
    "    def lgbm_train(best_params, nestimators):\n",
    "        model = lgb.LGBMClassifier(silent = False, random_state = randomseed, objective = 'binary', n_estimators=nestimators)\n",
    "        model.set_params(**best_params)\n",
    "        model.fit(X_train, y_train, eval_metric = \"auc\")\n",
    "        return model\n",
    "    \n",
    "    def lgbm_predict(X_test, y_test, model, mode = \"validate\"):\n",
    "        pred = model.predict_proba(X_test)[:, 1]\n",
    "        predict = np.where(pred > 0.5, 1, 0)\n",
    "        \n",
    "        if mode == \"validate\":\n",
    "            auc_score = roc_auc_score(y_test, pred)\n",
    "            recall_score = sklearn.metrics.recall_score(y_pred=predict, y_true=y_test)\n",
    "            print('recall score is: ', recall_score)\n",
    "            print('accuracy score: ', sklearn.metrics.accuracy_score(y_true=y_test, y_pred=predict))\n",
    "            print('The final AUC after taking the best params and num_rounds when it stopped is {:.4f}.'.format(auc_score), '\\n')\n",
    "            return pred, predict\n",
    "        else:\n",
    "            return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a lgb dataset\n",
    "train_set = lgb.Dataset(X_train, label = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9667677780712894 \n",
      "\n",
      "recall score is:  0.024390243902439025\n",
      "accuracy score:  0.9581893572909468\n",
      "The final AUC after taking the best params and num_rounds when it stopped is 0.5708. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "best, trials, nestimators = lightgbm_model.optimize()\n",
    "\n",
    "print(1 - trials.average_best_error(), '\\n')\n",
    "\n",
    "model = lightgbm_model.lgbm_train(best, nestimators)\n",
    "\n",
    "pred, predict = lightgbm_model.lgbm_predict(X_test=X_test, model=model, y_test=y_test, mode='validate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest class for tuning\n",
    "\n",
    "class rf_model():\n",
    "    \n",
    "    def __init__():\n",
    "        \"\"\" this class initializes some functions used in the random forest pipeline \"\"\"\n",
    "        \n",
    "    def rf_score(params):        \n",
    "        global ITERATION\n",
    "        ITERATION += 1\n",
    "\n",
    "        # Make sure parameters that need to be integers are integers\n",
    "        for parameter_name in ['max_depth', 'n_estimators']:\n",
    "            params[parameter_name] = int(params[parameter_name])\n",
    "                \n",
    "        rf_results = RandomForestClassifier(**params, random_state=randomseed)\n",
    "        rf_results.fit(X_train, y_train)\n",
    "\n",
    "        pred = rf_results.predict_proba(X_test)[:, 1]\n",
    "        auc_score = roc_auc_score(y_test, pred)\n",
    "        #print ('The AUC for iteration ', ITERATION, ' is {:.4f}.'.format(auc_score), '\\n')\n",
    "        return {'loss': (1 - auc_score), 'status': STATUS_OK, 'params': params, 'iteration': ITERATION}\n",
    "    \n",
    "    def optimize():\n",
    "        # Keep track of evals\n",
    "        global ITERATION\n",
    "        ITERATION = 0\n",
    "        \n",
    "        global trials\n",
    "        trials = Trials()\n",
    "        space = {\n",
    "            'max_depth' : hp.quniform('max_depth', 2, 8, 1),\n",
    "            'max_features': hp.choice('max_features', range(1, (X_train.shape[:][1] - 1))),\n",
    "            'criterion': hp.choice('criterion', [\"gini\", \"entropy\"]),\n",
    "            'n_estimators': hp.choice('n_estimators', np.arange(10, 100))\n",
    "        }\n",
    "        \n",
    "        # Run optimization\n",
    "        best = fmin(fn = rf_model.rf_score, space = space, algo = tpe.suggest, \n",
    "            max_evals = MAX_EVALS, trials = trials, rstate = np.random.RandomState(randomseed))\n",
    "        best = trials.best_trial['result']['params']\n",
    "        return best, trials\n",
    "    \n",
    "    def rf_train(best_params):\n",
    "        model = RandomForestClassifier(random_state = randomseed)\n",
    "        model.set_params(**best_params)\n",
    "        model.fit(X_train, y_train)\n",
    "        return model\n",
    "    \n",
    "    def rf_predict(X_test, y_test, model, mode = \"validate\"):\n",
    "        pred = model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        if mode == \"validate\":\n",
    "            auc_score = roc_auc_score(y_test, pred)\n",
    "            print('The AUC is {:.4f}.'.format(auc_score), '\\n')\n",
    "        else:\n",
    "            return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6713795310409031 \n",
      "\n",
      "The AUC is 0.6714. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "best, trials = rf_model.optimize()\n",
    "\n",
    "print(1 - trials.average_best_error(), '\\n')\n",
    "\n",
    "model = rf_model.rf_train(best)\n",
    "\n",
    "rf_model.rf_predict(X_test=X_test, model=model, y_test=y_test, mode='validate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
