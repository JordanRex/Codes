{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">[&#39;conf&#39;, &#39;ganglia&#39;, &#39;derby.log&#39;, &#39;logs&#39;, &#39;eventlogs&#39;]\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## importing the relevant packages:\n",
    "\n",
    "# clear the workspace\n",
    "#%reset -f\n",
    "\n",
    "# print list of files in directory\n",
    "import os\n",
    "print(os.listdir())\n",
    "\n",
    "# the base packages\n",
    "import collections # for the Counter function\n",
    "import csv # for reading/writing csv files\n",
    "import pandas as pd, numpy as np, time, gc, bisect, re\n",
    "from datetime import datetime as dt\n",
    "\n",
    "# the various packages/modules used across processing (sklearn), modelling (lightgbm) and bayesian optimization (hyperopt, bayes_opt)\n",
    "import sklearn\n",
    "from sklearn import metrics, preprocessing\n",
    "import sklearn.decomposition as decomposition\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import category_encoders as ce\n",
    "from scipy.stats import truncnorm\n",
    "\n",
    "# the modelling packages and related\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, recall_score, precision_score, f1_score, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# hyperopt modules\n",
    "#from bayes_opt import BayesianOptimization\n",
    "from tqdm import tqdm\n",
    "from hyperopt import hp, tpe, STATUS_OK, Trials, space_eval, rand\n",
    "from hyperopt.fmin import fmin\n",
    "from hyperopt.pyll.stochastic import sample\n",
    "\n",
    "MAX_EVALS = 5\n",
    "randomseed = 5 # the value for the random state used at various points in the pipeline\n",
    "pd.options.display.max_rows = 1000 # specify if you want the full output in cells rather the truncated list\n",
    "pd.options.display.max_columns = 200\n",
    "\n",
    "# to display multiple outputs in a cell without usin print/display\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## HELPER FUNCTIONS CLASS ##\n",
    "\n",
    "class helper_funcs():\n",
    "    \n",
    "    def __init__():\n",
    "        \"\"\" helper functions used across the pipeline \"\"\"\n",
    "    \n",
    "    ## datetime feature engineering\n",
    "    def datetime_feats(train, valid):\n",
    "        cols = [s for s in train.columns.values if 'date' in s]\n",
    "        print('datetime feature engineering is happening ...', '\\n')\n",
    "        # nested function to derive the various datetime features for a given date column\n",
    "        def dt_feats(df, col):\n",
    "            df[col] = pd.to_datetime(df[i])\n",
    "            #df[str(col+'_'+'day')] = df[col].dt.day\n",
    "            #df[str(col+'_'+'day_name')] = df[col].dt.day_name\n",
    "            #df[str(col+'_'+'dayofweek')] = df[col].dt.dayofweek\n",
    "            df[str(col+'_'+'dayofyear')] = df[col].dt.dayofyear\n",
    "            #df[str(col+'_'+'days_in_month')] = df[col].dt.days_in_month\n",
    "            df[str(col+'_'+'month')] = df[col].dt.month\n",
    "            #df[str(col+'_'+'month_name')] = df[col].dt.month_name\n",
    "            df[str(col+'_'+'quarter')] = df[col].dt.quarter\n",
    "            #df[str(col+'_'+'week')] = df[col].dt.week\n",
    "            #df[str(col+'_'+'weekday')] = df[col].dt.weekday\n",
    "            df[str(col+'_'+'year')] = df[col].dt.year\n",
    "            #df[col] = df[col].dt.date\n",
    "            df = df.drop([col], axis = 1)\n",
    "            return df\n",
    "        # loop function over all raw date columns\n",
    "        for i in cols:\n",
    "            train = dt_feats(train, i)\n",
    "            valid = dt_feats(valid, i)\n",
    "        return train, valid\n",
    "    \n",
    "    ## function to get frequency count of elements in a vector/list\n",
    "    def freq_count(input_vector):\n",
    "        return collections.Counter(input_vector)\n",
    "    \n",
    "    # removing near zero variance columns\n",
    "    def variance_threshold_selector(train, valid, threshold):\n",
    "        print('input data shape is: ', train.shape, '\\n')\n",
    "        selector = VarianceThreshold(threshold)\n",
    "        selector.fit(np.asanyarray(train))\n",
    "        X = train[train.columns[selector.get_support(indices=True)]]\n",
    "        Y = valid[valid.columns[selector.get_support(indices=True)]]\n",
    "        #display(pd.DataFrame(X.head(5)))\n",
    "        print('output data shape is: ', X.shape, '\\n')\n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## MISSING VALUE IMPUTATION CLASS ##\n",
    "\n",
    "class DataFrameImputer(TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Impute missing values.\n",
    "        Columns of dtype object are imputed with the most frequent value \n",
    "        in column.\n",
    "        Columns of other types are imputed with mean of column.\n",
    "        \"\"\"\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        X_temp = X.copy()\n",
    "        #self.fill = pd.Series([X_temp.groupby(['pay_grade_group_pa', 'global_job_om'])[c].value_counts().index[0] if X_temp[c].dtype == np.dtype('O') else X_temp.groupby(['pay_grade_group_pa', 'global_job_om'])[c].mean() for c in X_temp], index=X_temp.columns)\n",
    "        #X_temp = self.fill.copy().reset_index()\n",
    "        #self.fill = pd.Series([X_temp.groupby(['pay_grade_group_pa'])[c].value_counts().index[0] if X_temp[c].dtype == np.dtype('O') else X_temp.groupby(['pay_grade_group_pa'])[c].mean() for c in X_temp], index=X_temp.columns)\n",
    "        #X_temp = self.fill.copy().reset_index()\n",
    "        self.fill = pd.Series([X_temp[c].value_counts().index[0] if X_temp[c].dtype == np.dtype('O') else X_temp[c].mean() for c in X_temp], \n",
    "                              index=X_temp.columns)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.fill)\n",
    "    \n",
    "    def num_missing(self):\n",
    "        return sum(self.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# function to bucket sparse levels in categorical features to the 'others' category as well as handle new values in the valid df\n",
    "\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from collections import defaultdict\n",
    "\n",
    "class CategoryGrouper(BaseEstimator, TransformerMixin):  \n",
    "    \"\"\"A tranformer for combining low count observations for categorical features.\n",
    "    This transformer will preserve category values that are above a certain threshold, while bucketing together all the other values. This will fix issues where new data may have an unobserved category value that the training data did not have.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, threshold=0.05):\n",
    "        \"\"\" Initialize method.\n",
    "        Args: threshold (float): The threshold to apply the bucketing when categorical values drop below that threshold.\n",
    "        \"\"\"\n",
    "        self.d = defaultdict(list)\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def transform(self, X, **transform_params):\n",
    "        \"\"\"Transforms X with new buckets.\n",
    "        Args: X (obj): The dataset to pass to the transformer.\n",
    "        Returns: The transformed X with grouped buckets.\n",
    "        \"\"\"\n",
    "        X_copy = X.copy()\n",
    "        for col in X_copy.columns:\n",
    "            X_copy[col] = X_copy[col].apply(lambda x: x if x in self.d[col] else 'others')\n",
    "        return X_copy\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        \"\"\" Fits transformer over X.\n",
    "        Builds a dictionary of lists where the lists are category values of the\n",
    "        column key for preserving, since they meet the threshold.\n",
    "        \"\"\"\n",
    "        df_rows = len(X.index)\n",
    "        for col in X.columns:\n",
    "            calc_col = X.groupby(col)[col].agg(lambda x: (len(x) * 1.0) / df_rows)\n",
    "            self.d[col] = calc_col[calc_col >= self.threshold].index.tolist()\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dfs with 100 elements in cat1 and cat2\n",
    "# note how df_test has elements 'g' and 't' in the respective categories (unknown values)\n",
    "df_train = pd.DataFrame({'cat1': ['a'] * 20 + ['b'] * 30 + ['c'] * 40 + ['d'] * 3 + ['e'] * 4 + ['f'] * 3,\n",
    "                         'cat2': ['z'] * 25 + ['y'] * 25 + ['x'] * 25 + ['w'] * 20 +['v'] * 5})\n",
    "df_test = pd.DataFrame({'cat1': ['a'] * 10 + ['b'] * 20 + ['c'] * 5 + ['d'] * 50 + ['e'] * 10 + ['g'] * 5,\n",
    "                        'cat2': ['z'] * 25 + ['y'] * 55 + ['x'] * 5 + ['w'] * 5 + ['t'] * 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[91]: CategoryGrouper(threshold=0.05)\n",
       "Out[91]: \n",
       "                    cat1 cat2\n",
       "0                      a    z\n",
       "1                      a    z\n",
       "2                      a    z\n",
       "3                      a    z\n",
       "4                      a    z\n",
       "5                      a    z\n",
       "6                      a    z\n",
       "7                      a    z\n",
       "8                      a    z\n",
       "9                      a    z\n",
       "10                     a    z\n",
       "11                     a    z\n",
       "12                     a    z\n",
       "13                     a    z\n",
       "14                     a    z\n",
       "15                     a    z\n",
       "16                     a    z\n",
       "17                     a    z\n",
       "18                     a    z\n",
       "19                     a    z\n",
       "20                     b    z\n",
       "21                     b    z\n",
       "22                     b    z\n",
       "23                     b    z\n",
       "24                     b    z\n",
       "25                     b    y\n",
       "26                     b    y\n",
       "27                     b    y\n",
       "28                     b    y\n",
       "29                     b    y\n",
       "30                     b    y\n",
       "31                     b    y\n",
       "32                     b    y\n",
       "33                     b    y\n",
       "34                     b    y\n",
       "35                     b    y\n",
       "36                     b    y\n",
       "37                     b    y\n",
       "38                     b    y\n",
       "39                     b    y\n",
       "40                     b    y\n",
       "41                     b    y\n",
       "42                     b    y\n",
       "43                     b    y\n",
       "44                     b    y\n",
       "45                     b    y\n",
       "46                     b    y\n",
       "47                     b    y\n",
       "48                     b    y\n",
       "49                     b    y\n",
       "50                     c    x\n",
       "51                     c    x\n",
       "52                     c    x\n",
       "53                     c    x\n",
       "54                     c    x\n",
       "55                     c    x\n",
       "56                     c    x\n",
       "57                     c    x\n",
       "58                     c    x\n",
       "59                     c    x\n",
       "60                     c    x\n",
       "61                     c    x\n",
       "62                     c    x\n",
       "63                     c    x\n",
       "64                     c    x\n",
       "65                     c    x\n",
       "66                     c    x\n",
       "67                     c    x\n",
       "68                     c    x\n",
       "69                     c    x\n",
       "70                     c    x\n",
       "71                     c    x\n",
       "72                     c    x\n",
       "73                     c    x\n",
       "74                     c    x\n",
       "75                     c    w\n",
       "76                     c    w\n",
       "77                     c    w\n",
       "78                     c    w\n",
       "79                     c    w\n",
       "80                     c    w\n",
       "81                     c    w\n",
       "82                     c    w\n",
       "83                     c    w\n",
       "84                     c    w\n",
       "85                     c    w\n",
       "86                     c    w\n",
       "87                     c    w\n",
       "88                     c    w\n",
       "89                     c    w\n",
       "90  CategoryGrouperOther    w\n",
       "91  CategoryGrouperOther    w\n",
       "92  CategoryGrouperOther    w\n",
       "93  CategoryGrouperOther    w\n",
       "94  CategoryGrouperOther    w\n",
       "95  CategoryGrouperOther    v\n",
       "96  CategoryGrouperOther    v\n",
       "97  CategoryGrouperOther    v\n",
       "98  CategoryGrouperOther    v\n",
       "99  CategoryGrouperOther    v\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "catgrouper = CategoryGrouper()\n",
    "catgrouper.fit(df_train)\n",
    "df_test_transformed = catgrouper.transform(df_test)\n",
    "df_train_transformed = catgrouper.transform(df_train)\n",
    "\n",
    "df_train_transformed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "name": "3. Turnover_modelling_FW",
  "notebookId": 1377202759692372
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
