{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## santander"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder files:  ['.ipynb_checkpoints', 'dt.dot', 'sample_submission.csv', 'san.ipynb', 'san.pkl', 'sub.csv', 'test.csv', 'train.csv'] \n",
      "\n",
      "envir variables: \n",
      "MAX_EVALS\t kurtosis\t np\t os\t pd\t randomseed\t sklearn\t sys\t train_test_split\t \n",
      "warnings\t \n"
     ]
    }
   ],
   "source": [
    "# initialization\n",
    "\n",
    "%reset -f\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np, pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import kurtosis\n",
    "\n",
    "# ignore warnings (only if you are the kind that would code when the world is burning)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# some options\n",
    "MAX_EVALS=5\n",
    "randomseed = 1 # the value for the random state used at various points in the pipeline\n",
    "pd.options.display.max_rows = 10 # specify if you want the full output in cells rather the truncated list\n",
    "pd.options.display.max_columns = 200\n",
    "\n",
    "# to display multiple outputs in a cell without usin print/display\n",
    "# from IPython.core.interactiveshell import InteractiveShell\n",
    "# InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# display wd files\n",
    "import os as os\n",
    "print('folder files: ', os.listdir(), '\\n')\n",
    "print('envir variables: ')\n",
    "%who\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "#from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from hyperopt import hp, tpe, STATUS_OK, fmin, Trials\n",
    "from hyperopt.fmin import fmin\n",
    "from hyperopt.pyll.stochastic import sample\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# ## input\n",
    "\n",
    "# train = pd.read_csv('./train.csv')\n",
    "# test = pd.read_csv('./test.csv')\n",
    "# ss = pd.read_csv('./sample_submission.csv')\n",
    "\n",
    "# train_res = train.target.values\n",
    "# train.drop(columns=['target', 'ID_code'], inplace=True)\n",
    "# test.drop(columns=['ID_code'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# san = open('./san.pkl','wb')\n",
    "# pickle.dump(train, san)\n",
    "# pickle.dump(test, san)\n",
    "# pickle.dump(train_res, san)\n",
    "# pickle.dump(ss, san)\n",
    "# san.close()\n",
    "\n",
    "# load backup\n",
    "san = open('./san.pkl', 'rb')\n",
    "train = pickle.load(san)\n",
    "test = pickle.load(san)\n",
    "train_res = pickle.load(san)\n",
    "ss = pickle.load(san)\n",
    "san.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def mmm_feats(df):\n",
    "    df['max'] = df.max(axis=1)\n",
    "    df['min'] = df.min(axis=1)\n",
    "    df['mean'] = df.mean(axis=1)\n",
    "    df['median'] = df.median(axis=1)\n",
    "    df['std'] = df.std(axis=1)\n",
    "    df['kurt'] = df.kurtosis(axis=1)\n",
    "    df['sum'] = df.sum(axis=1)\n",
    "    df['skew'] = df.skew(axis=1)\n",
    "    return df\n",
    "\n",
    "train = mmm_feats(train)\n",
    "test = mmm_feats(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# from sklearn.tree import _tree\n",
    "\n",
    "# def tree_to_code(tree, feature_names):\n",
    "#     tree_ = tree.tree_\n",
    "#     feature_name = [\n",
    "#         feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n",
    "#         for i in tree_.feature\n",
    "#     ]\n",
    "#     print(\"def tree({}):\".format(\", \".join(feature_names)))\n",
    "\n",
    "#     def recurse(node, depth):\n",
    "#         indent = \"  \" * depth\n",
    "#         if tree_.feature[node] != _tree.TREE_UNDEFINED:\n",
    "#             name = feature_name[node]\n",
    "#             threshold = tree_.threshold[node]\n",
    "#             print(\"{}if {} <= {}:\".format(indent, name, threshold))\n",
    "#             recurse(tree_.children_left[node], depth + 1)\n",
    "#             print(\"{}else:  # if {} > {}\".format(indent, name, threshold))\n",
    "#             recurse(tree_.children_right[node], depth + 1)\n",
    "#         else:\n",
    "#             print(\"{}return {}\".format(indent, tree_.value[node]))\n",
    "#     recurse(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(train)\n",
    "train = pd.DataFrame(data=scaler.transform(train), columns=train.columns)\n",
    "test = pd.DataFrame(data=scaler.transform(test), columns=test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "full = pd.concat([train, test], axis=0)\n",
    "\n",
    "pcamod = PCA(n_components=10, random_state=1)\n",
    "pcamod.fit(full)\n",
    "xtrain = pcamod.transform(train)\n",
    "xtest = pcamod.transform(test)\n",
    "trainfull = pd.concat([train, pd.DataFrame(xtrain)], axis=1, ignore_index=True)\n",
    "testfull = pd.concat([test, pd.DataFrame(xtest)], axis=1, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "cols=train.columns\n",
    "\n",
    "for i in cols:\n",
    "    newcol = str(i + '_bucket')\n",
    "    mod = DecisionTreeClassifier(max_depth=2)\n",
    "    mod.fit(train[i].to_frame(), train_res)\n",
    "    train[newcol] = mod.predict_proba(train[i].to_frame())[:,1]\n",
    "    test[newcol] = mod.predict_proba(test[i].to_frame())[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "dummy_train, dummy_test, dummy_ytrain, dummy_ytest = train_test_split(train, train_res,\n",
    "                                                    stratify=train_res,\n",
    "                                                    test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "def get_xgb_imp(xgb):\n",
    "    imp_vals = xgb.get_fscore()\n",
    "    feats_imp = pd.DataFrame(imp_vals,index=np.arange(2)).T\n",
    "    feats_imp.iloc[:,0]= feats_imp.index    \n",
    "    feats_imp.columns=['feature','importance']\n",
    "    feats_imp.sort_values('importance',inplace=True,ascending=False)\n",
    "    feats_imp.reset_index(drop=True,inplace=True)\n",
    "    return feats_imp\n",
    "\n",
    "def quick_model(train, valid, ytrain, yvalid):\n",
    "    xg_train = xgb.DMatrix(train, label=ytrain)\n",
    "    xg_test = xgb.DMatrix(valid, label=yvalid)\n",
    "\n",
    "    # setup parameters for xgboost\n",
    "    param = {'objective':'binary:logistic', 'max_depth':50, 'silent':1, 'nthread':-1, 'subsample':0.75, \n",
    "             'colsample_bytree':0.8, 'learning_rate':0.1, 'eval_metric':['logloss', 'error'], 'n_jobs': -1,\n",
    "            'colsample_bylevel':0.7, 'tree_method':'hist', 'seed':10, 'grow_policy':'lossguide', 'max_delta_step':3,\n",
    "            'max_bin':200}\n",
    "\n",
    "    watchlist = [(xg_train, 'train'), (xg_test, 'test')]\n",
    "    num_round = 100\n",
    "    model = xgb.train(param, xg_train, num_round, watchlist, early_stopping_rounds=30, verbose_eval=10)\n",
    "    # get prediction\n",
    "    pred = model.predict(xg_test)\n",
    "    error_rate = np.sum(pred != yvalid) / yvalid.shape[0]\n",
    "    print('Test error using softprob = {}'.format(error_rate))\n",
    "\n",
    "    print(skm.accuracy_score(y_pred=pred, y_true=yvalid))\n",
    "    print(skm.confusion_matrix(y_pred=pred, y_true=yvalid))\n",
    "    return model, feat_names, xg_train, xg_test, pred, pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "model, feat_names, xg_train, xg_test, pred, pred_probs = quick_model(dummy_train, dummy_test, dummy_ytrain, dummy_ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "X = np.array(dummy_train)\n",
    "XV = np.array(dummy_test)\n",
    "Y = to_categorical(dummy_ytrain)\n",
    "YV = to_categorical(dummy_ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140000, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "140000/140000 [==============================] - 26s 189us/sample - loss: 0.2913 - accuracy: 0.8855\n",
      "Epoch 2/3\n",
      "140000/140000 [==============================] - 25s 175us/sample - loss: 0.2387 - accuracy: 0.9114\n",
      "Epoch 3/3\n",
      "140000/140000 [==============================] - 26s 183us/sample - loss: 0.2303 - accuracy: 0.9138\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.2512 - accuracy: 0.9072\n",
      "\n",
      "accuracy: 90.72%\n"
     ]
    }
   ],
   "source": [
    "input_dim = dummy_train.shape[1]\n",
    "\n",
    "class_weight = {0: 1, 1: 1}\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(input_dim, input_dim = input_dim , activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Input(shape = (2000,)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(200, activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(10, activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(2, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy' , optimizer = 'adam' , metrics = ['accuracy'] )\n",
    "model.fit(X, Y, epochs = 3, batch_size = 50, class_weight=class_weight, shuffle=True)\n",
    "scores = model.evaluate(XV, YV)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8615023556924606"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=model.predict(XV)\n",
    "sklearn.metrics.roc_auc_score(y_score=pred, y_true=YV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# X = np.array(xtrain)\n",
    "# XV = np.array(xtest)\n",
    "# Y = to_categorical(ytrain)\n",
    "# YV = to_categorical(ytest)\n",
    "\n",
    "X = np.reshape(xxtrain.values, (-1, 306, 1))\n",
    "Y = ytrain\n",
    "XV = np.reshape(xxtest.values, (-1, 306, 1))\n",
    "YV = ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "T = np.reshape(testfull.values, (-1, 300, 1))\n",
    "\n",
    "pred=model.predict(T)\n",
    "ss['target'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "ss.to_csv('sub.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
