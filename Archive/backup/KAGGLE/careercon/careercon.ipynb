{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "## careercon kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder files:  ['.ipynb_checkpoints', 'car.pkl', 'careercon.ipynb', 'carhyperas.py', 'model.h5', 'pred.csv', 'preddf.csv', 'sample_submission.csv', 'sub.csv', 'X_test.csv', 'X_train.csv', 'y_train.csv', '__pycache__'] \n",
      "\n",
      "envir variables: \n",
      "InteractiveShell\t MAX_EVALS\t np\t os\t pd\t randomseed\t skm\t sys\t train_test_split\t \n",
      "warnings\t \n"
     ]
    }
   ],
   "source": [
    "# initialization\n",
    "\n",
    "%reset -f\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np, pandas as pd\n",
    "import sklearn.metrics as skm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ignore warnings (only if you are the kind that would code when the world is burning)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# some options\n",
    "MAX_EVALS=5\n",
    "randomseed = 1 # the value for the random state used at various points in the pipeline\n",
    "pd.options.display.max_rows = 10 # specify if you want the full output in cells rather the truncated list\n",
    "pd.options.display.max_columns = 200\n",
    "\n",
    "# to display multiple outputs in a cell without usin print/display\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# display wd files\n",
    "import os as os\n",
    "print('folder files: ', os.listdir(), '\\n')\n",
    "print('envir variables: ')\n",
    "%who\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# global function to flatten columns after a grouped operation and aggregation\n",
    "# outside all classes since it is added as an attribute to pandas DataFrames\n",
    "\n",
    "def __my_flatten_cols(self, how=\"_\".join, reset_index=True):\n",
    "    how = (lambda iter: list(iter)[-1]) if how == \"last\" else how\n",
    "    self.columns = [how(filter(None, map(str, levels))) for levels in self.columns.values] \\\n",
    "    if isinstance(self.columns, pd.MultiIndex) else self.columns\n",
    "    return self.reset_index(drop=True) if reset_index else self\n",
    "pd.DataFrame.my_flatten_cols = __my_flatten_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# input\n",
    "\n",
    "train = pd.read_csv('X_train.csv')\n",
    "test = pd.read_csv('X_test.csv')\n",
    "trainres = pd.read_csv('y_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainres_enc = trainres.surface\n",
    "enc = LabelEncoder()\n",
    "enc.fit(trainres_enc)\n",
    "trainres_enc = enc.transform(trainres_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>measurement_number</th>\n",
       "      <th>orientation_X</th>\n",
       "      <th>orientation_Y</th>\n",
       "      <th>orientation_Z</th>\n",
       "      <th>orientation_W</th>\n",
       "      <th>angular_velocity_X</th>\n",
       "      <th>angular_velocity_Y</th>\n",
       "      <th>angular_velocity_Z</th>\n",
       "      <th>linear_acceleration_X</th>\n",
       "      <th>linear_acceleration_Y</th>\n",
       "      <th>linear_acceleration_Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.75853</td>\n",
       "      <td>-0.63435</td>\n",
       "      <td>-0.10488</td>\n",
       "      <td>-0.10597</td>\n",
       "      <td>0.107650</td>\n",
       "      <td>0.017561</td>\n",
       "      <td>0.000767</td>\n",
       "      <td>-0.74857</td>\n",
       "      <td>2.1030</td>\n",
       "      <td>-9.7532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.75853</td>\n",
       "      <td>-0.63434</td>\n",
       "      <td>-0.10490</td>\n",
       "      <td>-0.10600</td>\n",
       "      <td>0.067851</td>\n",
       "      <td>0.029939</td>\n",
       "      <td>0.003385</td>\n",
       "      <td>0.33995</td>\n",
       "      <td>1.5064</td>\n",
       "      <td>-9.4128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  row_id  series_id  measurement_number  orientation_X  orientation_Y  \\\n",
       "0    0_0          0                   0       -0.75853       -0.63435   \n",
       "1    0_1          0                   1       -0.75853       -0.63434   \n",
       "\n",
       "   orientation_Z  orientation_W  angular_velocity_X  angular_velocity_Y  \\\n",
       "0       -0.10488       -0.10597            0.107650            0.017561   \n",
       "1       -0.10490       -0.10600            0.067851            0.029939   \n",
       "\n",
       "   angular_velocity_Z  linear_acceleration_X  linear_acceleration_Y  \\\n",
       "0            0.000767               -0.74857                 2.1030   \n",
       "1            0.003385                0.33995                 1.5064   \n",
       "\n",
       "   linear_acceleration_Z  \n",
       "0                -9.7532  \n",
       "1                -9.4128  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0, 189],\n",
       "       [  1, 779],\n",
       "       [  2, 363],\n",
       "       [  3,  21],\n",
       "       [  4, 308],\n",
       "       [  5, 732],\n",
       "       [  6, 297],\n",
       "       [  7, 514],\n",
       "       [  8, 607]], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(np.unique(trainres_enc, return_counts=True)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "## FOR AGGREGATED APPROACH\n",
    "\n",
    "cols=['orientation_W', 'orientation_X', 'orientation_Y', 'orientation_Z', 'angular_velocity_X', 'angular_velocity_Y', \n",
    "      'angular_velocity_Z', 'linear_acceleration_X', 'linear_acceleration_Y', 'linear_acceleration_Z']\n",
    "\n",
    "trainagg = (train.\n",
    "            groupby(['series_id'])[cols].\n",
    "            agg(['sum', 'mean', 'max', 'min', 'median', 'skew']).\n",
    "            my_flatten_cols())\n",
    "testagg = (test.\n",
    "            groupby(['series_id'])[cols].\n",
    "            agg(['sum', 'mean', 'max', 'min', 'median', 'skew']).\n",
    "            my_flatten_cols())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainagg['series_id'] = trainagg.index\n",
    "testagg['series_id'] = testagg.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "train = train.merge(trainagg, how='left')\n",
    "test = test.merge(testagg, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((487680, 73), (488448, 73))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# # remove highly correlated features to reduce further computation time\n",
    "# print('correlation analysis is happening ...', '\\n')\n",
    "# # Create correlation matrix\n",
    "# corr_matrix = train.corr().abs()\n",
    "# # Select upper triangle of correlation matrix\n",
    "# upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "# # Find index of feature columns with correlation greater than 0.98\n",
    "# to_drop = [column for column in upper.columns if any(upper[column] > 0.98)]        \n",
    "# # Drop features\n",
    "# #print(to_drop, '\\n')\n",
    "# train.drop(to_drop, axis=1, inplace=True)\n",
    "# test.drop(to_drop, axis=1, inplace=True)\n",
    "# print('correlation analysis completed ...', '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainnew = pd.merge(train, trainres, how='left')\n",
    "trainnew['surface_enc'] = enc.transform(trainnew['surface'])\n",
    "trainnew.drop(columns=['row_id', 'measurement_number', 'group_id', 'surface'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>measurement_number</th>\n",
       "      <th>orientation_X</th>\n",
       "      <th>orientation_Y</th>\n",
       "      <th>orientation_Z</th>\n",
       "      <th>orientation_W</th>\n",
       "      <th>angular_velocity_X</th>\n",
       "      <th>angular_velocity_Y</th>\n",
       "      <th>angular_velocity_Z</th>\n",
       "      <th>linear_acceleration_X</th>\n",
       "      <th>linear_acceleration_Y</th>\n",
       "      <th>linear_acceleration_Z</th>\n",
       "      <th>orientation_W_sum</th>\n",
       "      <th>orientation_W_mean</th>\n",
       "      <th>orientation_W_max</th>\n",
       "      <th>orientation_W_min</th>\n",
       "      <th>orientation_W_median</th>\n",
       "      <th>orientation_W_skew</th>\n",
       "      <th>orientation_X_sum</th>\n",
       "      <th>orientation_X_mean</th>\n",
       "      <th>orientation_X_max</th>\n",
       "      <th>orientation_X_min</th>\n",
       "      <th>orientation_X_median</th>\n",
       "      <th>orientation_X_skew</th>\n",
       "      <th>orientation_Y_sum</th>\n",
       "      <th>orientation_Y_mean</th>\n",
       "      <th>orientation_Y_max</th>\n",
       "      <th>orientation_Y_min</th>\n",
       "      <th>orientation_Y_median</th>\n",
       "      <th>orientation_Y_skew</th>\n",
       "      <th>orientation_Z_sum</th>\n",
       "      <th>orientation_Z_mean</th>\n",
       "      <th>orientation_Z_max</th>\n",
       "      <th>orientation_Z_min</th>\n",
       "      <th>orientation_Z_median</th>\n",
       "      <th>orientation_Z_skew</th>\n",
       "      <th>angular_velocity_X_sum</th>\n",
       "      <th>angular_velocity_X_mean</th>\n",
       "      <th>angular_velocity_X_max</th>\n",
       "      <th>angular_velocity_X_min</th>\n",
       "      <th>angular_velocity_X_median</th>\n",
       "      <th>angular_velocity_X_skew</th>\n",
       "      <th>angular_velocity_Y_sum</th>\n",
       "      <th>angular_velocity_Y_mean</th>\n",
       "      <th>angular_velocity_Y_max</th>\n",
       "      <th>angular_velocity_Y_min</th>\n",
       "      <th>angular_velocity_Y_median</th>\n",
       "      <th>angular_velocity_Y_skew</th>\n",
       "      <th>angular_velocity_Z_sum</th>\n",
       "      <th>angular_velocity_Z_mean</th>\n",
       "      <th>angular_velocity_Z_max</th>\n",
       "      <th>angular_velocity_Z_min</th>\n",
       "      <th>angular_velocity_Z_median</th>\n",
       "      <th>angular_velocity_Z_skew</th>\n",
       "      <th>linear_acceleration_X_sum</th>\n",
       "      <th>linear_acceleration_X_mean</th>\n",
       "      <th>linear_acceleration_X_max</th>\n",
       "      <th>linear_acceleration_X_min</th>\n",
       "      <th>linear_acceleration_X_median</th>\n",
       "      <th>linear_acceleration_X_skew</th>\n",
       "      <th>linear_acceleration_Y_sum</th>\n",
       "      <th>linear_acceleration_Y_mean</th>\n",
       "      <th>linear_acceleration_Y_max</th>\n",
       "      <th>linear_acceleration_Y_min</th>\n",
       "      <th>linear_acceleration_Y_median</th>\n",
       "      <th>linear_acceleration_Y_skew</th>\n",
       "      <th>linear_acceleration_Z_sum</th>\n",
       "      <th>linear_acceleration_Z_mean</th>\n",
       "      <th>linear_acceleration_Z_max</th>\n",
       "      <th>linear_acceleration_Z_min</th>\n",
       "      <th>linear_acceleration_Z_median</th>\n",
       "      <th>linear_acceleration_Z_skew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.025773</td>\n",
       "      <td>-0.98864</td>\n",
       "      <td>-0.148010</td>\n",
       "      <td>0.003350</td>\n",
       "      <td>-0.006524</td>\n",
       "      <td>-0.001071</td>\n",
       "      <td>-0.027390</td>\n",
       "      <td>0.10043</td>\n",
       "      <td>4.2061</td>\n",
       "      <td>-5.5439</td>\n",
       "      <td>0.40286</td>\n",
       "      <td>0.003147</td>\n",
       "      <td>0.003609</td>\n",
       "      <td>0.002654</td>\n",
       "      <td>0.003134</td>\n",
       "      <td>-0.142993</td>\n",
       "      <td>-3.303669</td>\n",
       "      <td>-0.025810</td>\n",
       "      <td>-0.025156</td>\n",
       "      <td>-0.026418</td>\n",
       "      <td>-0.025748</td>\n",
       "      <td>-0.389316</td>\n",
       "      <td>-126.54647</td>\n",
       "      <td>-0.988644</td>\n",
       "      <td>-0.98854</td>\n",
       "      <td>-0.98873</td>\n",
       "      <td>-0.988645</td>\n",
       "      <td>0.203751</td>\n",
       "      <td>-18.944760</td>\n",
       "      <td>-0.148006</td>\n",
       "      <td>-0.147480</td>\n",
       "      <td>-0.148720</td>\n",
       "      <td>-0.148010</td>\n",
       "      <td>-0.165049</td>\n",
       "      <td>0.127245</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>0.231270</td>\n",
       "      <td>-0.225610</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.123732</td>\n",
       "      <td>0.336571</td>\n",
       "      <td>0.002629</td>\n",
       "      <td>0.11486</td>\n",
       "      <td>-0.13797</td>\n",
       "      <td>0.002223</td>\n",
       "      <td>-0.203662</td>\n",
       "      <td>-0.380337</td>\n",
       "      <td>-0.002971</td>\n",
       "      <td>0.097635</td>\n",
       "      <td>-0.10259</td>\n",
       "      <td>-0.008017</td>\n",
       "      <td>0.095072</td>\n",
       "      <td>18.117709</td>\n",
       "      <td>0.141545</td>\n",
       "      <td>3.3996</td>\n",
       "      <td>-3.0939</td>\n",
       "      <td>0.150615</td>\n",
       "      <td>-0.185976</td>\n",
       "      <td>368.22865</td>\n",
       "      <td>2.876786</td>\n",
       "      <td>6.3266</td>\n",
       "      <td>0.20204</td>\n",
       "      <td>2.83825</td>\n",
       "      <td>0.125563</td>\n",
       "      <td>-1193.6338</td>\n",
       "      <td>-9.325264</td>\n",
       "      <td>-3.9960</td>\n",
       "      <td>-16.362</td>\n",
       "      <td>-9.3756</td>\n",
       "      <td>-0.047728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.025683</td>\n",
       "      <td>-0.98862</td>\n",
       "      <td>-0.148160</td>\n",
       "      <td>0.003439</td>\n",
       "      <td>-0.113960</td>\n",
       "      <td>0.083987</td>\n",
       "      <td>-0.060590</td>\n",
       "      <td>-0.70889</td>\n",
       "      <td>3.9905</td>\n",
       "      <td>-8.0273</td>\n",
       "      <td>0.40286</td>\n",
       "      <td>0.003147</td>\n",
       "      <td>0.003609</td>\n",
       "      <td>0.002654</td>\n",
       "      <td>0.003134</td>\n",
       "      <td>-0.142993</td>\n",
       "      <td>-3.303669</td>\n",
       "      <td>-0.025810</td>\n",
       "      <td>-0.025156</td>\n",
       "      <td>-0.026418</td>\n",
       "      <td>-0.025748</td>\n",
       "      <td>-0.389316</td>\n",
       "      <td>-126.54647</td>\n",
       "      <td>-0.988644</td>\n",
       "      <td>-0.98854</td>\n",
       "      <td>-0.98873</td>\n",
       "      <td>-0.988645</td>\n",
       "      <td>0.203751</td>\n",
       "      <td>-18.944760</td>\n",
       "      <td>-0.148006</td>\n",
       "      <td>-0.147480</td>\n",
       "      <td>-0.148720</td>\n",
       "      <td>-0.148010</td>\n",
       "      <td>-0.165049</td>\n",
       "      <td>0.127245</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>0.231270</td>\n",
       "      <td>-0.225610</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.123732</td>\n",
       "      <td>0.336571</td>\n",
       "      <td>0.002629</td>\n",
       "      <td>0.11486</td>\n",
       "      <td>-0.13797</td>\n",
       "      <td>0.002223</td>\n",
       "      <td>-0.203662</td>\n",
       "      <td>-0.380337</td>\n",
       "      <td>-0.002971</td>\n",
       "      <td>0.097635</td>\n",
       "      <td>-0.10259</td>\n",
       "      <td>-0.008017</td>\n",
       "      <td>0.095072</td>\n",
       "      <td>18.117709</td>\n",
       "      <td>0.141545</td>\n",
       "      <td>3.3996</td>\n",
       "      <td>-3.0939</td>\n",
       "      <td>0.150615</td>\n",
       "      <td>-0.185976</td>\n",
       "      <td>368.22865</td>\n",
       "      <td>2.876786</td>\n",
       "      <td>6.3266</td>\n",
       "      <td>0.20204</td>\n",
       "      <td>2.83825</td>\n",
       "      <td>0.125563</td>\n",
       "      <td>-1193.6338</td>\n",
       "      <td>-9.325264</td>\n",
       "      <td>-3.9960</td>\n",
       "      <td>-16.362</td>\n",
       "      <td>-9.3756</td>\n",
       "      <td>-0.047728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.025617</td>\n",
       "      <td>-0.98861</td>\n",
       "      <td>-0.148260</td>\n",
       "      <td>0.003571</td>\n",
       "      <td>-0.080518</td>\n",
       "      <td>0.114860</td>\n",
       "      <td>-0.037177</td>\n",
       "      <td>1.45710</td>\n",
       "      <td>2.2828</td>\n",
       "      <td>-11.2990</td>\n",
       "      <td>0.40286</td>\n",
       "      <td>0.003147</td>\n",
       "      <td>0.003609</td>\n",
       "      <td>0.002654</td>\n",
       "      <td>0.003134</td>\n",
       "      <td>-0.142993</td>\n",
       "      <td>-3.303669</td>\n",
       "      <td>-0.025810</td>\n",
       "      <td>-0.025156</td>\n",
       "      <td>-0.026418</td>\n",
       "      <td>-0.025748</td>\n",
       "      <td>-0.389316</td>\n",
       "      <td>-126.54647</td>\n",
       "      <td>-0.988644</td>\n",
       "      <td>-0.98854</td>\n",
       "      <td>-0.98873</td>\n",
       "      <td>-0.988645</td>\n",
       "      <td>0.203751</td>\n",
       "      <td>-18.944760</td>\n",
       "      <td>-0.148006</td>\n",
       "      <td>-0.147480</td>\n",
       "      <td>-0.148720</td>\n",
       "      <td>-0.148010</td>\n",
       "      <td>-0.165049</td>\n",
       "      <td>0.127245</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>0.231270</td>\n",
       "      <td>-0.225610</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.123732</td>\n",
       "      <td>0.336571</td>\n",
       "      <td>0.002629</td>\n",
       "      <td>0.11486</td>\n",
       "      <td>-0.13797</td>\n",
       "      <td>0.002223</td>\n",
       "      <td>-0.203662</td>\n",
       "      <td>-0.380337</td>\n",
       "      <td>-0.002971</td>\n",
       "      <td>0.097635</td>\n",
       "      <td>-0.10259</td>\n",
       "      <td>-0.008017</td>\n",
       "      <td>0.095072</td>\n",
       "      <td>18.117709</td>\n",
       "      <td>0.141545</td>\n",
       "      <td>3.3996</td>\n",
       "      <td>-3.0939</td>\n",
       "      <td>0.150615</td>\n",
       "      <td>-0.185976</td>\n",
       "      <td>368.22865</td>\n",
       "      <td>2.876786</td>\n",
       "      <td>6.3266</td>\n",
       "      <td>0.20204</td>\n",
       "      <td>2.83825</td>\n",
       "      <td>0.125563</td>\n",
       "      <td>-1193.6338</td>\n",
       "      <td>-9.325264</td>\n",
       "      <td>-3.9960</td>\n",
       "      <td>-16.362</td>\n",
       "      <td>-9.3756</td>\n",
       "      <td>-0.047728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.025566</td>\n",
       "      <td>-0.98862</td>\n",
       "      <td>-0.148170</td>\n",
       "      <td>0.003609</td>\n",
       "      <td>0.070067</td>\n",
       "      <td>0.033820</td>\n",
       "      <td>-0.035904</td>\n",
       "      <td>0.71096</td>\n",
       "      <td>1.8582</td>\n",
       "      <td>-12.2270</td>\n",
       "      <td>0.40286</td>\n",
       "      <td>0.003147</td>\n",
       "      <td>0.003609</td>\n",
       "      <td>0.002654</td>\n",
       "      <td>0.003134</td>\n",
       "      <td>-0.142993</td>\n",
       "      <td>-3.303669</td>\n",
       "      <td>-0.025810</td>\n",
       "      <td>-0.025156</td>\n",
       "      <td>-0.026418</td>\n",
       "      <td>-0.025748</td>\n",
       "      <td>-0.389316</td>\n",
       "      <td>-126.54647</td>\n",
       "      <td>-0.988644</td>\n",
       "      <td>-0.98854</td>\n",
       "      <td>-0.98873</td>\n",
       "      <td>-0.988645</td>\n",
       "      <td>0.203751</td>\n",
       "      <td>-18.944760</td>\n",
       "      <td>-0.148006</td>\n",
       "      <td>-0.147480</td>\n",
       "      <td>-0.148720</td>\n",
       "      <td>-0.148010</td>\n",
       "      <td>-0.165049</td>\n",
       "      <td>0.127245</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>0.231270</td>\n",
       "      <td>-0.225610</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.123732</td>\n",
       "      <td>0.336571</td>\n",
       "      <td>0.002629</td>\n",
       "      <td>0.11486</td>\n",
       "      <td>-0.13797</td>\n",
       "      <td>0.002223</td>\n",
       "      <td>-0.203662</td>\n",
       "      <td>-0.380337</td>\n",
       "      <td>-0.002971</td>\n",
       "      <td>0.097635</td>\n",
       "      <td>-0.10259</td>\n",
       "      <td>-0.008017</td>\n",
       "      <td>0.095072</td>\n",
       "      <td>18.117709</td>\n",
       "      <td>0.141545</td>\n",
       "      <td>3.3996</td>\n",
       "      <td>-3.0939</td>\n",
       "      <td>0.150615</td>\n",
       "      <td>-0.185976</td>\n",
       "      <td>368.22865</td>\n",
       "      <td>2.876786</td>\n",
       "      <td>6.3266</td>\n",
       "      <td>0.20204</td>\n",
       "      <td>2.83825</td>\n",
       "      <td>0.125563</td>\n",
       "      <td>-1193.6338</td>\n",
       "      <td>-9.325264</td>\n",
       "      <td>-3.9960</td>\n",
       "      <td>-16.362</td>\n",
       "      <td>-9.3756</td>\n",
       "      <td>-0.047728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.025548</td>\n",
       "      <td>-0.98866</td>\n",
       "      <td>-0.147920</td>\n",
       "      <td>0.003477</td>\n",
       "      <td>0.152050</td>\n",
       "      <td>-0.029016</td>\n",
       "      <td>-0.015314</td>\n",
       "      <td>3.39960</td>\n",
       "      <td>2.7881</td>\n",
       "      <td>-10.4100</td>\n",
       "      <td>0.40286</td>\n",
       "      <td>0.003147</td>\n",
       "      <td>0.003609</td>\n",
       "      <td>0.002654</td>\n",
       "      <td>0.003134</td>\n",
       "      <td>-0.142993</td>\n",
       "      <td>-3.303669</td>\n",
       "      <td>-0.025810</td>\n",
       "      <td>-0.025156</td>\n",
       "      <td>-0.026418</td>\n",
       "      <td>-0.025748</td>\n",
       "      <td>-0.389316</td>\n",
       "      <td>-126.54647</td>\n",
       "      <td>-0.988644</td>\n",
       "      <td>-0.98854</td>\n",
       "      <td>-0.98873</td>\n",
       "      <td>-0.988645</td>\n",
       "      <td>0.203751</td>\n",
       "      <td>-18.944760</td>\n",
       "      <td>-0.148006</td>\n",
       "      <td>-0.147480</td>\n",
       "      <td>-0.148720</td>\n",
       "      <td>-0.148010</td>\n",
       "      <td>-0.165049</td>\n",
       "      <td>0.127245</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>0.231270</td>\n",
       "      <td>-0.225610</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.123732</td>\n",
       "      <td>0.336571</td>\n",
       "      <td>0.002629</td>\n",
       "      <td>0.11486</td>\n",
       "      <td>-0.13797</td>\n",
       "      <td>0.002223</td>\n",
       "      <td>-0.203662</td>\n",
       "      <td>-0.380337</td>\n",
       "      <td>-0.002971</td>\n",
       "      <td>0.097635</td>\n",
       "      <td>-0.10259</td>\n",
       "      <td>-0.008017</td>\n",
       "      <td>0.095072</td>\n",
       "      <td>18.117709</td>\n",
       "      <td>0.141545</td>\n",
       "      <td>3.3996</td>\n",
       "      <td>-3.0939</td>\n",
       "      <td>0.150615</td>\n",
       "      <td>-0.185976</td>\n",
       "      <td>368.22865</td>\n",
       "      <td>2.876786</td>\n",
       "      <td>6.3266</td>\n",
       "      <td>0.20204</td>\n",
       "      <td>2.83825</td>\n",
       "      <td>0.125563</td>\n",
       "      <td>-1193.6338</td>\n",
       "      <td>-9.325264</td>\n",
       "      <td>-3.9960</td>\n",
       "      <td>-16.362</td>\n",
       "      <td>-9.3756</td>\n",
       "      <td>-0.047728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488443</th>\n",
       "      <td>3815_123</td>\n",
       "      <td>3815</td>\n",
       "      <td>123</td>\n",
       "      <td>-0.966830</td>\n",
       "      <td>0.20760</td>\n",
       "      <td>0.021964</td>\n",
       "      <td>-0.147150</td>\n",
       "      <td>-0.000390</td>\n",
       "      <td>-0.214570</td>\n",
       "      <td>0.573270</td>\n",
       "      <td>1.11380</td>\n",
       "      <td>3.9277</td>\n",
       "      <td>-9.0971</td>\n",
       "      <td>-18.92822</td>\n",
       "      <td>-0.147877</td>\n",
       "      <td>-0.147090</td>\n",
       "      <td>-0.148810</td>\n",
       "      <td>-0.147990</td>\n",
       "      <td>-0.123192</td>\n",
       "      <td>-124.721350</td>\n",
       "      <td>-0.974386</td>\n",
       "      <td>-0.966210</td>\n",
       "      <td>-0.981070</td>\n",
       "      <td>-0.974750</td>\n",
       "      <td>0.218397</td>\n",
       "      <td>21.33927</td>\n",
       "      <td>0.166713</td>\n",
       "      <td>0.21048</td>\n",
       "      <td>0.12366</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.020975</td>\n",
       "      <td>1.998631</td>\n",
       "      <td>0.015614</td>\n",
       "      <td>0.022436</td>\n",
       "      <td>0.008861</td>\n",
       "      <td>0.015511</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>-1.160498</td>\n",
       "      <td>-0.009066</td>\n",
       "      <td>0.037245</td>\n",
       "      <td>-0.044484</td>\n",
       "      <td>-0.011316</td>\n",
       "      <td>0.548156</td>\n",
       "      <td>-21.125900</td>\n",
       "      <td>-0.165046</td>\n",
       "      <td>-0.11204</td>\n",
       "      <td>-0.21815</td>\n",
       "      <td>-0.166345</td>\n",
       "      <td>-0.075674</td>\n",
       "      <td>68.622870</td>\n",
       "      <td>0.536116</td>\n",
       "      <td>0.575400</td>\n",
       "      <td>0.47803</td>\n",
       "      <td>0.540485</td>\n",
       "      <td>-0.516849</td>\n",
       "      <td>61.908466</td>\n",
       "      <td>0.483660</td>\n",
       "      <td>1.6753</td>\n",
       "      <td>-1.0361</td>\n",
       "      <td>0.505110</td>\n",
       "      <td>-0.150957</td>\n",
       "      <td>384.45770</td>\n",
       "      <td>3.003576</td>\n",
       "      <td>3.9725</td>\n",
       "      <td>1.81600</td>\n",
       "      <td>3.07820</td>\n",
       "      <td>-0.313571</td>\n",
       "      <td>-1194.6237</td>\n",
       "      <td>-9.332998</td>\n",
       "      <td>-8.2423</td>\n",
       "      <td>-10.294</td>\n",
       "      <td>-9.3282</td>\n",
       "      <td>0.053851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488444</th>\n",
       "      <td>3815_124</td>\n",
       "      <td>3815</td>\n",
       "      <td>124</td>\n",
       "      <td>-0.966680</td>\n",
       "      <td>0.20832</td>\n",
       "      <td>0.022090</td>\n",
       "      <td>-0.147120</td>\n",
       "      <td>-0.001529</td>\n",
       "      <td>-0.189840</td>\n",
       "      <td>0.566910</td>\n",
       "      <td>0.22492</td>\n",
       "      <td>3.4683</td>\n",
       "      <td>-9.4288</td>\n",
       "      <td>-18.92822</td>\n",
       "      <td>-0.147877</td>\n",
       "      <td>-0.147090</td>\n",
       "      <td>-0.148810</td>\n",
       "      <td>-0.147990</td>\n",
       "      <td>-0.123192</td>\n",
       "      <td>-124.721350</td>\n",
       "      <td>-0.974386</td>\n",
       "      <td>-0.966210</td>\n",
       "      <td>-0.981070</td>\n",
       "      <td>-0.974750</td>\n",
       "      <td>0.218397</td>\n",
       "      <td>21.33927</td>\n",
       "      <td>0.166713</td>\n",
       "      <td>0.21048</td>\n",
       "      <td>0.12366</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.020975</td>\n",
       "      <td>1.998631</td>\n",
       "      <td>0.015614</td>\n",
       "      <td>0.022436</td>\n",
       "      <td>0.008861</td>\n",
       "      <td>0.015511</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>-1.160498</td>\n",
       "      <td>-0.009066</td>\n",
       "      <td>0.037245</td>\n",
       "      <td>-0.044484</td>\n",
       "      <td>-0.011316</td>\n",
       "      <td>0.548156</td>\n",
       "      <td>-21.125900</td>\n",
       "      <td>-0.165046</td>\n",
       "      <td>-0.11204</td>\n",
       "      <td>-0.21815</td>\n",
       "      <td>-0.166345</td>\n",
       "      <td>-0.075674</td>\n",
       "      <td>68.622870</td>\n",
       "      <td>0.536116</td>\n",
       "      <td>0.575400</td>\n",
       "      <td>0.47803</td>\n",
       "      <td>0.540485</td>\n",
       "      <td>-0.516849</td>\n",
       "      <td>61.908466</td>\n",
       "      <td>0.483660</td>\n",
       "      <td>1.6753</td>\n",
       "      <td>-1.0361</td>\n",
       "      <td>0.505110</td>\n",
       "      <td>-0.150957</td>\n",
       "      <td>384.45770</td>\n",
       "      <td>3.003576</td>\n",
       "      <td>3.9725</td>\n",
       "      <td>1.81600</td>\n",
       "      <td>3.07820</td>\n",
       "      <td>-0.313571</td>\n",
       "      <td>-1194.6237</td>\n",
       "      <td>-9.332998</td>\n",
       "      <td>-8.2423</td>\n",
       "      <td>-10.294</td>\n",
       "      <td>-9.3282</td>\n",
       "      <td>0.053851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488445</th>\n",
       "      <td>3815_125</td>\n",
       "      <td>3815</td>\n",
       "      <td>125</td>\n",
       "      <td>-0.966530</td>\n",
       "      <td>0.20902</td>\n",
       "      <td>0.022185</td>\n",
       "      <td>-0.147130</td>\n",
       "      <td>0.001642</td>\n",
       "      <td>-0.163310</td>\n",
       "      <td>0.566500</td>\n",
       "      <td>0.66608</td>\n",
       "      <td>3.6620</td>\n",
       "      <td>-8.9208</td>\n",
       "      <td>-18.92822</td>\n",
       "      <td>-0.147877</td>\n",
       "      <td>-0.147090</td>\n",
       "      <td>-0.148810</td>\n",
       "      <td>-0.147990</td>\n",
       "      <td>-0.123192</td>\n",
       "      <td>-124.721350</td>\n",
       "      <td>-0.974386</td>\n",
       "      <td>-0.966210</td>\n",
       "      <td>-0.981070</td>\n",
       "      <td>-0.974750</td>\n",
       "      <td>0.218397</td>\n",
       "      <td>21.33927</td>\n",
       "      <td>0.166713</td>\n",
       "      <td>0.21048</td>\n",
       "      <td>0.12366</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.020975</td>\n",
       "      <td>1.998631</td>\n",
       "      <td>0.015614</td>\n",
       "      <td>0.022436</td>\n",
       "      <td>0.008861</td>\n",
       "      <td>0.015511</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>-1.160498</td>\n",
       "      <td>-0.009066</td>\n",
       "      <td>0.037245</td>\n",
       "      <td>-0.044484</td>\n",
       "      <td>-0.011316</td>\n",
       "      <td>0.548156</td>\n",
       "      <td>-21.125900</td>\n",
       "      <td>-0.165046</td>\n",
       "      <td>-0.11204</td>\n",
       "      <td>-0.21815</td>\n",
       "      <td>-0.166345</td>\n",
       "      <td>-0.075674</td>\n",
       "      <td>68.622870</td>\n",
       "      <td>0.536116</td>\n",
       "      <td>0.575400</td>\n",
       "      <td>0.47803</td>\n",
       "      <td>0.540485</td>\n",
       "      <td>-0.516849</td>\n",
       "      <td>61.908466</td>\n",
       "      <td>0.483660</td>\n",
       "      <td>1.6753</td>\n",
       "      <td>-1.0361</td>\n",
       "      <td>0.505110</td>\n",
       "      <td>-0.150957</td>\n",
       "      <td>384.45770</td>\n",
       "      <td>3.003576</td>\n",
       "      <td>3.9725</td>\n",
       "      <td>1.81600</td>\n",
       "      <td>3.07820</td>\n",
       "      <td>-0.313571</td>\n",
       "      <td>-1194.6237</td>\n",
       "      <td>-9.332998</td>\n",
       "      <td>-8.2423</td>\n",
       "      <td>-10.294</td>\n",
       "      <td>-9.3282</td>\n",
       "      <td>0.053851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488446</th>\n",
       "      <td>3815_126</td>\n",
       "      <td>3815</td>\n",
       "      <td>126</td>\n",
       "      <td>-0.966370</td>\n",
       "      <td>0.20974</td>\n",
       "      <td>0.022284</td>\n",
       "      <td>-0.147100</td>\n",
       "      <td>-0.000159</td>\n",
       "      <td>-0.169680</td>\n",
       "      <td>0.575150</td>\n",
       "      <td>0.37295</td>\n",
       "      <td>3.5197</td>\n",
       "      <td>-8.4622</td>\n",
       "      <td>-18.92822</td>\n",
       "      <td>-0.147877</td>\n",
       "      <td>-0.147090</td>\n",
       "      <td>-0.148810</td>\n",
       "      <td>-0.147990</td>\n",
       "      <td>-0.123192</td>\n",
       "      <td>-124.721350</td>\n",
       "      <td>-0.974386</td>\n",
       "      <td>-0.966210</td>\n",
       "      <td>-0.981070</td>\n",
       "      <td>-0.974750</td>\n",
       "      <td>0.218397</td>\n",
       "      <td>21.33927</td>\n",
       "      <td>0.166713</td>\n",
       "      <td>0.21048</td>\n",
       "      <td>0.12366</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.020975</td>\n",
       "      <td>1.998631</td>\n",
       "      <td>0.015614</td>\n",
       "      <td>0.022436</td>\n",
       "      <td>0.008861</td>\n",
       "      <td>0.015511</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>-1.160498</td>\n",
       "      <td>-0.009066</td>\n",
       "      <td>0.037245</td>\n",
       "      <td>-0.044484</td>\n",
       "      <td>-0.011316</td>\n",
       "      <td>0.548156</td>\n",
       "      <td>-21.125900</td>\n",
       "      <td>-0.165046</td>\n",
       "      <td>-0.11204</td>\n",
       "      <td>-0.21815</td>\n",
       "      <td>-0.166345</td>\n",
       "      <td>-0.075674</td>\n",
       "      <td>68.622870</td>\n",
       "      <td>0.536116</td>\n",
       "      <td>0.575400</td>\n",
       "      <td>0.47803</td>\n",
       "      <td>0.540485</td>\n",
       "      <td>-0.516849</td>\n",
       "      <td>61.908466</td>\n",
       "      <td>0.483660</td>\n",
       "      <td>1.6753</td>\n",
       "      <td>-1.0361</td>\n",
       "      <td>0.505110</td>\n",
       "      <td>-0.150957</td>\n",
       "      <td>384.45770</td>\n",
       "      <td>3.003576</td>\n",
       "      <td>3.9725</td>\n",
       "      <td>1.81600</td>\n",
       "      <td>3.07820</td>\n",
       "      <td>-0.313571</td>\n",
       "      <td>-1194.6237</td>\n",
       "      <td>-9.332998</td>\n",
       "      <td>-8.2423</td>\n",
       "      <td>-10.294</td>\n",
       "      <td>-9.3282</td>\n",
       "      <td>0.053851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488447</th>\n",
       "      <td>3815_127</td>\n",
       "      <td>3815</td>\n",
       "      <td>127</td>\n",
       "      <td>-0.966210</td>\n",
       "      <td>0.21048</td>\n",
       "      <td>0.022436</td>\n",
       "      <td>-0.147090</td>\n",
       "      <td>-0.023368</td>\n",
       "      <td>-0.208180</td>\n",
       "      <td>0.575400</td>\n",
       "      <td>0.40491</td>\n",
       "      <td>3.6126</td>\n",
       "      <td>-8.5836</td>\n",
       "      <td>-18.92822</td>\n",
       "      <td>-0.147877</td>\n",
       "      <td>-0.147090</td>\n",
       "      <td>-0.148810</td>\n",
       "      <td>-0.147990</td>\n",
       "      <td>-0.123192</td>\n",
       "      <td>-124.721350</td>\n",
       "      <td>-0.974386</td>\n",
       "      <td>-0.966210</td>\n",
       "      <td>-0.981070</td>\n",
       "      <td>-0.974750</td>\n",
       "      <td>0.218397</td>\n",
       "      <td>21.33927</td>\n",
       "      <td>0.166713</td>\n",
       "      <td>0.21048</td>\n",
       "      <td>0.12366</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.020975</td>\n",
       "      <td>1.998631</td>\n",
       "      <td>0.015614</td>\n",
       "      <td>0.022436</td>\n",
       "      <td>0.008861</td>\n",
       "      <td>0.015511</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>-1.160498</td>\n",
       "      <td>-0.009066</td>\n",
       "      <td>0.037245</td>\n",
       "      <td>-0.044484</td>\n",
       "      <td>-0.011316</td>\n",
       "      <td>0.548156</td>\n",
       "      <td>-21.125900</td>\n",
       "      <td>-0.165046</td>\n",
       "      <td>-0.11204</td>\n",
       "      <td>-0.21815</td>\n",
       "      <td>-0.166345</td>\n",
       "      <td>-0.075674</td>\n",
       "      <td>68.622870</td>\n",
       "      <td>0.536116</td>\n",
       "      <td>0.575400</td>\n",
       "      <td>0.47803</td>\n",
       "      <td>0.540485</td>\n",
       "      <td>-0.516849</td>\n",
       "      <td>61.908466</td>\n",
       "      <td>0.483660</td>\n",
       "      <td>1.6753</td>\n",
       "      <td>-1.0361</td>\n",
       "      <td>0.505110</td>\n",
       "      <td>-0.150957</td>\n",
       "      <td>384.45770</td>\n",
       "      <td>3.003576</td>\n",
       "      <td>3.9725</td>\n",
       "      <td>1.81600</td>\n",
       "      <td>3.07820</td>\n",
       "      <td>-0.313571</td>\n",
       "      <td>-1194.6237</td>\n",
       "      <td>-9.332998</td>\n",
       "      <td>-8.2423</td>\n",
       "      <td>-10.294</td>\n",
       "      <td>-9.3282</td>\n",
       "      <td>0.053851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>488448 rows × 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          row_id  series_id  measurement_number  orientation_X  orientation_Y  \\\n",
       "0            0_0          0                   0      -0.025773       -0.98864   \n",
       "1            0_1          0                   1      -0.025683       -0.98862   \n",
       "2            0_2          0                   2      -0.025617       -0.98861   \n",
       "3            0_3          0                   3      -0.025566       -0.98862   \n",
       "4            0_4          0                   4      -0.025548       -0.98866   \n",
       "...          ...        ...                 ...            ...            ...   \n",
       "488443  3815_123       3815                 123      -0.966830        0.20760   \n",
       "488444  3815_124       3815                 124      -0.966680        0.20832   \n",
       "488445  3815_125       3815                 125      -0.966530        0.20902   \n",
       "488446  3815_126       3815                 126      -0.966370        0.20974   \n",
       "488447  3815_127       3815                 127      -0.966210        0.21048   \n",
       "\n",
       "        orientation_Z  orientation_W  angular_velocity_X  angular_velocity_Y  \\\n",
       "0           -0.148010       0.003350           -0.006524           -0.001071   \n",
       "1           -0.148160       0.003439           -0.113960            0.083987   \n",
       "2           -0.148260       0.003571           -0.080518            0.114860   \n",
       "3           -0.148170       0.003609            0.070067            0.033820   \n",
       "4           -0.147920       0.003477            0.152050           -0.029016   \n",
       "...               ...            ...                 ...                 ...   \n",
       "488443       0.021964      -0.147150           -0.000390           -0.214570   \n",
       "488444       0.022090      -0.147120           -0.001529           -0.189840   \n",
       "488445       0.022185      -0.147130            0.001642           -0.163310   \n",
       "488446       0.022284      -0.147100           -0.000159           -0.169680   \n",
       "488447       0.022436      -0.147090           -0.023368           -0.208180   \n",
       "\n",
       "        angular_velocity_Z  linear_acceleration_X  linear_acceleration_Y  \\\n",
       "0                -0.027390                0.10043                 4.2061   \n",
       "1                -0.060590               -0.70889                 3.9905   \n",
       "2                -0.037177                1.45710                 2.2828   \n",
       "3                -0.035904                0.71096                 1.8582   \n",
       "4                -0.015314                3.39960                 2.7881   \n",
       "...                    ...                    ...                    ...   \n",
       "488443            0.573270                1.11380                 3.9277   \n",
       "488444            0.566910                0.22492                 3.4683   \n",
       "488445            0.566500                0.66608                 3.6620   \n",
       "488446            0.575150                0.37295                 3.5197   \n",
       "488447            0.575400                0.40491                 3.6126   \n",
       "\n",
       "        linear_acceleration_Z  orientation_W_sum  orientation_W_mean  \\\n",
       "0                     -5.5439            0.40286            0.003147   \n",
       "1                     -8.0273            0.40286            0.003147   \n",
       "2                    -11.2990            0.40286            0.003147   \n",
       "3                    -12.2270            0.40286            0.003147   \n",
       "4                    -10.4100            0.40286            0.003147   \n",
       "...                       ...                ...                 ...   \n",
       "488443                -9.0971          -18.92822           -0.147877   \n",
       "488444                -9.4288          -18.92822           -0.147877   \n",
       "488445                -8.9208          -18.92822           -0.147877   \n",
       "488446                -8.4622          -18.92822           -0.147877   \n",
       "488447                -8.5836          -18.92822           -0.147877   \n",
       "\n",
       "        orientation_W_max  orientation_W_min  orientation_W_median  \\\n",
       "0                0.003609           0.002654              0.003134   \n",
       "1                0.003609           0.002654              0.003134   \n",
       "2                0.003609           0.002654              0.003134   \n",
       "3                0.003609           0.002654              0.003134   \n",
       "4                0.003609           0.002654              0.003134   \n",
       "...                   ...                ...                   ...   \n",
       "488443          -0.147090          -0.148810             -0.147990   \n",
       "488444          -0.147090          -0.148810             -0.147990   \n",
       "488445          -0.147090          -0.148810             -0.147990   \n",
       "488446          -0.147090          -0.148810             -0.147990   \n",
       "488447          -0.147090          -0.148810             -0.147990   \n",
       "\n",
       "        orientation_W_skew  orientation_X_sum  orientation_X_mean  \\\n",
       "0                -0.142993          -3.303669           -0.025810   \n",
       "1                -0.142993          -3.303669           -0.025810   \n",
       "2                -0.142993          -3.303669           -0.025810   \n",
       "3                -0.142993          -3.303669           -0.025810   \n",
       "4                -0.142993          -3.303669           -0.025810   \n",
       "...                    ...                ...                 ...   \n",
       "488443           -0.123192        -124.721350           -0.974386   \n",
       "488444           -0.123192        -124.721350           -0.974386   \n",
       "488445           -0.123192        -124.721350           -0.974386   \n",
       "488446           -0.123192        -124.721350           -0.974386   \n",
       "488447           -0.123192        -124.721350           -0.974386   \n",
       "\n",
       "        orientation_X_max  orientation_X_min  orientation_X_median  \\\n",
       "0               -0.025156          -0.026418             -0.025748   \n",
       "1               -0.025156          -0.026418             -0.025748   \n",
       "2               -0.025156          -0.026418             -0.025748   \n",
       "3               -0.025156          -0.026418             -0.025748   \n",
       "4               -0.025156          -0.026418             -0.025748   \n",
       "...                   ...                ...                   ...   \n",
       "488443          -0.966210          -0.981070             -0.974750   \n",
       "488444          -0.966210          -0.981070             -0.974750   \n",
       "488445          -0.966210          -0.981070             -0.974750   \n",
       "488446          -0.966210          -0.981070             -0.974750   \n",
       "488447          -0.966210          -0.981070             -0.974750   \n",
       "\n",
       "        orientation_X_skew  orientation_Y_sum  orientation_Y_mean  \\\n",
       "0                -0.389316         -126.54647           -0.988644   \n",
       "1                -0.389316         -126.54647           -0.988644   \n",
       "2                -0.389316         -126.54647           -0.988644   \n",
       "3                -0.389316         -126.54647           -0.988644   \n",
       "4                -0.389316         -126.54647           -0.988644   \n",
       "...                    ...                ...                 ...   \n",
       "488443            0.218397           21.33927            0.166713   \n",
       "488444            0.218397           21.33927            0.166713   \n",
       "488445            0.218397           21.33927            0.166713   \n",
       "488446            0.218397           21.33927            0.166713   \n",
       "488447            0.218397           21.33927            0.166713   \n",
       "\n",
       "        orientation_Y_max  orientation_Y_min  orientation_Y_median  \\\n",
       "0                -0.98854           -0.98873             -0.988645   \n",
       "1                -0.98854           -0.98873             -0.988645   \n",
       "2                -0.98854           -0.98873             -0.988645   \n",
       "3                -0.98854           -0.98873             -0.988645   \n",
       "4                -0.98854           -0.98873             -0.988645   \n",
       "...                   ...                ...                   ...   \n",
       "488443            0.21048            0.12366              0.166480   \n",
       "488444            0.21048            0.12366              0.166480   \n",
       "488445            0.21048            0.12366              0.166480   \n",
       "488446            0.21048            0.12366              0.166480   \n",
       "488447            0.21048            0.12366              0.166480   \n",
       "\n",
       "        orientation_Y_skew  orientation_Z_sum  orientation_Z_mean  \\\n",
       "0                 0.203751         -18.944760           -0.148006   \n",
       "1                 0.203751         -18.944760           -0.148006   \n",
       "2                 0.203751         -18.944760           -0.148006   \n",
       "3                 0.203751         -18.944760           -0.148006   \n",
       "4                 0.203751         -18.944760           -0.148006   \n",
       "...                    ...                ...                 ...   \n",
       "488443            0.020975           1.998631            0.015614   \n",
       "488444            0.020975           1.998631            0.015614   \n",
       "488445            0.020975           1.998631            0.015614   \n",
       "488446            0.020975           1.998631            0.015614   \n",
       "488447            0.020975           1.998631            0.015614   \n",
       "\n",
       "        orientation_Z_max  orientation_Z_min  orientation_Z_median  \\\n",
       "0               -0.147480          -0.148720             -0.148010   \n",
       "1               -0.147480          -0.148720             -0.148010   \n",
       "2               -0.147480          -0.148720             -0.148010   \n",
       "3               -0.147480          -0.148720             -0.148010   \n",
       "4               -0.147480          -0.148720             -0.148010   \n",
       "...                   ...                ...                   ...   \n",
       "488443           0.022436           0.008861              0.015511   \n",
       "488444           0.022436           0.008861              0.015511   \n",
       "488445           0.022436           0.008861              0.015511   \n",
       "488446           0.022436           0.008861              0.015511   \n",
       "488447           0.022436           0.008861              0.015511   \n",
       "\n",
       "        orientation_Z_skew  angular_velocity_X_sum  angular_velocity_X_mean  \\\n",
       "0                -0.165049                0.127245                 0.000994   \n",
       "1                -0.165049                0.127245                 0.000994   \n",
       "2                -0.165049                0.127245                 0.000994   \n",
       "3                -0.165049                0.127245                 0.000994   \n",
       "4                -0.165049                0.127245                 0.000994   \n",
       "...                    ...                     ...                      ...   \n",
       "488443            0.000798               -1.160498                -0.009066   \n",
       "488444            0.000798               -1.160498                -0.009066   \n",
       "488445            0.000798               -1.160498                -0.009066   \n",
       "488446            0.000798               -1.160498                -0.009066   \n",
       "488447            0.000798               -1.160498                -0.009066   \n",
       "\n",
       "        angular_velocity_X_max  angular_velocity_X_min  \\\n",
       "0                     0.231270               -0.225610   \n",
       "1                     0.231270               -0.225610   \n",
       "2                     0.231270               -0.225610   \n",
       "3                     0.231270               -0.225610   \n",
       "4                     0.231270               -0.225610   \n",
       "...                        ...                     ...   \n",
       "488443                0.037245               -0.044484   \n",
       "488444                0.037245               -0.044484   \n",
       "488445                0.037245               -0.044484   \n",
       "488446                0.037245               -0.044484   \n",
       "488447                0.037245               -0.044484   \n",
       "\n",
       "        angular_velocity_X_median  angular_velocity_X_skew  \\\n",
       "0                        0.000418                 0.123732   \n",
       "1                        0.000418                 0.123732   \n",
       "2                        0.000418                 0.123732   \n",
       "3                        0.000418                 0.123732   \n",
       "4                        0.000418                 0.123732   \n",
       "...                           ...                      ...   \n",
       "488443                  -0.011316                 0.548156   \n",
       "488444                  -0.011316                 0.548156   \n",
       "488445                  -0.011316                 0.548156   \n",
       "488446                  -0.011316                 0.548156   \n",
       "488447                  -0.011316                 0.548156   \n",
       "\n",
       "        angular_velocity_Y_sum  angular_velocity_Y_mean  \\\n",
       "0                     0.336571                 0.002629   \n",
       "1                     0.336571                 0.002629   \n",
       "2                     0.336571                 0.002629   \n",
       "3                     0.336571                 0.002629   \n",
       "4                     0.336571                 0.002629   \n",
       "...                        ...                      ...   \n",
       "488443              -21.125900                -0.165046   \n",
       "488444              -21.125900                -0.165046   \n",
       "488445              -21.125900                -0.165046   \n",
       "488446              -21.125900                -0.165046   \n",
       "488447              -21.125900                -0.165046   \n",
       "\n",
       "        angular_velocity_Y_max  angular_velocity_Y_min  \\\n",
       "0                      0.11486                -0.13797   \n",
       "1                      0.11486                -0.13797   \n",
       "2                      0.11486                -0.13797   \n",
       "3                      0.11486                -0.13797   \n",
       "4                      0.11486                -0.13797   \n",
       "...                        ...                     ...   \n",
       "488443                -0.11204                -0.21815   \n",
       "488444                -0.11204                -0.21815   \n",
       "488445                -0.11204                -0.21815   \n",
       "488446                -0.11204                -0.21815   \n",
       "488447                -0.11204                -0.21815   \n",
       "\n",
       "        angular_velocity_Y_median  angular_velocity_Y_skew  \\\n",
       "0                        0.002223                -0.203662   \n",
       "1                        0.002223                -0.203662   \n",
       "2                        0.002223                -0.203662   \n",
       "3                        0.002223                -0.203662   \n",
       "4                        0.002223                -0.203662   \n",
       "...                           ...                      ...   \n",
       "488443                  -0.166345                -0.075674   \n",
       "488444                  -0.166345                -0.075674   \n",
       "488445                  -0.166345                -0.075674   \n",
       "488446                  -0.166345                -0.075674   \n",
       "488447                  -0.166345                -0.075674   \n",
       "\n",
       "        angular_velocity_Z_sum  angular_velocity_Z_mean  \\\n",
       "0                    -0.380337                -0.002971   \n",
       "1                    -0.380337                -0.002971   \n",
       "2                    -0.380337                -0.002971   \n",
       "3                    -0.380337                -0.002971   \n",
       "4                    -0.380337                -0.002971   \n",
       "...                        ...                      ...   \n",
       "488443               68.622870                 0.536116   \n",
       "488444               68.622870                 0.536116   \n",
       "488445               68.622870                 0.536116   \n",
       "488446               68.622870                 0.536116   \n",
       "488447               68.622870                 0.536116   \n",
       "\n",
       "        angular_velocity_Z_max  angular_velocity_Z_min  \\\n",
       "0                     0.097635                -0.10259   \n",
       "1                     0.097635                -0.10259   \n",
       "2                     0.097635                -0.10259   \n",
       "3                     0.097635                -0.10259   \n",
       "4                     0.097635                -0.10259   \n",
       "...                        ...                     ...   \n",
       "488443                0.575400                 0.47803   \n",
       "488444                0.575400                 0.47803   \n",
       "488445                0.575400                 0.47803   \n",
       "488446                0.575400                 0.47803   \n",
       "488447                0.575400                 0.47803   \n",
       "\n",
       "        angular_velocity_Z_median  angular_velocity_Z_skew  \\\n",
       "0                       -0.008017                 0.095072   \n",
       "1                       -0.008017                 0.095072   \n",
       "2                       -0.008017                 0.095072   \n",
       "3                       -0.008017                 0.095072   \n",
       "4                       -0.008017                 0.095072   \n",
       "...                           ...                      ...   \n",
       "488443                   0.540485                -0.516849   \n",
       "488444                   0.540485                -0.516849   \n",
       "488445                   0.540485                -0.516849   \n",
       "488446                   0.540485                -0.516849   \n",
       "488447                   0.540485                -0.516849   \n",
       "\n",
       "        linear_acceleration_X_sum  linear_acceleration_X_mean  \\\n",
       "0                       18.117709                    0.141545   \n",
       "1                       18.117709                    0.141545   \n",
       "2                       18.117709                    0.141545   \n",
       "3                       18.117709                    0.141545   \n",
       "4                       18.117709                    0.141545   \n",
       "...                           ...                         ...   \n",
       "488443                  61.908466                    0.483660   \n",
       "488444                  61.908466                    0.483660   \n",
       "488445                  61.908466                    0.483660   \n",
       "488446                  61.908466                    0.483660   \n",
       "488447                  61.908466                    0.483660   \n",
       "\n",
       "        linear_acceleration_X_max  linear_acceleration_X_min  \\\n",
       "0                          3.3996                    -3.0939   \n",
       "1                          3.3996                    -3.0939   \n",
       "2                          3.3996                    -3.0939   \n",
       "3                          3.3996                    -3.0939   \n",
       "4                          3.3996                    -3.0939   \n",
       "...                           ...                        ...   \n",
       "488443                     1.6753                    -1.0361   \n",
       "488444                     1.6753                    -1.0361   \n",
       "488445                     1.6753                    -1.0361   \n",
       "488446                     1.6753                    -1.0361   \n",
       "488447                     1.6753                    -1.0361   \n",
       "\n",
       "        linear_acceleration_X_median  linear_acceleration_X_skew  \\\n",
       "0                           0.150615                   -0.185976   \n",
       "1                           0.150615                   -0.185976   \n",
       "2                           0.150615                   -0.185976   \n",
       "3                           0.150615                   -0.185976   \n",
       "4                           0.150615                   -0.185976   \n",
       "...                              ...                         ...   \n",
       "488443                      0.505110                   -0.150957   \n",
       "488444                      0.505110                   -0.150957   \n",
       "488445                      0.505110                   -0.150957   \n",
       "488446                      0.505110                   -0.150957   \n",
       "488447                      0.505110                   -0.150957   \n",
       "\n",
       "        linear_acceleration_Y_sum  linear_acceleration_Y_mean  \\\n",
       "0                       368.22865                    2.876786   \n",
       "1                       368.22865                    2.876786   \n",
       "2                       368.22865                    2.876786   \n",
       "3                       368.22865                    2.876786   \n",
       "4                       368.22865                    2.876786   \n",
       "...                           ...                         ...   \n",
       "488443                  384.45770                    3.003576   \n",
       "488444                  384.45770                    3.003576   \n",
       "488445                  384.45770                    3.003576   \n",
       "488446                  384.45770                    3.003576   \n",
       "488447                  384.45770                    3.003576   \n",
       "\n",
       "        linear_acceleration_Y_max  linear_acceleration_Y_min  \\\n",
       "0                          6.3266                    0.20204   \n",
       "1                          6.3266                    0.20204   \n",
       "2                          6.3266                    0.20204   \n",
       "3                          6.3266                    0.20204   \n",
       "4                          6.3266                    0.20204   \n",
       "...                           ...                        ...   \n",
       "488443                     3.9725                    1.81600   \n",
       "488444                     3.9725                    1.81600   \n",
       "488445                     3.9725                    1.81600   \n",
       "488446                     3.9725                    1.81600   \n",
       "488447                     3.9725                    1.81600   \n",
       "\n",
       "        linear_acceleration_Y_median  linear_acceleration_Y_skew  \\\n",
       "0                            2.83825                    0.125563   \n",
       "1                            2.83825                    0.125563   \n",
       "2                            2.83825                    0.125563   \n",
       "3                            2.83825                    0.125563   \n",
       "4                            2.83825                    0.125563   \n",
       "...                              ...                         ...   \n",
       "488443                       3.07820                   -0.313571   \n",
       "488444                       3.07820                   -0.313571   \n",
       "488445                       3.07820                   -0.313571   \n",
       "488446                       3.07820                   -0.313571   \n",
       "488447                       3.07820                   -0.313571   \n",
       "\n",
       "        linear_acceleration_Z_sum  linear_acceleration_Z_mean  \\\n",
       "0                      -1193.6338                   -9.325264   \n",
       "1                      -1193.6338                   -9.325264   \n",
       "2                      -1193.6338                   -9.325264   \n",
       "3                      -1193.6338                   -9.325264   \n",
       "4                      -1193.6338                   -9.325264   \n",
       "...                           ...                         ...   \n",
       "488443                 -1194.6237                   -9.332998   \n",
       "488444                 -1194.6237                   -9.332998   \n",
       "488445                 -1194.6237                   -9.332998   \n",
       "488446                 -1194.6237                   -9.332998   \n",
       "488447                 -1194.6237                   -9.332998   \n",
       "\n",
       "        linear_acceleration_Z_max  linear_acceleration_Z_min  \\\n",
       "0                         -3.9960                    -16.362   \n",
       "1                         -3.9960                    -16.362   \n",
       "2                         -3.9960                    -16.362   \n",
       "3                         -3.9960                    -16.362   \n",
       "4                         -3.9960                    -16.362   \n",
       "...                           ...                        ...   \n",
       "488443                    -8.2423                    -10.294   \n",
       "488444                    -8.2423                    -10.294   \n",
       "488445                    -8.2423                    -10.294   \n",
       "488446                    -8.2423                    -10.294   \n",
       "488447                    -8.2423                    -10.294   \n",
       "\n",
       "        linear_acceleration_Z_median  linear_acceleration_Z_skew  \n",
       "0                            -9.3756                   -0.047728  \n",
       "1                            -9.3756                   -0.047728  \n",
       "2                            -9.3756                   -0.047728  \n",
       "3                            -9.3756                   -0.047728  \n",
       "4                            -9.3756                   -0.047728  \n",
       "...                              ...                         ...  \n",
       "488443                       -9.3282                    0.053851  \n",
       "488444                       -9.3282                    0.053851  \n",
       "488445                       -9.3282                    0.053851  \n",
       "488446                       -9.3282                    0.053851  \n",
       "488447                       -9.3282                    0.053851  \n",
       "\n",
       "[488448 rows x 73 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test.drop(columns=['row_id', 'series_id', 'measurement_number'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "YYY = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "XXX = trainnew.groupby(['series_id']).mean().reset_index()\n",
    "XXY = XXX.surface_enc.values\n",
    "XXX.drop(columns=['surface_enc', 'series_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3810, 70), (3810,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XXX.shape, XXY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orientation_X</th>\n",
       "      <th>orientation_Y</th>\n",
       "      <th>orientation_Z</th>\n",
       "      <th>orientation_W</th>\n",
       "      <th>angular_velocity_X</th>\n",
       "      <th>angular_velocity_Y</th>\n",
       "      <th>angular_velocity_Z</th>\n",
       "      <th>linear_acceleration_X</th>\n",
       "      <th>linear_acceleration_Y</th>\n",
       "      <th>linear_acceleration_Z</th>\n",
       "      <th>orientation_W_sum</th>\n",
       "      <th>orientation_W_mean</th>\n",
       "      <th>orientation_W_max</th>\n",
       "      <th>orientation_W_min</th>\n",
       "      <th>orientation_W_median</th>\n",
       "      <th>orientation_W_skew</th>\n",
       "      <th>orientation_X_sum</th>\n",
       "      <th>orientation_X_mean</th>\n",
       "      <th>orientation_X_max</th>\n",
       "      <th>orientation_X_min</th>\n",
       "      <th>orientation_X_median</th>\n",
       "      <th>orientation_X_skew</th>\n",
       "      <th>orientation_Y_sum</th>\n",
       "      <th>orientation_Y_mean</th>\n",
       "      <th>orientation_Y_max</th>\n",
       "      <th>orientation_Y_min</th>\n",
       "      <th>orientation_Y_median</th>\n",
       "      <th>orientation_Y_skew</th>\n",
       "      <th>orientation_Z_sum</th>\n",
       "      <th>orientation_Z_mean</th>\n",
       "      <th>orientation_Z_max</th>\n",
       "      <th>orientation_Z_min</th>\n",
       "      <th>orientation_Z_median</th>\n",
       "      <th>orientation_Z_skew</th>\n",
       "      <th>angular_velocity_X_sum</th>\n",
       "      <th>angular_velocity_X_mean</th>\n",
       "      <th>angular_velocity_X_max</th>\n",
       "      <th>angular_velocity_X_min</th>\n",
       "      <th>angular_velocity_X_median</th>\n",
       "      <th>angular_velocity_X_skew</th>\n",
       "      <th>angular_velocity_Y_sum</th>\n",
       "      <th>angular_velocity_Y_mean</th>\n",
       "      <th>angular_velocity_Y_max</th>\n",
       "      <th>angular_velocity_Y_min</th>\n",
       "      <th>angular_velocity_Y_median</th>\n",
       "      <th>angular_velocity_Y_skew</th>\n",
       "      <th>angular_velocity_Z_sum</th>\n",
       "      <th>angular_velocity_Z_mean</th>\n",
       "      <th>angular_velocity_Z_max</th>\n",
       "      <th>angular_velocity_Z_min</th>\n",
       "      <th>angular_velocity_Z_median</th>\n",
       "      <th>angular_velocity_Z_skew</th>\n",
       "      <th>linear_acceleration_X_sum</th>\n",
       "      <th>linear_acceleration_X_mean</th>\n",
       "      <th>linear_acceleration_X_max</th>\n",
       "      <th>linear_acceleration_X_min</th>\n",
       "      <th>linear_acceleration_X_median</th>\n",
       "      <th>linear_acceleration_X_skew</th>\n",
       "      <th>linear_acceleration_Y_sum</th>\n",
       "      <th>linear_acceleration_Y_mean</th>\n",
       "      <th>linear_acceleration_Y_max</th>\n",
       "      <th>linear_acceleration_Y_min</th>\n",
       "      <th>linear_acceleration_Y_median</th>\n",
       "      <th>linear_acceleration_Y_skew</th>\n",
       "      <th>linear_acceleration_Z_sum</th>\n",
       "      <th>linear_acceleration_Z_mean</th>\n",
       "      <th>linear_acceleration_Z_max</th>\n",
       "      <th>linear_acceleration_Z_min</th>\n",
       "      <th>linear_acceleration_Z_median</th>\n",
       "      <th>linear_acceleration_Z_skew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.758666</td>\n",
       "      <td>-0.634008</td>\n",
       "      <td>-0.105474</td>\n",
       "      <td>-0.106470</td>\n",
       "      <td>-0.002481</td>\n",
       "      <td>-0.003306</td>\n",
       "      <td>0.007532</td>\n",
       "      <td>0.263418</td>\n",
       "      <td>2.984195</td>\n",
       "      <td>-9.320391</td>\n",
       "      <td>-13.628110</td>\n",
       "      <td>-0.106470</td>\n",
       "      <td>-0.105590</td>\n",
       "      <td>-0.107050</td>\n",
       "      <td>-0.106555</td>\n",
       "      <td>0.441564</td>\n",
       "      <td>-97.10922</td>\n",
       "      <td>-0.758666</td>\n",
       "      <td>-0.75822</td>\n",
       "      <td>-0.75953</td>\n",
       "      <td>-0.758530</td>\n",
       "      <td>-0.659082</td>\n",
       "      <td>-81.15298</td>\n",
       "      <td>-0.634008</td>\n",
       "      <td>-0.63306</td>\n",
       "      <td>-0.63456</td>\n",
       "      <td>-0.634270</td>\n",
       "      <td>0.603197</td>\n",
       "      <td>-13.500690</td>\n",
       "      <td>-0.105474</td>\n",
       "      <td>-0.104610</td>\n",
       "      <td>-0.106140</td>\n",
       "      <td>-0.105500</td>\n",
       "      <td>0.193309</td>\n",
       "      <td>-0.317527</td>\n",
       "      <td>-0.002481</td>\n",
       "      <td>0.107650</td>\n",
       "      <td>-0.160410</td>\n",
       "      <td>-0.005082</td>\n",
       "      <td>-0.342643</td>\n",
       "      <td>-0.423172</td>\n",
       "      <td>-0.003306</td>\n",
       "      <td>0.072698</td>\n",
       "      <td>-0.079404</td>\n",
       "      <td>-0.004037</td>\n",
       "      <td>0.016396</td>\n",
       "      <td>0.964051</td>\n",
       "      <td>0.007532</td>\n",
       "      <td>0.051720</td>\n",
       "      <td>-0.030181</td>\n",
       "      <td>0.006842</td>\n",
       "      <td>0.126373</td>\n",
       "      <td>33.717542</td>\n",
       "      <td>0.263418</td>\n",
       "      <td>2.85380</td>\n",
       "      <td>-1.864400</td>\n",
       "      <td>0.231665</td>\n",
       "      <td>0.132684</td>\n",
       "      <td>381.976947</td>\n",
       "      <td>2.984195</td>\n",
       "      <td>5.3864</td>\n",
       "      <td>0.075417</td>\n",
       "      <td>3.40755</td>\n",
       "      <td>-0.364964</td>\n",
       "      <td>-1193.010000</td>\n",
       "      <td>-9.320391</td>\n",
       "      <td>-6.26810</td>\n",
       "      <td>-12.5120</td>\n",
       "      <td>-9.42995</td>\n",
       "      <td>0.067391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.958606</td>\n",
       "      <td>0.241867</td>\n",
       "      <td>0.031650</td>\n",
       "      <td>-0.146876</td>\n",
       "      <td>0.004605</td>\n",
       "      <td>-0.007757</td>\n",
       "      <td>0.006206</td>\n",
       "      <td>0.121867</td>\n",
       "      <td>2.768193</td>\n",
       "      <td>-9.388899</td>\n",
       "      <td>-18.800070</td>\n",
       "      <td>-0.146876</td>\n",
       "      <td>-0.145870</td>\n",
       "      <td>-0.148090</td>\n",
       "      <td>-0.146910</td>\n",
       "      <td>-0.169549</td>\n",
       "      <td>-122.70162</td>\n",
       "      <td>-0.958606</td>\n",
       "      <td>-0.95837</td>\n",
       "      <td>-0.95896</td>\n",
       "      <td>-0.958595</td>\n",
       "      <td>-0.397289</td>\n",
       "      <td>30.95897</td>\n",
       "      <td>0.241867</td>\n",
       "      <td>0.24270</td>\n",
       "      <td>0.24074</td>\n",
       "      <td>0.241890</td>\n",
       "      <td>-0.422565</td>\n",
       "      <td>4.051239</td>\n",
       "      <td>0.031650</td>\n",
       "      <td>0.032341</td>\n",
       "      <td>0.030504</td>\n",
       "      <td>0.031689</td>\n",
       "      <td>-0.517180</td>\n",
       "      <td>0.589410</td>\n",
       "      <td>0.004605</td>\n",
       "      <td>0.283420</td>\n",
       "      <td>-0.254800</td>\n",
       "      <td>0.010344</td>\n",
       "      <td>-0.136062</td>\n",
       "      <td>-0.992868</td>\n",
       "      <td>-0.007757</td>\n",
       "      <td>0.112080</td>\n",
       "      <td>-0.134330</td>\n",
       "      <td>-0.006330</td>\n",
       "      <td>-0.246493</td>\n",
       "      <td>0.794404</td>\n",
       "      <td>0.006206</td>\n",
       "      <td>0.129150</td>\n",
       "      <td>-0.121610</td>\n",
       "      <td>0.003538</td>\n",
       "      <td>0.004702</td>\n",
       "      <td>15.599035</td>\n",
       "      <td>0.121867</td>\n",
       "      <td>5.10020</td>\n",
       "      <td>-3.193400</td>\n",
       "      <td>0.003571</td>\n",
       "      <td>0.759101</td>\n",
       "      <td>354.328697</td>\n",
       "      <td>2.768193</td>\n",
       "      <td>6.6850</td>\n",
       "      <td>-2.149200</td>\n",
       "      <td>2.75010</td>\n",
       "      <td>-0.183139</td>\n",
       "      <td>-1201.779100</td>\n",
       "      <td>-9.388899</td>\n",
       "      <td>-2.74490</td>\n",
       "      <td>-16.9280</td>\n",
       "      <td>-9.41380</td>\n",
       "      <td>-0.126848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.512057</td>\n",
       "      <td>-0.846171</td>\n",
       "      <td>-0.129371</td>\n",
       "      <td>-0.071082</td>\n",
       "      <td>0.002646</td>\n",
       "      <td>-0.009232</td>\n",
       "      <td>0.027989</td>\n",
       "      <td>0.149711</td>\n",
       "      <td>2.886745</td>\n",
       "      <td>-9.395783</td>\n",
       "      <td>-9.098478</td>\n",
       "      <td>-0.071082</td>\n",
       "      <td>-0.070378</td>\n",
       "      <td>-0.071535</td>\n",
       "      <td>-0.071139</td>\n",
       "      <td>0.511039</td>\n",
       "      <td>-65.54334</td>\n",
       "      <td>-0.512057</td>\n",
       "      <td>-0.50944</td>\n",
       "      <td>-0.51434</td>\n",
       "      <td>-0.512035</td>\n",
       "      <td>0.151971</td>\n",
       "      <td>-108.30988</td>\n",
       "      <td>-0.846171</td>\n",
       "      <td>-0.84490</td>\n",
       "      <td>-0.84779</td>\n",
       "      <td>-0.846210</td>\n",
       "      <td>-0.161786</td>\n",
       "      <td>-16.559440</td>\n",
       "      <td>-0.129371</td>\n",
       "      <td>-0.128520</td>\n",
       "      <td>-0.130300</td>\n",
       "      <td>-0.129405</td>\n",
       "      <td>-0.034406</td>\n",
       "      <td>0.338645</td>\n",
       "      <td>0.002646</td>\n",
       "      <td>0.141920</td>\n",
       "      <td>-0.152710</td>\n",
       "      <td>-0.003120</td>\n",
       "      <td>0.205228</td>\n",
       "      <td>-1.181655</td>\n",
       "      <td>-0.009232</td>\n",
       "      <td>0.091946</td>\n",
       "      <td>-0.107810</td>\n",
       "      <td>-0.010879</td>\n",
       "      <td>-0.077528</td>\n",
       "      <td>3.582611</td>\n",
       "      <td>0.027989</td>\n",
       "      <td>0.088730</td>\n",
       "      <td>-0.015697</td>\n",
       "      <td>0.028323</td>\n",
       "      <td>0.069123</td>\n",
       "      <td>19.163063</td>\n",
       "      <td>0.149711</td>\n",
       "      <td>1.85330</td>\n",
       "      <td>-2.593000</td>\n",
       "      <td>0.174515</td>\n",
       "      <td>-0.480996</td>\n",
       "      <td>369.503305</td>\n",
       "      <td>2.886745</td>\n",
       "      <td>6.2105</td>\n",
       "      <td>-1.254000</td>\n",
       "      <td>3.03375</td>\n",
       "      <td>-0.266815</td>\n",
       "      <td>-1202.660200</td>\n",
       "      <td>-9.395783</td>\n",
       "      <td>-5.74420</td>\n",
       "      <td>-12.4990</td>\n",
       "      <td>-9.37440</td>\n",
       "      <td>0.085877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.939169</td>\n",
       "      <td>0.310140</td>\n",
       "      <td>0.038955</td>\n",
       "      <td>-0.142319</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>-0.002804</td>\n",
       "      <td>0.007887</td>\n",
       "      <td>0.201791</td>\n",
       "      <td>2.657922</td>\n",
       "      <td>-9.451164</td>\n",
       "      <td>-18.216810</td>\n",
       "      <td>-0.142319</td>\n",
       "      <td>-0.139340</td>\n",
       "      <td>-0.144370</td>\n",
       "      <td>-0.142510</td>\n",
       "      <td>0.175628</td>\n",
       "      <td>-120.21364</td>\n",
       "      <td>-0.939169</td>\n",
       "      <td>-0.93884</td>\n",
       "      <td>-0.93968</td>\n",
       "      <td>-0.939170</td>\n",
       "      <td>-0.096106</td>\n",
       "      <td>39.69794</td>\n",
       "      <td>0.310140</td>\n",
       "      <td>0.31147</td>\n",
       "      <td>0.30943</td>\n",
       "      <td>0.310115</td>\n",
       "      <td>1.230981</td>\n",
       "      <td>4.986241</td>\n",
       "      <td>0.038955</td>\n",
       "      <td>0.039799</td>\n",
       "      <td>0.037922</td>\n",
       "      <td>0.038889</td>\n",
       "      <td>0.097680</td>\n",
       "      <td>0.079866</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.519130</td>\n",
       "      <td>-0.401520</td>\n",
       "      <td>0.006709</td>\n",
       "      <td>-0.003575</td>\n",
       "      <td>-0.358926</td>\n",
       "      <td>-0.002804</td>\n",
       "      <td>0.135780</td>\n",
       "      <td>-0.168150</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>-0.320948</td>\n",
       "      <td>1.009490</td>\n",
       "      <td>0.007887</td>\n",
       "      <td>0.085345</td>\n",
       "      <td>-0.073414</td>\n",
       "      <td>0.005856</td>\n",
       "      <td>-0.272105</td>\n",
       "      <td>25.829186</td>\n",
       "      <td>0.201791</td>\n",
       "      <td>4.20320</td>\n",
       "      <td>-3.793400</td>\n",
       "      <td>0.317205</td>\n",
       "      <td>-0.210587</td>\n",
       "      <td>340.214058</td>\n",
       "      <td>2.657922</td>\n",
       "      <td>11.7430</td>\n",
       "      <td>-5.825100</td>\n",
       "      <td>3.00885</td>\n",
       "      <td>-0.117380</td>\n",
       "      <td>-1209.749000</td>\n",
       "      <td>-9.451164</td>\n",
       "      <td>-0.55910</td>\n",
       "      <td>-19.8450</td>\n",
       "      <td>-9.16170</td>\n",
       "      <td>-0.210103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.891301</td>\n",
       "      <td>0.428144</td>\n",
       "      <td>0.060056</td>\n",
       "      <td>-0.136460</td>\n",
       "      <td>0.006969</td>\n",
       "      <td>0.046109</td>\n",
       "      <td>-0.142385</td>\n",
       "      <td>-0.086171</td>\n",
       "      <td>2.981498</td>\n",
       "      <td>-9.349988</td>\n",
       "      <td>-17.466930</td>\n",
       "      <td>-0.136460</td>\n",
       "      <td>-0.135380</td>\n",
       "      <td>-0.137320</td>\n",
       "      <td>-0.136560</td>\n",
       "      <td>0.485774</td>\n",
       "      <td>-114.08647</td>\n",
       "      <td>-0.891301</td>\n",
       "      <td>-0.88673</td>\n",
       "      <td>-0.89689</td>\n",
       "      <td>-0.890940</td>\n",
       "      <td>-0.226700</td>\n",
       "      <td>54.80246</td>\n",
       "      <td>0.428144</td>\n",
       "      <td>0.43740</td>\n",
       "      <td>0.41646</td>\n",
       "      <td>0.428865</td>\n",
       "      <td>-0.242538</td>\n",
       "      <td>7.687225</td>\n",
       "      <td>0.060056</td>\n",
       "      <td>0.061771</td>\n",
       "      <td>0.058247</td>\n",
       "      <td>0.060113</td>\n",
       "      <td>-0.092397</td>\n",
       "      <td>0.892016</td>\n",
       "      <td>0.006969</td>\n",
       "      <td>0.080904</td>\n",
       "      <td>-0.104070</td>\n",
       "      <td>0.010157</td>\n",
       "      <td>-0.394054</td>\n",
       "      <td>5.901899</td>\n",
       "      <td>0.046109</td>\n",
       "      <td>0.083764</td>\n",
       "      <td>0.008231</td>\n",
       "      <td>0.047561</td>\n",
       "      <td>-0.218780</td>\n",
       "      <td>-18.225288</td>\n",
       "      <td>-0.142385</td>\n",
       "      <td>-0.063372</td>\n",
       "      <td>-0.213940</td>\n",
       "      <td>-0.146670</td>\n",
       "      <td>0.085068</td>\n",
       "      <td>-11.029920</td>\n",
       "      <td>-0.086171</td>\n",
       "      <td>0.82891</td>\n",
       "      <td>-1.269600</td>\n",
       "      <td>-0.054043</td>\n",
       "      <td>-0.375568</td>\n",
       "      <td>381.631730</td>\n",
       "      <td>2.981498</td>\n",
       "      <td>4.8181</td>\n",
       "      <td>0.342070</td>\n",
       "      <td>3.13565</td>\n",
       "      <td>-0.534365</td>\n",
       "      <td>-1196.798500</td>\n",
       "      <td>-9.349988</td>\n",
       "      <td>-7.44900</td>\n",
       "      <td>-10.9750</td>\n",
       "      <td>-9.33280</td>\n",
       "      <td>0.106132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3805</th>\n",
       "      <td>-0.228787</td>\n",
       "      <td>0.961730</td>\n",
       "      <td>0.144690</td>\n",
       "      <td>-0.042361</td>\n",
       "      <td>0.002519</td>\n",
       "      <td>0.008479</td>\n",
       "      <td>-0.021297</td>\n",
       "      <td>0.266687</td>\n",
       "      <td>2.745177</td>\n",
       "      <td>-9.465299</td>\n",
       "      <td>-5.422159</td>\n",
       "      <td>-0.042361</td>\n",
       "      <td>-0.041502</td>\n",
       "      <td>-0.043270</td>\n",
       "      <td>-0.042384</td>\n",
       "      <td>-0.206177</td>\n",
       "      <td>-29.28475</td>\n",
       "      <td>-0.228787</td>\n",
       "      <td>-0.22638</td>\n",
       "      <td>-0.23001</td>\n",
       "      <td>-0.229275</td>\n",
       "      <td>0.763646</td>\n",
       "      <td>123.10148</td>\n",
       "      <td>0.961730</td>\n",
       "      <td>0.96225</td>\n",
       "      <td>0.96140</td>\n",
       "      <td>0.961650</td>\n",
       "      <td>0.619900</td>\n",
       "      <td>18.520330</td>\n",
       "      <td>0.144690</td>\n",
       "      <td>0.145550</td>\n",
       "      <td>0.143370</td>\n",
       "      <td>0.144740</td>\n",
       "      <td>-0.644989</td>\n",
       "      <td>0.322397</td>\n",
       "      <td>0.002519</td>\n",
       "      <td>0.483080</td>\n",
       "      <td>-0.430190</td>\n",
       "      <td>-0.005029</td>\n",
       "      <td>0.073135</td>\n",
       "      <td>1.085290</td>\n",
       "      <td>0.008479</td>\n",
       "      <td>0.173090</td>\n",
       "      <td>-0.179140</td>\n",
       "      <td>0.010954</td>\n",
       "      <td>-0.011865</td>\n",
       "      <td>-2.725986</td>\n",
       "      <td>-0.021297</td>\n",
       "      <td>0.082269</td>\n",
       "      <td>-0.162820</td>\n",
       "      <td>-0.013893</td>\n",
       "      <td>-0.397359</td>\n",
       "      <td>34.135889</td>\n",
       "      <td>0.266687</td>\n",
       "      <td>4.61280</td>\n",
       "      <td>-5.557700</td>\n",
       "      <td>0.390665</td>\n",
       "      <td>-0.388012</td>\n",
       "      <td>351.382690</td>\n",
       "      <td>2.745177</td>\n",
       "      <td>7.5051</td>\n",
       "      <td>-1.305500</td>\n",
       "      <td>2.58605</td>\n",
       "      <td>0.101470</td>\n",
       "      <td>-1211.558256</td>\n",
       "      <td>-9.465299</td>\n",
       "      <td>4.95690</td>\n",
       "      <td>-22.2530</td>\n",
       "      <td>-9.65750</td>\n",
       "      <td>0.205344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3806</th>\n",
       "      <td>0.542262</td>\n",
       "      <td>0.826590</td>\n",
       "      <td>0.129890</td>\n",
       "      <td>0.076335</td>\n",
       "      <td>-0.000453</td>\n",
       "      <td>0.003409</td>\n",
       "      <td>-0.000416</td>\n",
       "      <td>0.136476</td>\n",
       "      <td>2.900305</td>\n",
       "      <td>-9.367247</td>\n",
       "      <td>9.770885</td>\n",
       "      <td>0.076335</td>\n",
       "      <td>0.076684</td>\n",
       "      <td>0.076015</td>\n",
       "      <td>0.076329</td>\n",
       "      <td>0.069180</td>\n",
       "      <td>69.40952</td>\n",
       "      <td>0.542262</td>\n",
       "      <td>0.54436</td>\n",
       "      <td>0.54028</td>\n",
       "      <td>0.542260</td>\n",
       "      <td>0.017965</td>\n",
       "      <td>105.80358</td>\n",
       "      <td>0.826590</td>\n",
       "      <td>0.82789</td>\n",
       "      <td>0.82522</td>\n",
       "      <td>0.826590</td>\n",
       "      <td>-0.014884</td>\n",
       "      <td>16.625920</td>\n",
       "      <td>0.129890</td>\n",
       "      <td>0.130080</td>\n",
       "      <td>0.129630</td>\n",
       "      <td>0.129900</td>\n",
       "      <td>-0.258467</td>\n",
       "      <td>-0.057970</td>\n",
       "      <td>-0.000453</td>\n",
       "      <td>0.008284</td>\n",
       "      <td>-0.008044</td>\n",
       "      <td>-0.000334</td>\n",
       "      <td>0.023644</td>\n",
       "      <td>0.436392</td>\n",
       "      <td>0.003409</td>\n",
       "      <td>0.011729</td>\n",
       "      <td>-0.004850</td>\n",
       "      <td>0.003386</td>\n",
       "      <td>0.038432</td>\n",
       "      <td>-0.053218</td>\n",
       "      <td>-0.000416</td>\n",
       "      <td>0.006290</td>\n",
       "      <td>-0.007287</td>\n",
       "      <td>-0.000213</td>\n",
       "      <td>-0.243886</td>\n",
       "      <td>17.468924</td>\n",
       "      <td>0.136476</td>\n",
       "      <td>0.21648</td>\n",
       "      <td>0.061417</td>\n",
       "      <td>0.136950</td>\n",
       "      <td>-0.038278</td>\n",
       "      <td>371.239000</td>\n",
       "      <td>2.900305</td>\n",
       "      <td>2.9568</td>\n",
       "      <td>2.837900</td>\n",
       "      <td>2.90145</td>\n",
       "      <td>-0.140696</td>\n",
       "      <td>-1199.007600</td>\n",
       "      <td>-9.367247</td>\n",
       "      <td>-9.31850</td>\n",
       "      <td>-9.4094</td>\n",
       "      <td>-9.36740</td>\n",
       "      <td>0.060870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3807</th>\n",
       "      <td>-0.416511</td>\n",
       "      <td>0.895374</td>\n",
       "      <td>0.140185</td>\n",
       "      <td>-0.070016</td>\n",
       "      <td>0.031838</td>\n",
       "      <td>0.103777</td>\n",
       "      <td>-0.338278</td>\n",
       "      <td>-0.061158</td>\n",
       "      <td>3.660786</td>\n",
       "      <td>-9.192466</td>\n",
       "      <td>-8.962046</td>\n",
       "      <td>-0.070016</td>\n",
       "      <td>-0.067059</td>\n",
       "      <td>-0.072336</td>\n",
       "      <td>-0.070143</td>\n",
       "      <td>0.050622</td>\n",
       "      <td>-53.31344</td>\n",
       "      <td>-0.416511</td>\n",
       "      <td>-0.39188</td>\n",
       "      <td>-0.44250</td>\n",
       "      <td>-0.416225</td>\n",
       "      <td>-0.113999</td>\n",
       "      <td>114.60787</td>\n",
       "      <td>0.895374</td>\n",
       "      <td>0.90642</td>\n",
       "      <td>0.88360</td>\n",
       "      <td>0.895975</td>\n",
       "      <td>-0.164749</td>\n",
       "      <td>17.943660</td>\n",
       "      <td>0.140185</td>\n",
       "      <td>0.144040</td>\n",
       "      <td>0.135370</td>\n",
       "      <td>0.139735</td>\n",
       "      <td>-0.132593</td>\n",
       "      <td>4.075327</td>\n",
       "      <td>0.031838</td>\n",
       "      <td>0.638570</td>\n",
       "      <td>-0.502510</td>\n",
       "      <td>0.038775</td>\n",
       "      <td>0.236030</td>\n",
       "      <td>13.283490</td>\n",
       "      <td>0.103777</td>\n",
       "      <td>0.297520</td>\n",
       "      <td>-0.264770</td>\n",
       "      <td>0.113335</td>\n",
       "      <td>-0.959642</td>\n",
       "      <td>-43.299620</td>\n",
       "      <td>-0.338278</td>\n",
       "      <td>-0.129720</td>\n",
       "      <td>-0.596830</td>\n",
       "      <td>-0.333705</td>\n",
       "      <td>-0.200093</td>\n",
       "      <td>-7.828190</td>\n",
       "      <td>-0.061158</td>\n",
       "      <td>7.80970</td>\n",
       "      <td>-10.479000</td>\n",
       "      <td>0.165465</td>\n",
       "      <td>-0.122274</td>\n",
       "      <td>468.580635</td>\n",
       "      <td>3.660786</td>\n",
       "      <td>16.4520</td>\n",
       "      <td>-9.657400</td>\n",
       "      <td>3.65475</td>\n",
       "      <td>0.162879</td>\n",
       "      <td>-1176.635710</td>\n",
       "      <td>-9.192466</td>\n",
       "      <td>3.08360</td>\n",
       "      <td>-24.6860</td>\n",
       "      <td>-9.53715</td>\n",
       "      <td>-0.044238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3808</th>\n",
       "      <td>-0.264584</td>\n",
       "      <td>0.952734</td>\n",
       "      <td>0.142060</td>\n",
       "      <td>-0.045705</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>-0.029315</td>\n",
       "      <td>0.088592</td>\n",
       "      <td>0.218964</td>\n",
       "      <td>3.075475</td>\n",
       "      <td>-9.345442</td>\n",
       "      <td>-5.850268</td>\n",
       "      <td>-0.045705</td>\n",
       "      <td>-0.044652</td>\n",
       "      <td>-0.047749</td>\n",
       "      <td>-0.045753</td>\n",
       "      <td>-0.782383</td>\n",
       "      <td>-33.86672</td>\n",
       "      <td>-0.264584</td>\n",
       "      <td>-0.25672</td>\n",
       "      <td>-0.27113</td>\n",
       "      <td>-0.265320</td>\n",
       "      <td>0.255234</td>\n",
       "      <td>121.94998</td>\n",
       "      <td>0.952734</td>\n",
       "      <td>0.95470</td>\n",
       "      <td>0.95067</td>\n",
       "      <td>0.952310</td>\n",
       "      <td>0.097948</td>\n",
       "      <td>18.183740</td>\n",
       "      <td>0.142060</td>\n",
       "      <td>0.144370</td>\n",
       "      <td>0.139910</td>\n",
       "      <td>0.141975</td>\n",
       "      <td>0.132153</td>\n",
       "      <td>0.144381</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>0.401700</td>\n",
       "      <td>-0.307450</td>\n",
       "      <td>-0.017597</td>\n",
       "      <td>0.339035</td>\n",
       "      <td>-3.752277</td>\n",
       "      <td>-0.029315</td>\n",
       "      <td>0.114060</td>\n",
       "      <td>-0.203420</td>\n",
       "      <td>-0.032655</td>\n",
       "      <td>-0.093687</td>\n",
       "      <td>11.339753</td>\n",
       "      <td>0.088592</td>\n",
       "      <td>0.268660</td>\n",
       "      <td>-0.068827</td>\n",
       "      <td>0.093768</td>\n",
       "      <td>0.090947</td>\n",
       "      <td>28.027417</td>\n",
       "      <td>0.218964</td>\n",
       "      <td>7.85800</td>\n",
       "      <td>-6.356000</td>\n",
       "      <td>0.266105</td>\n",
       "      <td>-0.153116</td>\n",
       "      <td>393.660794</td>\n",
       "      <td>3.075475</td>\n",
       "      <td>11.8520</td>\n",
       "      <td>-4.531000</td>\n",
       "      <td>2.27130</td>\n",
       "      <td>0.224241</td>\n",
       "      <td>-1196.216610</td>\n",
       "      <td>-9.345442</td>\n",
       "      <td>-0.60391</td>\n",
       "      <td>-17.3750</td>\n",
       "      <td>-9.40045</td>\n",
       "      <td>0.108252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3809</th>\n",
       "      <td>0.627878</td>\n",
       "      <td>-0.769601</td>\n",
       "      <td>-0.083867</td>\n",
       "      <td>0.080308</td>\n",
       "      <td>-0.003995</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>0.002248</td>\n",
       "      <td>0.150692</td>\n",
       "      <td>2.222328</td>\n",
       "      <td>-9.560770</td>\n",
       "      <td>10.279365</td>\n",
       "      <td>0.080308</td>\n",
       "      <td>0.081284</td>\n",
       "      <td>0.079091</td>\n",
       "      <td>0.080387</td>\n",
       "      <td>-0.475620</td>\n",
       "      <td>80.36838</td>\n",
       "      <td>0.627878</td>\n",
       "      <td>0.62951</td>\n",
       "      <td>0.62705</td>\n",
       "      <td>0.627645</td>\n",
       "      <td>0.783668</td>\n",
       "      <td>-98.50887</td>\n",
       "      <td>-0.769601</td>\n",
       "      <td>-0.76820</td>\n",
       "      <td>-0.77039</td>\n",
       "      <td>-0.769690</td>\n",
       "      <td>0.735398</td>\n",
       "      <td>-10.734917</td>\n",
       "      <td>-0.083867</td>\n",
       "      <td>-0.082672</td>\n",
       "      <td>-0.085207</td>\n",
       "      <td>-0.083863</td>\n",
       "      <td>-0.010013</td>\n",
       "      <td>-0.511327</td>\n",
       "      <td>-0.003995</td>\n",
       "      <td>0.106110</td>\n",
       "      <td>-0.150910</td>\n",
       "      <td>0.006451</td>\n",
       "      <td>-0.403503</td>\n",
       "      <td>0.063414</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>0.165260</td>\n",
       "      <td>-0.087124</td>\n",
       "      <td>-0.005610</td>\n",
       "      <td>1.413377</td>\n",
       "      <td>0.287759</td>\n",
       "      <td>0.002248</td>\n",
       "      <td>0.121930</td>\n",
       "      <td>-0.142740</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>-0.261525</td>\n",
       "      <td>19.288531</td>\n",
       "      <td>0.150692</td>\n",
       "      <td>4.42750</td>\n",
       "      <td>-3.804600</td>\n",
       "      <td>0.244865</td>\n",
       "      <td>-0.279286</td>\n",
       "      <td>284.458005</td>\n",
       "      <td>2.222328</td>\n",
       "      <td>5.8675</td>\n",
       "      <td>-2.714200</td>\n",
       "      <td>2.74810</td>\n",
       "      <td>-0.442227</td>\n",
       "      <td>-1223.778500</td>\n",
       "      <td>-9.560770</td>\n",
       "      <td>-7.60010</td>\n",
       "      <td>-13.3650</td>\n",
       "      <td>-9.46180</td>\n",
       "      <td>-0.881500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3810 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      orientation_X  orientation_Y  orientation_Z  orientation_W  \\\n",
       "0         -0.758666      -0.634008      -0.105474      -0.106470   \n",
       "1         -0.958606       0.241867       0.031650      -0.146876   \n",
       "2         -0.512057      -0.846171      -0.129371      -0.071082   \n",
       "3         -0.939169       0.310140       0.038955      -0.142319   \n",
       "4         -0.891301       0.428144       0.060056      -0.136460   \n",
       "...             ...            ...            ...            ...   \n",
       "3805      -0.228787       0.961730       0.144690      -0.042361   \n",
       "3806       0.542262       0.826590       0.129890       0.076335   \n",
       "3807      -0.416511       0.895374       0.140185      -0.070016   \n",
       "3808      -0.264584       0.952734       0.142060      -0.045705   \n",
       "3809       0.627878      -0.769601      -0.083867       0.080308   \n",
       "\n",
       "      angular_velocity_X  angular_velocity_Y  angular_velocity_Z  \\\n",
       "0              -0.002481           -0.003306            0.007532   \n",
       "1               0.004605           -0.007757            0.006206   \n",
       "2               0.002646           -0.009232            0.027989   \n",
       "3               0.000624           -0.002804            0.007887   \n",
       "4               0.006969            0.046109           -0.142385   \n",
       "...                  ...                 ...                 ...   \n",
       "3805            0.002519            0.008479           -0.021297   \n",
       "3806           -0.000453            0.003409           -0.000416   \n",
       "3807            0.031838            0.103777           -0.338278   \n",
       "3808            0.001128           -0.029315            0.088592   \n",
       "3809           -0.003995            0.000495            0.002248   \n",
       "\n",
       "      linear_acceleration_X  linear_acceleration_Y  linear_acceleration_Z  \\\n",
       "0                  0.263418               2.984195              -9.320391   \n",
       "1                  0.121867               2.768193              -9.388899   \n",
       "2                  0.149711               2.886745              -9.395783   \n",
       "3                  0.201791               2.657922              -9.451164   \n",
       "4                 -0.086171               2.981498              -9.349988   \n",
       "...                     ...                    ...                    ...   \n",
       "3805               0.266687               2.745177              -9.465299   \n",
       "3806               0.136476               2.900305              -9.367247   \n",
       "3807              -0.061158               3.660786              -9.192466   \n",
       "3808               0.218964               3.075475              -9.345442   \n",
       "3809               0.150692               2.222328              -9.560770   \n",
       "\n",
       "      orientation_W_sum  orientation_W_mean  orientation_W_max  \\\n",
       "0            -13.628110           -0.106470          -0.105590   \n",
       "1            -18.800070           -0.146876          -0.145870   \n",
       "2             -9.098478           -0.071082          -0.070378   \n",
       "3            -18.216810           -0.142319          -0.139340   \n",
       "4            -17.466930           -0.136460          -0.135380   \n",
       "...                 ...                 ...                ...   \n",
       "3805          -5.422159           -0.042361          -0.041502   \n",
       "3806           9.770885            0.076335           0.076684   \n",
       "3807          -8.962046           -0.070016          -0.067059   \n",
       "3808          -5.850268           -0.045705          -0.044652   \n",
       "3809          10.279365            0.080308           0.081284   \n",
       "\n",
       "      orientation_W_min  orientation_W_median  orientation_W_skew  \\\n",
       "0             -0.107050             -0.106555            0.441564   \n",
       "1             -0.148090             -0.146910           -0.169549   \n",
       "2             -0.071535             -0.071139            0.511039   \n",
       "3             -0.144370             -0.142510            0.175628   \n",
       "4             -0.137320             -0.136560            0.485774   \n",
       "...                 ...                   ...                 ...   \n",
       "3805          -0.043270             -0.042384           -0.206177   \n",
       "3806           0.076015              0.076329            0.069180   \n",
       "3807          -0.072336             -0.070143            0.050622   \n",
       "3808          -0.047749             -0.045753           -0.782383   \n",
       "3809           0.079091              0.080387           -0.475620   \n",
       "\n",
       "      orientation_X_sum  orientation_X_mean  orientation_X_max  \\\n",
       "0             -97.10922           -0.758666           -0.75822   \n",
       "1            -122.70162           -0.958606           -0.95837   \n",
       "2             -65.54334           -0.512057           -0.50944   \n",
       "3            -120.21364           -0.939169           -0.93884   \n",
       "4            -114.08647           -0.891301           -0.88673   \n",
       "...                 ...                 ...                ...   \n",
       "3805          -29.28475           -0.228787           -0.22638   \n",
       "3806           69.40952            0.542262            0.54436   \n",
       "3807          -53.31344           -0.416511           -0.39188   \n",
       "3808          -33.86672           -0.264584           -0.25672   \n",
       "3809           80.36838            0.627878            0.62951   \n",
       "\n",
       "      orientation_X_min  orientation_X_median  orientation_X_skew  \\\n",
       "0              -0.75953             -0.758530           -0.659082   \n",
       "1              -0.95896             -0.958595           -0.397289   \n",
       "2              -0.51434             -0.512035            0.151971   \n",
       "3              -0.93968             -0.939170           -0.096106   \n",
       "4              -0.89689             -0.890940           -0.226700   \n",
       "...                 ...                   ...                 ...   \n",
       "3805           -0.23001             -0.229275            0.763646   \n",
       "3806            0.54028              0.542260            0.017965   \n",
       "3807           -0.44250             -0.416225           -0.113999   \n",
       "3808           -0.27113             -0.265320            0.255234   \n",
       "3809            0.62705              0.627645            0.783668   \n",
       "\n",
       "      orientation_Y_sum  orientation_Y_mean  orientation_Y_max  \\\n",
       "0             -81.15298           -0.634008           -0.63306   \n",
       "1              30.95897            0.241867            0.24270   \n",
       "2            -108.30988           -0.846171           -0.84490   \n",
       "3              39.69794            0.310140            0.31147   \n",
       "4              54.80246            0.428144            0.43740   \n",
       "...                 ...                 ...                ...   \n",
       "3805          123.10148            0.961730            0.96225   \n",
       "3806          105.80358            0.826590            0.82789   \n",
       "3807          114.60787            0.895374            0.90642   \n",
       "3808          121.94998            0.952734            0.95470   \n",
       "3809          -98.50887           -0.769601           -0.76820   \n",
       "\n",
       "      orientation_Y_min  orientation_Y_median  orientation_Y_skew  \\\n",
       "0              -0.63456             -0.634270            0.603197   \n",
       "1               0.24074              0.241890           -0.422565   \n",
       "2              -0.84779             -0.846210           -0.161786   \n",
       "3               0.30943              0.310115            1.230981   \n",
       "4               0.41646              0.428865           -0.242538   \n",
       "...                 ...                   ...                 ...   \n",
       "3805            0.96140              0.961650            0.619900   \n",
       "3806            0.82522              0.826590           -0.014884   \n",
       "3807            0.88360              0.895975           -0.164749   \n",
       "3808            0.95067              0.952310            0.097948   \n",
       "3809           -0.77039             -0.769690            0.735398   \n",
       "\n",
       "      orientation_Z_sum  orientation_Z_mean  orientation_Z_max  \\\n",
       "0            -13.500690           -0.105474          -0.104610   \n",
       "1              4.051239            0.031650           0.032341   \n",
       "2            -16.559440           -0.129371          -0.128520   \n",
       "3              4.986241            0.038955           0.039799   \n",
       "4              7.687225            0.060056           0.061771   \n",
       "...                 ...                 ...                ...   \n",
       "3805          18.520330            0.144690           0.145550   \n",
       "3806          16.625920            0.129890           0.130080   \n",
       "3807          17.943660            0.140185           0.144040   \n",
       "3808          18.183740            0.142060           0.144370   \n",
       "3809         -10.734917           -0.083867          -0.082672   \n",
       "\n",
       "      orientation_Z_min  orientation_Z_median  orientation_Z_skew  \\\n",
       "0             -0.106140             -0.105500            0.193309   \n",
       "1              0.030504              0.031689           -0.517180   \n",
       "2             -0.130300             -0.129405           -0.034406   \n",
       "3              0.037922              0.038889            0.097680   \n",
       "4              0.058247              0.060113           -0.092397   \n",
       "...                 ...                   ...                 ...   \n",
       "3805           0.143370              0.144740           -0.644989   \n",
       "3806           0.129630              0.129900           -0.258467   \n",
       "3807           0.135370              0.139735           -0.132593   \n",
       "3808           0.139910              0.141975            0.132153   \n",
       "3809          -0.085207             -0.083863           -0.010013   \n",
       "\n",
       "      angular_velocity_X_sum  angular_velocity_X_mean  angular_velocity_X_max  \\\n",
       "0                  -0.317527                -0.002481                0.107650   \n",
       "1                   0.589410                 0.004605                0.283420   \n",
       "2                   0.338645                 0.002646                0.141920   \n",
       "3                   0.079866                 0.000624                0.519130   \n",
       "4                   0.892016                 0.006969                0.080904   \n",
       "...                      ...                      ...                     ...   \n",
       "3805                0.322397                 0.002519                0.483080   \n",
       "3806               -0.057970                -0.000453                0.008284   \n",
       "3807                4.075327                 0.031838                0.638570   \n",
       "3808                0.144381                 0.001128                0.401700   \n",
       "3809               -0.511327                -0.003995                0.106110   \n",
       "\n",
       "      angular_velocity_X_min  angular_velocity_X_median  \\\n",
       "0                  -0.160410                  -0.005082   \n",
       "1                  -0.254800                   0.010344   \n",
       "2                  -0.152710                  -0.003120   \n",
       "3                  -0.401520                   0.006709   \n",
       "4                  -0.104070                   0.010157   \n",
       "...                      ...                        ...   \n",
       "3805               -0.430190                  -0.005029   \n",
       "3806               -0.008044                  -0.000334   \n",
       "3807               -0.502510                   0.038775   \n",
       "3808               -0.307450                  -0.017597   \n",
       "3809               -0.150910                   0.006451   \n",
       "\n",
       "      angular_velocity_X_skew  angular_velocity_Y_sum  \\\n",
       "0                   -0.342643               -0.423172   \n",
       "1                   -0.136062               -0.992868   \n",
       "2                    0.205228               -1.181655   \n",
       "3                   -0.003575               -0.358926   \n",
       "4                   -0.394054                5.901899   \n",
       "...                       ...                     ...   \n",
       "3805                 0.073135                1.085290   \n",
       "3806                 0.023644                0.436392   \n",
       "3807                 0.236030               13.283490   \n",
       "3808                 0.339035               -3.752277   \n",
       "3809                -0.403503                0.063414   \n",
       "\n",
       "      angular_velocity_Y_mean  angular_velocity_Y_max  angular_velocity_Y_min  \\\n",
       "0                   -0.003306                0.072698               -0.079404   \n",
       "1                   -0.007757                0.112080               -0.134330   \n",
       "2                   -0.009232                0.091946               -0.107810   \n",
       "3                   -0.002804                0.135780               -0.168150   \n",
       "4                    0.046109                0.083764                0.008231   \n",
       "...                       ...                     ...                     ...   \n",
       "3805                 0.008479                0.173090               -0.179140   \n",
       "3806                 0.003409                0.011729               -0.004850   \n",
       "3807                 0.103777                0.297520               -0.264770   \n",
       "3808                -0.029315                0.114060               -0.203420   \n",
       "3809                 0.000495                0.165260               -0.087124   \n",
       "\n",
       "      angular_velocity_Y_median  angular_velocity_Y_skew  \\\n",
       "0                     -0.004037                 0.016396   \n",
       "1                     -0.006330                -0.246493   \n",
       "2                     -0.010879                -0.077528   \n",
       "3                      0.000518                -0.320948   \n",
       "4                      0.047561                -0.218780   \n",
       "...                         ...                      ...   \n",
       "3805                   0.010954                -0.011865   \n",
       "3806                   0.003386                 0.038432   \n",
       "3807                   0.113335                -0.959642   \n",
       "3808                  -0.032655                -0.093687   \n",
       "3809                  -0.005610                 1.413377   \n",
       "\n",
       "      angular_velocity_Z_sum  angular_velocity_Z_mean  angular_velocity_Z_max  \\\n",
       "0                   0.964051                 0.007532                0.051720   \n",
       "1                   0.794404                 0.006206                0.129150   \n",
       "2                   3.582611                 0.027989                0.088730   \n",
       "3                   1.009490                 0.007887                0.085345   \n",
       "4                 -18.225288                -0.142385               -0.063372   \n",
       "...                      ...                      ...                     ...   \n",
       "3805               -2.725986                -0.021297                0.082269   \n",
       "3806               -0.053218                -0.000416                0.006290   \n",
       "3807              -43.299620                -0.338278               -0.129720   \n",
       "3808               11.339753                 0.088592                0.268660   \n",
       "3809                0.287759                 0.002248                0.121930   \n",
       "\n",
       "      angular_velocity_Z_min  angular_velocity_Z_median  \\\n",
       "0                  -0.030181                   0.006842   \n",
       "1                  -0.121610                   0.003538   \n",
       "2                  -0.015697                   0.028323   \n",
       "3                  -0.073414                   0.005856   \n",
       "4                  -0.213940                  -0.146670   \n",
       "...                      ...                        ...   \n",
       "3805               -0.162820                  -0.013893   \n",
       "3806               -0.007287                  -0.000213   \n",
       "3807               -0.596830                  -0.333705   \n",
       "3808               -0.068827                   0.093768   \n",
       "3809               -0.142740                   0.000250   \n",
       "\n",
       "      angular_velocity_Z_skew  linear_acceleration_X_sum  \\\n",
       "0                    0.126373                  33.717542   \n",
       "1                    0.004702                  15.599035   \n",
       "2                    0.069123                  19.163063   \n",
       "3                   -0.272105                  25.829186   \n",
       "4                    0.085068                 -11.029920   \n",
       "...                       ...                        ...   \n",
       "3805                -0.397359                  34.135889   \n",
       "3806                -0.243886                  17.468924   \n",
       "3807                -0.200093                  -7.828190   \n",
       "3808                 0.090947                  28.027417   \n",
       "3809                -0.261525                  19.288531   \n",
       "\n",
       "      linear_acceleration_X_mean  linear_acceleration_X_max  \\\n",
       "0                       0.263418                    2.85380   \n",
       "1                       0.121867                    5.10020   \n",
       "2                       0.149711                    1.85330   \n",
       "3                       0.201791                    4.20320   \n",
       "4                      -0.086171                    0.82891   \n",
       "...                          ...                        ...   \n",
       "3805                    0.266687                    4.61280   \n",
       "3806                    0.136476                    0.21648   \n",
       "3807                   -0.061158                    7.80970   \n",
       "3808                    0.218964                    7.85800   \n",
       "3809                    0.150692                    4.42750   \n",
       "\n",
       "      linear_acceleration_X_min  linear_acceleration_X_median  \\\n",
       "0                     -1.864400                      0.231665   \n",
       "1                     -3.193400                      0.003571   \n",
       "2                     -2.593000                      0.174515   \n",
       "3                     -3.793400                      0.317205   \n",
       "4                     -1.269600                     -0.054043   \n",
       "...                         ...                           ...   \n",
       "3805                  -5.557700                      0.390665   \n",
       "3806                   0.061417                      0.136950   \n",
       "3807                 -10.479000                      0.165465   \n",
       "3808                  -6.356000                      0.266105   \n",
       "3809                  -3.804600                      0.244865   \n",
       "\n",
       "      linear_acceleration_X_skew  linear_acceleration_Y_sum  \\\n",
       "0                       0.132684                 381.976947   \n",
       "1                       0.759101                 354.328697   \n",
       "2                      -0.480996                 369.503305   \n",
       "3                      -0.210587                 340.214058   \n",
       "4                      -0.375568                 381.631730   \n",
       "...                          ...                        ...   \n",
       "3805                   -0.388012                 351.382690   \n",
       "3806                   -0.038278                 371.239000   \n",
       "3807                   -0.122274                 468.580635   \n",
       "3808                   -0.153116                 393.660794   \n",
       "3809                   -0.279286                 284.458005   \n",
       "\n",
       "      linear_acceleration_Y_mean  linear_acceleration_Y_max  \\\n",
       "0                       2.984195                     5.3864   \n",
       "1                       2.768193                     6.6850   \n",
       "2                       2.886745                     6.2105   \n",
       "3                       2.657922                    11.7430   \n",
       "4                       2.981498                     4.8181   \n",
       "...                          ...                        ...   \n",
       "3805                    2.745177                     7.5051   \n",
       "3806                    2.900305                     2.9568   \n",
       "3807                    3.660786                    16.4520   \n",
       "3808                    3.075475                    11.8520   \n",
       "3809                    2.222328                     5.8675   \n",
       "\n",
       "      linear_acceleration_Y_min  linear_acceleration_Y_median  \\\n",
       "0                      0.075417                       3.40755   \n",
       "1                     -2.149200                       2.75010   \n",
       "2                     -1.254000                       3.03375   \n",
       "3                     -5.825100                       3.00885   \n",
       "4                      0.342070                       3.13565   \n",
       "...                         ...                           ...   \n",
       "3805                  -1.305500                       2.58605   \n",
       "3806                   2.837900                       2.90145   \n",
       "3807                  -9.657400                       3.65475   \n",
       "3808                  -4.531000                       2.27130   \n",
       "3809                  -2.714200                       2.74810   \n",
       "\n",
       "      linear_acceleration_Y_skew  linear_acceleration_Z_sum  \\\n",
       "0                      -0.364964               -1193.010000   \n",
       "1                      -0.183139               -1201.779100   \n",
       "2                      -0.266815               -1202.660200   \n",
       "3                      -0.117380               -1209.749000   \n",
       "4                      -0.534365               -1196.798500   \n",
       "...                          ...                        ...   \n",
       "3805                    0.101470               -1211.558256   \n",
       "3806                   -0.140696               -1199.007600   \n",
       "3807                    0.162879               -1176.635710   \n",
       "3808                    0.224241               -1196.216610   \n",
       "3809                   -0.442227               -1223.778500   \n",
       "\n",
       "      linear_acceleration_Z_mean  linear_acceleration_Z_max  \\\n",
       "0                      -9.320391                   -6.26810   \n",
       "1                      -9.388899                   -2.74490   \n",
       "2                      -9.395783                   -5.74420   \n",
       "3                      -9.451164                   -0.55910   \n",
       "4                      -9.349988                   -7.44900   \n",
       "...                          ...                        ...   \n",
       "3805                   -9.465299                    4.95690   \n",
       "3806                   -9.367247                   -9.31850   \n",
       "3807                   -9.192466                    3.08360   \n",
       "3808                   -9.345442                   -0.60391   \n",
       "3809                   -9.560770                   -7.60010   \n",
       "\n",
       "      linear_acceleration_Z_min  linear_acceleration_Z_median  \\\n",
       "0                      -12.5120                      -9.42995   \n",
       "1                      -16.9280                      -9.41380   \n",
       "2                      -12.4990                      -9.37440   \n",
       "3                      -19.8450                      -9.16170   \n",
       "4                      -10.9750                      -9.33280   \n",
       "...                         ...                           ...   \n",
       "3805                   -22.2530                      -9.65750   \n",
       "3806                    -9.4094                      -9.36740   \n",
       "3807                   -24.6860                      -9.53715   \n",
       "3808                   -17.3750                      -9.40045   \n",
       "3809                   -13.3650                      -9.46180   \n",
       "\n",
       "      linear_acceleration_Z_skew  \n",
       "0                       0.067391  \n",
       "1                      -0.126848  \n",
       "2                       0.085877  \n",
       "3                      -0.210103  \n",
       "4                       0.106132  \n",
       "...                          ...  \n",
       "3805                    0.205344  \n",
       "3806                    0.060870  \n",
       "3807                   -0.044238  \n",
       "3808                    0.108252  \n",
       "3809                   -0.881500  \n",
       "\n",
       "[3810 rows x 70 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "dummy_train, dummy_test, dummy_ytrain, dummy_ytest = train_test_split(XXX, XXY,\n",
    "                                                    stratify=XXY,\n",
    "                                                    test_size=0.33, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0, 127],\n",
       "       [  1, 522],\n",
       "       [  2, 243],\n",
       "       [  3,  14],\n",
       "       [  4, 206],\n",
       "       [  5, 490],\n",
       "       [  6, 199],\n",
       "       [  7, 344],\n",
       "       [  8, 407]], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(np.unique(dummy_ytrain, return_counts=True)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,  62],\n",
       "       [  1, 257],\n",
       "       [  2, 120],\n",
       "       [  3,   7],\n",
       "       [  4, 102],\n",
       "       [  5, 242],\n",
       "       [  6,  98],\n",
       "       [  7, 170],\n",
       "       [  8, 200]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(np.unique(dummy_ytest, return_counts=True)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "def get_xgb_imp(xgb):\n",
    "    imp_vals = xgb.get_fscore()\n",
    "    feats_imp = pd.DataFrame(imp_vals,index=np.arange(2)).T\n",
    "    feats_imp.iloc[:,0]= feats_imp.index    \n",
    "    feats_imp.columns=['feature','importance']\n",
    "    feats_imp.sort_values('importance',inplace=True,ascending=False)\n",
    "    feats_imp.reset_index(drop=True,inplace=True)\n",
    "    return feats_imp\n",
    "\n",
    "def quick_model(train, valid, ytrain, yvalid):\n",
    "    weights_dict = {0:1.3, 1:1, 2:1.2, 3:2, 4:1.3, 5:1, 6:1.5, 7:1.2, 8:1}\n",
    "    ytrain_weights = np.copy(ytrain)\n",
    "    yvalid_weights = np.copy(yvalid)\n",
    "    for k, v in weights_dict.items(): \n",
    "        ytrain_weights[ytrain==k]=v\n",
    "        yvalid_weights[yvalid==k]=v\n",
    "    \n",
    "    feat_names = train.columns.values\n",
    "\n",
    "    xg_train = xgb.DMatrix(train, label=ytrain, weight=ytrain_weights)\n",
    "    xg_test = xgb.DMatrix(valid, label=yvalid, weight=yvalid_weights)\n",
    "\n",
    "    # setup parameters for xgboost\n",
    "    param = {'objective':'multi:softprob', 'max_depth':15, 'silent':1, 'nthread':-1, 'num_class':9, 'subsample':0.85, \n",
    "             'colsample_bytree':0.7, 'learning_rate':0.05, 'eval_metric':['mlogloss', 'merror'], 'n_jobs': -1,\n",
    "            'colsample_bylevel':0.6, 'tree_method':'hist', 'seed':10, 'grow_policy':'lossguide', 'max_delta_step':1,\n",
    "            'max_bin':512}\n",
    "\n",
    "    watchlist = [(xg_train, 'train'), (xg_test, 'test')]\n",
    "    num_round = 100\n",
    "    model = xgb.train(param, xg_train, num_round, watchlist, early_stopping_rounds=20, verbose_eval=10)\n",
    "    # get prediction\n",
    "    pred_probs = model.predict(xg_test)\n",
    "    pred = np.argmax(pred_probs, 1)\n",
    "    error_rate = np.sum(pred != yvalid) / yvalid.shape[0]\n",
    "    print('Test error using softprob = {}'.format(error_rate))\n",
    "\n",
    "    print(skm.accuracy_score(y_pred=pred, y_true=yvalid))\n",
    "    print(skm.confusion_matrix(y_pred=pred, y_true=yvalid))\n",
    "    return model, feat_names, xg_train, xg_test, pred, pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:2.1375\ttrain-merror:0.226422\ttest-mlogloss:2.14645\ttest-merror:0.327273\n",
      "Multiple eval metrics have been passed: 'test-merror' will be used for early stopping.\n",
      "\n",
      "Will train until test-merror hasn't improved in 20 rounds.\n",
      "[10]\ttrain-mlogloss:1.57506\ttrain-merror:0.069369\ttest-mlogloss:1.68153\ttest-merror:0.21502\n",
      "[20]\ttrain-mlogloss:1.0937\ttrain-merror:0.023383\ttest-mlogloss:1.29887\ttest-merror:0.186561\n",
      "[30]\ttrain-mlogloss:0.722813\ttrain-merror:0.007794\ttest-mlogloss:1.00785\ttest-merror:0.167589\n",
      "[40]\ttrain-mlogloss:0.484351\ttrain-merror:0.003897\ttest-mlogloss:0.810926\ttest-merror:0.156522\n",
      "[50]\ttrain-mlogloss:0.335085\ttrain-merror:0.000779\ttest-mlogloss:0.685116\ttest-merror:0.149407\n",
      "[60]\ttrain-mlogloss:0.237882\ttrain-merror:0.00039\ttest-mlogloss:0.599325\ttest-merror:0.150198\n",
      "[70]\ttrain-mlogloss:0.173756\ttrain-merror:0\ttest-mlogloss:0.540165\ttest-merror:0.148617\n",
      "[80]\ttrain-mlogloss:0.130937\ttrain-merror:0\ttest-mlogloss:0.499974\ttest-merror:0.144664\n",
      "[90]\ttrain-mlogloss:0.101374\ttrain-merror:0\ttest-mlogloss:0.470318\ttest-merror:0.141502\n",
      "[99]\ttrain-mlogloss:0.082315\ttrain-merror:0\ttest-mlogloss:0.451196\ttest-merror:0.141502\n",
      "Test error using softprob = 0.1383147853736089\n",
      "0.8616852146263911\n",
      "[[ 48   7   1   0   2   0   0   1   3]\n",
      " [  3 220   3   0   5   7   4  10   5]\n",
      " [  1   4 100   0   0   3   0   4   8]\n",
      " [  0   0   0   2   0   1   1   0   3]\n",
      " [  0   5   0   0  91   1   0   1   4]\n",
      " [  4   8   4   0   3 211   5   2   5]\n",
      " [  1   3   0   0   0   3  90   1   0]\n",
      " [  2   4   2   0   0   2   3 155   2]\n",
      " [  1   5   0   0   0  17   0  10 167]]\n"
     ]
    }
   ],
   "source": [
    "model, feat_names, xg_train, xg_test, pred, pred_probs = quick_model(train=dummy_train.copy(),\n",
    "                                                                    valid=dummy_test.copy(),\n",
    "                                                                    ytrain=dummy_ytrain.copy(),\n",
    "                                                                    yvalid=dummy_ytest.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from hyperopt import hp, tpe, STATUS_OK, fmin, Trials\n",
    "from hyperopt.fmin import fmin\n",
    "from hyperopt.pyll.stochastic import sample\n",
    "\n",
    "class xgbclass():\n",
    "    \"\"\" mode = c['C', 'R'] (C==classification, R==regression)\n",
    "    self.cust_score\n",
    "    \"\"\"\n",
    "    \n",
    "    ################################################### INIT ###############################################\n",
    "    def __init__(self, train, valid, ytrain, yvalid, mode=['C']):\n",
    "        self.mode=mode\n",
    "        self.randomseed = 1\n",
    "        self.N_FOLDS = 3\n",
    "        self.trials = Trials()\n",
    "        self.MAX_EVALS = 10\n",
    "        self.yvalid = yvalid\n",
    "        \n",
    "        feat_names = train.columns.values\n",
    "\n",
    "        weights_dict = {0:1.3, 1:1, 2:1.2, 3:2, 4:1.3, 5:1, 6:1.5, 7:1.2, 8:1}\n",
    "        \n",
    "        ytrain_weights = np.copy(ytrain)\n",
    "        yvalid_weights = np.copy(yvalid)\n",
    "        for k, v in weights_dict.items(): \n",
    "            ytrain_weights[ytrain==k]=v\n",
    "            yvalid_weights[yvalid==k]=v\n",
    "            \n",
    "        self.dtrain = xgb.DMatrix(data=train, feature_names=train.columns.values, \n",
    "                                  label=ytrain, weight=ytrain_weights)\n",
    "        self.dtest = xgb.DMatrix(data=valid, feature_names=valid.columns.values, \n",
    "                                 label=yvalid, weight=yvalid_weights)\n",
    "\n",
    "        self.optimize()\n",
    "    ####################################################################################################\n",
    "    \n",
    "    def cust_score(self, preds, dtrain):\n",
    "        labels = dtrain.get_label()\n",
    "        score = skm.log_loss(y_pred=preds, y_true=labels)\n",
    "        return 'score', score\n",
    "    \n",
    "    # function to be minimized and sent to the optimize function of hyperopt\n",
    "    def xgb_score(self, params):\n",
    "        # Make sure parameters that need to be integers are integers\n",
    "        for parameter_name in ['max_depth', 'max_bin']:\n",
    "            params[parameter_name] = int(params[parameter_name])\n",
    "            \n",
    "        ## to tune on cv results (the right method)\n",
    "        xgb_cv = xgb.cv(params=params, num_boost_round=50, nfold=self.N_FOLDS, dtrain=self.dtrain, early_stopping_rounds=10,\n",
    "                       maximize=False, stratified=True, verbose_eval=25, metrics=['merror', 'mlogloss'])#, feval=self.cust_score \n",
    "        num_rounds = len(xgb_cv['test-merror-mean'])\n",
    "        bst_score = xgb_cv['test-merror-mean'][num_rounds-1]\n",
    "        print('evaluation metric score of iteration is: ', bst_score, '\\n')\n",
    "        print('validation accuracy is: ', 1-xgb_cv['test-merror-mean'][num_rounds-1])\n",
    "        return {'loss': bst_score, 'status': STATUS_OK, 'params': params, 'num_boost': num_rounds-1, \n",
    "                'valid_acc': 1-xgb_cv['test-merror-mean'][num_rounds-1]}        \n",
    "    \n",
    "    # function to do hyperparameter tuning with hyperopt (bayesian based method)\n",
    "    def optimize(self):\n",
    "        # space to be traversed for the hyperopt function\n",
    "        space = {\n",
    "            'base_score' : hp.uniform('base_score', 0.45, 0.55),\n",
    "             #'max_depth' : hp.choice('max_depth', np.arange(3, 8, dtype=int)),\n",
    "            'max_depth' : hp.quniform('max_depth', 4, 15, 1),\n",
    "             'min_child_weight' : hp.quniform('min_child_weight', 2, 10, 0.1),\n",
    "             'subsample' : hp.uniform('subsample', 0.7, 0.95),\n",
    "            'alpha': hp.uniform('alpha', 0, 0.1),\n",
    "             'gamma' : hp.uniform('gamma', 0, 0.1),\n",
    "            'lambda' : hp.uniform ('lambda', 0, 0.1),\n",
    "             'colsample_bytree' : hp.uniform('colsample_bytree', 0.7, 0.85),\n",
    "            'colsample_bylevel': hp.uniform('colsample_bylevel', 0.6, 0.85),\n",
    "            'objective' : 'multi:softprob',\n",
    "            'num_class':9,\n",
    "            'grow_policy': 'lossguide', #hp.choice('grow_policy', ['depthwise', 'lossguide']),\n",
    "            'max_bin': hp.quniform('max_bin', 250, 500, 25),\n",
    "            'max_delta_step': hp.quniform('max_delta_step', 0, 5, 1),\n",
    "            'booster': 'gbtree', #hp.choice('booster', ['gbtree', 'dart']),\n",
    "            'tree_method': 'exact', #hp.choice('tree_method', ['exact', '']),\n",
    "            'n_jobs': -1,\n",
    "            'learning_rate':0.1\n",
    "        }\n",
    "        self.best = fmin(self.xgb_score, space, algo=tpe.suggest, trials=self.trials, max_evals=self.MAX_EVALS,\n",
    "                    rstate=np.random.RandomState(self.randomseed))\n",
    "        self.num_rounds = self.trials.best_trial['result']['num_boost']\n",
    "        return None # results of all the iterations, the best one and the number of rounds for the best run\n",
    "    \n",
    "    # train and return a model with the best params\n",
    "    def xgb_train_and_predict(self):\n",
    "        self.model = xgb.train(self.trials.best_trial['result']['params'], dtrain=self.dtrain, maximize=False, \n",
    "                               num_boost_round=self.num_rounds) #, feval=self.cust_score)\n",
    "        self.predprobs = self.model.predict(self.dtest)\n",
    "        self.pred = np.asarray([np.argmax(line) for line in self.predprobs])\n",
    "        print(skm.accuracy_score(y_pred=self.pred, y_true=self.yvalid), '\\n')\n",
    "        print(skm.confusion_matrix(y_true=self.yvalid, y_pred=xgbmod.pred), '\\n')\n",
    "        return None\n",
    "    \n",
    "    # function to return cv results for train dataset (recall/precision/f1/accuracy)\n",
    "    def xgb_cv(self):\n",
    "        best=self.trials.best_trial['result']['params']\n",
    "        model = xgb.XGBClassifier(**best, silent=True)\n",
    "        xgb_cv_scores = sklearn.model_selection.cross_val_predict(model, self.dtrain, self.trainres, cv=5)\n",
    "        print('recall: ', sklearn.metrics.recall_score(y_pred=xgb_cv_scores, y_true=self.trainres))\n",
    "        print('precision: ', sklearn.metrics.precision_score(y_pred=xgb_cv_scores, y_true=self.trainres))\n",
    "        print('f1: ', sklearn.metrics.f1_score(y_pred=xgb_cv_scores, y_true=self.trainres))\n",
    "        print('accuracy: ', sklearn.metrics.accuracy_score(y_pred=xgb_cv_scores, y_true=self.trainres))\n",
    "        return None\n",
    "    \n",
    "    def get_xgb_imp(self):\n",
    "        imp_vals = self.model.get_fscore()\n",
    "        feats_imp = pd.DataFrame(imp_vals,index=np.arange(2)).T\n",
    "        feats_imp.iloc[:,0]= feats_imp.index\n",
    "        feats_imp.columns=['feature','importance']\n",
    "        feats_imp.sort_values('importance',inplace=True,ascending=False)\n",
    "        feats_imp.reset_index(drop=True,inplace=True)\n",
    "        return feats_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.330054+0.0182989\ttrain-mlogloss:2.05138+0.00389012\ttest-merror:0.393254+0.0205168\ttest-mlogloss:2.06561+0.00416511\n",
      "\n",
      "[25]\ttrain-merror:0.082618+0.000906007\ttrain-mlogloss:0.547831+0.01529\ttest-merror:0.229904+0.0187176\ttest-mlogloss:0.819828+0.0448178\n",
      "\n",
      "[49]\ttrain-merror:0.0290343+0.00121875\ttrain-mlogloss:0.28327+0.00803519\ttest-merror:0.210058+0.016436\ttest-mlogloss:0.654663+0.0538614\n",
      "\n",
      "evaluation metric score of iteration is: \n",
      "0.21005766666666667\n",
      "validation accuracy is: \n",
      "0.7899423333333333\n",
      "[0]\ttrain-merror:0.289952+0.00535177\ttrain-mlogloss:2.08427+0.000877262\ttest-merror:0.404585+0.0231592\ttest-mlogloss:2.10267+0.00197732\n",
      "\n",
      "[25]\ttrain-merror:0.0126677+0.00101644\ttrain-mlogloss:0.407789+0.00490342\ttest-merror:0.19254+0.0136963\ttest-mlogloss:0.780082+0.0504018\n",
      "\n",
      "[49]\ttrain-merror:0.00117033+0.000829201\ttrain-mlogloss:0.130321+0.00212302\ttest-merror:0.180439+0.0194919\ttest-mlogloss:0.570148+0.0659364\n",
      "\n",
      "evaluation metric score of iteration is: \n",
      "0.18043866666666666\n",
      "validation accuracy is: \n",
      "0.8195613333333334\n",
      "[0]\ttrain-merror:0.353867+0.00932956\ttrain-mlogloss:2.05117+0.00146615\ttest-merror:0.408706+0.0273722\ttest-mlogloss:2.06651+0.00554245\n",
      "\n",
      "[25]\ttrain-merror:0.127437+0.00833584\ttrain-mlogloss:0.668751+0.0164188\ttest-merror:0.250575+0.0127077\ttest-mlogloss:0.902445+0.0493061\n",
      "\n",
      "[49]\ttrain-merror:0.0672283+0.00830764\ttrain-mlogloss:0.391268+0.0153238\ttest-merror:0.21822+0.0154379\ttest-mlogloss:0.713478+0.0501018\n",
      "\n",
      "evaluation metric score of iteration is: \n",
      "0.21822\n",
      "validation accuracy is: \n",
      "0.78178\n",
      "[0]\ttrain-merror:0.261496+0.00747165\ttrain-mlogloss:2.08117+0.000879078\ttest-merror:0.361664+0.0203079\ttest-mlogloss:2.10022+0.00342477\n",
      "\n",
      "[25]\ttrain-merror:0.00370367+0.00099811\ttrain-mlogloss:0.348489+0.00403016\ttest-merror:0.188275+0.021098\ttest-mlogloss:0.764524+0.0495294\n",
      "\n",
      "[49]\ttrain-merror:0.000194333+0.000274829\ttrain-mlogloss:0.0957063+0.00200094\ttest-merror:0.175003+0.0199068\ttest-mlogloss:0.554547+0.0674033\n",
      "\n",
      "evaluation metric score of iteration is: \n",
      "0.17500300000000002\n",
      "validation accuracy is: \n",
      "0.824997\n",
      "[0]\ttrain-merror:0.310034+0.0140044\ttrain-mlogloss:2.04473+0.00125108\ttest-merror:0.367802+0.0224778\ttest-mlogloss:2.06142+0.00496946\n",
      "\n",
      "[25]\ttrain-merror:0.0880743+0.00604044\ttrain-mlogloss:0.572086+0.0202618\ttest-merror:0.228356+0.0180281\ttest-mlogloss:0.838011+0.0417921\n",
      "\n",
      "[49]\ttrain-merror:0.0387747+0.00509482\ttrain-mlogloss:0.30369+0.0138874\ttest-merror:0.206126+0.0192602\ttest-mlogloss:0.664161+0.0529792\n",
      "\n",
      "evaluation metric score of iteration is: \n",
      "0.20612566666666665\n",
      "validation accuracy is: \n",
      "0.7938743333333333\n",
      "[0]\ttrain-merror:0.296573+0.0115211\ttrain-mlogloss:2.01928+0.00370356\ttest-merror:0.367413+0.0220314\ttest-mlogloss:2.03754+0.0072716\n",
      "\n",
      "[25]\ttrain-merror:0.123531+0.00728406\ttrain-mlogloss:0.651133+0.0188677\ttest-merror:0.250966+0.0153283\ttest-mlogloss:0.890715+0.0493608\n",
      "\n",
      "[49]\ttrain-merror:0.0637173+0.0101041\ttrain-mlogloss:0.382622+0.0206956\ttest-merror:0.217458+0.0143761\ttest-mlogloss:0.708216+0.0525429\n",
      "\n",
      "evaluation metric score of iteration is: \n",
      "0.21745766666666666\n",
      "validation accuracy is: \n",
      "0.7825423333333333\n",
      "[0]\ttrain-merror:0.322877+0.00472778\ttrain-mlogloss:2.08949+0.00120271\ttest-merror:0.385441+0.025563\ttest-mlogloss:2.10331+0.00207281\n",
      "\n",
      "[25]\ttrain-merror:0.040143+0.00153185\ttrain-mlogloss:0.483702+0.00604458\ttest-merror:0.20381+0.0183944\ttest-mlogloss:0.801786+0.0460528\n",
      "\n",
      "[49]\ttrain-merror:0.00623467+0.000723212\ttrain-mlogloss:0.18564+0.00316867\ttest-merror:0.179246+0.0178781\ttest-mlogloss:0.59103+0.0583107\n",
      "\n",
      "evaluation metric score of iteration is: \n",
      "0.1792463333333333\n",
      "validation accuracy is: \n",
      "0.8207536666666667\n",
      "[0]\ttrain-merror:0.221544+0.00824854\ttrain-mlogloss:2.02065+0.00217401\ttest-merror:0.335878+0.0278957\ttest-mlogloss:2.05066+0.0033358\n",
      "\n",
      "[25]\ttrain-merror:0.00740467+0.000273809\ttrain-mlogloss:0.314981+0.00432921\ttest-merror:0.182779+0.0252923\ttest-mlogloss:0.714127+0.0506509\n",
      "\n",
      "[49]\ttrain-merror:0.000974333+0.000275311\ttrain-mlogloss:0.107989+0.00133611\ttest-merror:0.172638+0.0208669\ttest-mlogloss:0.554541+0.0672055\n",
      "\n",
      "evaluation metric score of iteration is: \n",
      "0.1726383333333333\n",
      "validation accuracy is: \n",
      "0.8273616666666667\n",
      "[0]\ttrain-merror:0.312358+0.0148325\ttrain-mlogloss:2.01094+0.00423258\ttest-merror:0.376035+0.0232815\ttest-mlogloss:2.02995+0.00485839\n",
      "\n",
      "[25]\ttrain-merror:0.0851603+0.00501118\ttrain-mlogloss:0.548701+0.0107644\ttest-merror:0.224433+0.0226659\ttest-mlogloss:0.813481+0.0490571\n",
      "\n",
      "[49]\ttrain-merror:0.0337127+0.00152012\ttrain-mlogloss:0.293917+0.00677393\ttest-merror:0.212379+0.0141074\ttest-mlogloss:0.658495+0.0556945\n",
      "\n",
      "evaluation metric score of iteration is: \n",
      "0.21237933333333334\n",
      "validation accuracy is: \n",
      "0.7876206666666666\n",
      "[0]\ttrain-merror:0.267936+0.00702636\ttrain-mlogloss:1.99885+0.00262499\ttest-merror:0.342942+0.0165147\ttest-mlogloss:2.01989+0.00701694\n",
      "\n",
      "[25]\ttrain-merror:0.0522227+0.00359853\ttrain-mlogloss:0.455275+0.00830589\ttest-merror:0.217066+0.0141954\ttest-mlogloss:0.774494+0.0470327\n",
      "\n",
      "[49]\ttrain-merror:0.0128613+0.000965387\ttrain-mlogloss:0.213765+0.00451347\ttest-merror:0.204579+0.0111702\ttest-mlogloss:0.621179+0.0589888\n",
      "\n",
      "evaluation metric score of iteration is: \n",
      "0.20457933333333334\n",
      "validation accuracy is: \n",
      "0.7954206666666667\n",
      "100%|███████████████████████████████████████████████████| 10/10 [01:34<00:00,  9.23s/it, best loss: 0.1726383333333333]\n"
     ]
    }
   ],
   "source": [
    "xgbmod = xgbclass(train=dummy_train.copy(), valid=dummy_test.copy(), ytrain=dummy_ytrain.copy(), yvalid=dummy_ytest.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.856120826709062 \n",
      "\n",
      "[[ 47   6   0   0   2   0   0   2   5]\n",
      " [  4 215   3   0   4   5   4  13   9]\n",
      " [  1   4  97   0   0   6   0   3   9]\n",
      " [  0   0   0   3   0   1   1   0   2]\n",
      " [  0   5   0   0  91   2   0   1   3]\n",
      " [  3   8   3   0   2 212   5   3   6]\n",
      " [  0   3   0   0   0   3  91   1   0]\n",
      " [  2   3   2   0   0   2   2 157   2]\n",
      " [  2   5   1   0   0  17   0  11 164]] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.07739865491608339,\n",
       " 'base_score': 0.45148537679535017,\n",
       " 'colsample_bylevel': 0.8219456271136347,\n",
       " 'colsample_bytree': 0.770458686268976,\n",
       " 'gamma': 0.0562367981858677,\n",
       " 'lambda': 0.0816621449648167,\n",
       " 'max_bin': 300.0,\n",
       " 'max_delta_step': 2.0,\n",
       " 'max_depth': 11.0,\n",
       " 'min_child_weight': 2.8000000000000003,\n",
       " 'subsample': 0.8624294820509246}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1\n",
       "0  0   59\n",
       "1  1  249\n",
       "2  2  106\n",
       "3  3    3\n",
       "4  4   99\n",
       "5  5  248\n",
       "6  6  103\n",
       "7  7  191\n",
       "8  8  200"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1cd96a24ba8>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbmod.xgb_train_and_predict()\n",
    "\n",
    "xgbmod.best\n",
    "model2=xgbmod.model\n",
    "\n",
    "pd.DataFrame(np.array(np.unique(xgbmod.pred, return_counts=True)).T)\n",
    "\n",
    "feature_importance_df1 = xgbmod.get_xgb_imp()\n",
    "xgb.plot_importance(model, max_num_features = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.199532\ttest-merror:0.303557\n",
      "Multiple eval metrics have been passed: 'test-merror' will be used for early stopping.\n",
      "\n",
      "Will train until test-merror hasn't improved in 100 rounds.\n",
      "[50]\ttrain-merror:0.046376\ttest-merror:0.167589\n",
      "[100]\ttrain-merror:0.026111\ttest-merror:0.158893\n",
      "[150]\ttrain-merror:0.01403\ttest-merror:0.149407\n",
      "[200]\ttrain-merror:0.008574\ttest-merror:0.147036\n",
      "[250]\ttrain-merror:0.006625\ttest-merror:0.148617\n",
      "[300]\ttrain-merror:0.003897\ttest-merror:0.145455\n",
      "[350]\ttrain-merror:0.002338\ttest-merror:0.143083\n",
      "[400]\ttrain-merror:0.001559\ttest-merror:0.143083\n",
      "[450]\ttrain-merror:0.000779\ttest-merror:0.13834\n",
      "[499]\ttrain-merror:0.00039\ttest-merror:0.137549\n",
      "0.8640699523052464 \n",
      "\n",
      "[[ 51   5   0   0   1   0   0   1   4]\n",
      " [  3 221   2   0   5   5   4  11   6]\n",
      " [  1   5  97   0   0   4   0   3  10]\n",
      " [  0   0   0   4   0   1   1   0   1]\n",
      " [  0   4   0   0  92   1   0   1   4]\n",
      " [  3   7   3   0   3 212   6   2   6]\n",
      " [  0   3   0   0   0   3  91   1   0]\n",
      " [  2   3   2   0   1   2   2 156   2]\n",
      " [  2   5   0   1   0  18   0  11 163]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "params_new = {'alpha': 0.07739865491608339,\n",
    "'base_score': 0.45148537679535017,\n",
    "'colsample_bylevel': 0.8219456271136347,\n",
    "'colsample_bytree': 0.770458686268976,\n",
    "'gamma': 0.0562367981858677,\n",
    "'lambda': 0.0816621449648167,\n",
    "'max_bin': 300,\n",
    "'max_delta_step': 2,\n",
    "'max_depth': 30,\n",
    "'min_child_weight': 2.8000000000000003,\n",
    "'subsample': 0.8624294820509246,\n",
    "'metrics':['mlogloss', 'merror'],\n",
    "'objective' : 'multi:softprob',\n",
    "'num_class':9,\n",
    "'grow_policy': 'lossguide',\n",
    "'learning_rate':0.01,\n",
    "'n_jobs':-1}\n",
    "\n",
    "watchlist = [(xgbmod.dtrain, 'train'), (xgbmod.dtest, 'test')]\n",
    "numround=500\n",
    "model3 = xgb.train(params_new, xgbmod.dtrain, numround, watchlist, maximize=False, \n",
    "                   early_stopping_rounds=100, verbose_eval=50)\n",
    "dummypredprobs = model3.predict(xgbmod.dtest)\n",
    "dummypred = np.asarray([np.argmax(line) for line in dummypredprobs])\n",
    "print(skm.accuracy_score(y_pred=dummypred, y_true=dummy_ytest), '\\n')\n",
    "print(skm.confusion_matrix(y_true=dummy_ytest, y_pred=dummypred), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "X = np.array(dummy_train)\n",
    "XV = np.array(dummy_test)\n",
    "Y = to_categorical(dummy_ytrain)\n",
    "YV = to_categorical(dummy_ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "car = open('./car.pkl','wb')\n",
    "pickle.dump(X, car)\n",
    "pickle.dump(Y, car)\n",
    "pickle.dump(XV, car)\n",
    "pickle.dump(YV, car)\n",
    "car.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import tensorflow as tf\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input, Flatten, LSTM, SpatialDropout1D\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras.callbacks import EarlyStopping\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pickle\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'activation': hp.choice('activation', ['relu', 'sigmoid', 'tanh', 'elu']),\n",
      "        'Dense': hp.choice('Dense', [50, 100, 250, 500, 1000, 2000]),\n",
      "        'activation_1': hp.choice('activation_1', ['relu', 'sigmoid', 'tanh', 'elu']),\n",
      "        'Dropout': hp.uniform('Dropout', 0, 0.7),\n",
      "        'Dense_1': hp.choice('Dense_1', [50, 100, 250, 500, 1000]),\n",
      "        'activation_2': hp.choice('activation_2', ['relu', 'sigmoid', 'tanh', 'elu']),\n",
      "        'activation_3': hp.choice('activation_3', ['true', 'false']),\n",
      "        'Dense_2': hp.choice('Dense_2', [5, 20, 30, 50, 100]),\n",
      "        'activation_4': hp.choice('activation_4', ['relu', 'sigmoid', 'tanh', 'elu']),\n",
      "        'activation_5': hp.choice('activation_5', ['true', 'false']),\n",
      "        'Dense_3': hp.choice('Dense_3', [5, 20, 30, 50, 100]),\n",
      "        'activation_6': hp.choice('activation_6', ['relu', 'sigmoid', 'tanh', 'elu']),\n",
      "        'Dropout_1': hp.uniform('Dropout_1', 0, 0.7),\n",
      "        'activation_7': hp.choice('activation_7', ['softmax']),\n",
      "        'optimizer': hp.choice('optimizer', ['rmsprop', 'adam', 'sgd', 'nadam', 'adadelta']),\n",
      "        'batch_size': hp.choice('batch_size', [5, 10, 20, 50]),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "  1: \n",
      "  2: import pickle\n",
      "  3: \n",
      "  4: # load backup\n",
      "  5: car = open('./car.pkl', 'rb')\n",
      "  6: X = pickle.load(car)\n",
      "  7: Y = pickle.load(car)\n",
      "  8: XV = pickle.load(car)\n",
      "  9: YV = pickle.load(car)\n",
      " 10: car.close()\n",
      " 11: \n",
      " 12: \n",
      " 13: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3:     input_dim = X.shape[1]\n",
      "   4: \n",
      "   5:     model = Sequential()\n",
      "   6:     model.add(Dense(input_dim, input_dim = input_dim , activation=space['activation']))\n",
      "   7:     model.add(BatchNormalization())\n",
      "   8:     model.add(Dense(space['Dense'], activation=space['activation_1']))\n",
      "   9:     model.add(Dropout(space['Dropout']))\n",
      "  10:     model.add(Dense(space['Dense_1'], activation = space['activation_2']))\n",
      "  11:     if space['activation_3'] == 'true':\n",
      "  12:         model.add(Dense(space['Dense_2'], activation = space['activation_4']))\n",
      "  13:     if space['activation_5'] == 'true':\n",
      "  14:         model.add(Dense(space['Dense_3'], activation = space['activation_6']))\n",
      "  15:     model.add(Dropout(space['Dropout_1']))\n",
      "  16:     model.add(Dense(9, activation=space['activation_7']))\n",
      "  17: \n",
      "  18:     model.compile(loss='categorical_crossentropy', optimizer = space['optimizer'], \n",
      "  19:                   metrics=['accuracy'])\n",
      "  20:     model.fit(X, Y, batch_size=space['batch_size'], epochs=5, verbose=2, validation_data=(XV, YV), shuffle=True, callbacks=[EarlyStopping(monitor='val_loss', patience=7, min_delta=0.0001)])\n",
      "  21:     score, acc = model.evaluate(XV, YV, verbose=1)\n",
      "  22:     print('Test accuracy:', acc)\n",
      "  23:     return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n",
      "  24: \n",
      "Train on 2552 samples, validate on 1258 samples\n",
      "Epoch 1/5\n",
      "2552/2552 - 2s - loss: 1.9522 - accuracy: 0.2602 - val_loss: 1.9379 - val_accuracy: 0.2440\n",
      "\n",
      "Epoch 2/5\n",
      "2552/2552 - 2s - loss: 1.9426 - accuracy: 0.2770 - val_loss: 1.9138 - val_accuracy: 0.2663\n",
      "\n",
      "Epoch 3/5\n",
      "2552/2552 - 1s - loss: 1.9776 - accuracy: 0.2453 - val_loss: 1.9791 - val_accuracy: 0.2401\n",
      "\n",
      "Epoch 4/5\n",
      "2552/2552 - 1s - loss: 1.9828 - accuracy: 0.2394 - val_loss: 1.9140 - val_accuracy: 0.2536\n",
      "\n",
      "Epoch 5/5\n",
      "2552/2552 - 1s - loss: 1.9150 - accuracy: 0.2727 - val_loss: 1.8779 - val_accuracy: 0.2878\n",
      "\n",
      "  32/1258 [..............................]\n",
      " - ETA: 0s - loss: 1.6219 - accuracy: 0.5000\n",
      "                                                                                                                      \n",
      " 512/1258 [===========>..................]\n",
      " - ETA: 0s - loss: 1.8340 - accuracy: 0.3125\n",
      "                                                                                                                      \n",
      " 704/1258 [===============>..............]\n",
      " - ETA: 0s - loss: 1.8710 - accuracy: 0.2997\n",
      "                                                                                                                      \n",
      "1184/1258 [===========================>..]\n",
      " - ETA: 0s - loss: 1.8766 - accuracy: 0.2897\n",
      "                                                                                                                      \n",
      "1258/1258 [==============================]\n",
      " - 0s 149us/sample - loss: 1.8779 - accuracy: 0.2878\n",
      "\n",
      "Test accuracy:\n",
      "0.28775835\n",
      "Train on 2552 samples, validate on 1258 samples\n",
      "Epoch 1/5\n",
      "2552/2552 - 2s - loss: 2.5181 - accuracy: 0.0443 - val_loss: 2.4950 - val_accuracy: 0.0056\n",
      "\n",
      "Epoch 2/5\n",
      "2552/2552 - 2s - loss: 2.5173 - accuracy: 0.0396 - val_loss: 2.4498 - val_accuracy: 0.0056\n",
      "\n",
      "Epoch 3/5\n",
      "2552/2552 - 2s - loss: 2.5118 - accuracy: 0.0435 - val_loss: 2.4203 - val_accuracy: 0.0056\n",
      "\n",
      "Epoch 4/5\n",
      "2552/2552 - 2s - loss: 2.4850 - accuracy: 0.0478 - val_loss: 2.4034 - val_accuracy: 0.0056\n",
      "\n",
      "Epoch 5/5\n",
      "2552/2552 - 2s - loss: 2.4922 - accuracy: 0.0435 - val_loss: 2.3902 - val_accuracy: 0.0056\n",
      "\n",
      "  32/1258 [..............................]\n",
      " - ETA: 0s - loss: 2.4088 - accuracy: 0.0000e+00\n",
      "                                                                                                                      \n",
      " 320/1258 [======>.......................]\n",
      " - ETA: 0s - loss: 2.4060 - accuracy: 0.0063    \n",
      "                                                                                                                      \n",
      " 544/1258 [===========>..................]\n",
      " - ETA: 0s - loss: 2.3898 - accuracy: 0.0074\n",
      "                                                                                                                      \n",
      " 736/1258 [================>.............]\n",
      " - ETA: 0s - loss: 2.3848 - accuracy: 0.0068\n",
      "                                                                                                                      \n",
      "1056/1258 [========================>.....]\n",
      " - ETA: 0s - loss: 2.3951 - accuracy: 0.0057\n",
      "                                                                                                                      \n",
      "1258/1258 [==============================]\n",
      " - 0s 207us/sample - loss: 2.3902 - accuracy: 0.0056\n",
      "\n",
      "Test accuracy:\n",
      "0.005564388\n",
      "Train on 2552 samples, validate on 1258 samples\n",
      "Epoch 1/5\n",
      "2552/2552 - 1s - loss: 2.2523 - accuracy: 0.1403 - val_loss: 2.2249 - val_accuracy: 0.1391\n",
      "\n",
      "Epoch 2/5\n",
      "2552/2552 - 0s - loss: 2.1487 - accuracy: 0.1998 - val_loss: 2.0034 - val_accuracy: 0.2798\n",
      "\n",
      "Epoch 3/5\n",
      "2552/2552 - 0s - loss: 2.0999 - accuracy: 0.2139 - val_loss: 1.9539 - val_accuracy: 0.2615\n",
      "\n",
      "Epoch 4/5\n",
      "2552/2552 - 0s - loss: 2.0471 - accuracy: 0.2316 - val_loss: 1.9121 - val_accuracy: 0.2862\n",
      "\n",
      "Epoch 5/5\n",
      "2552/2552 - 0s - loss: 2.0218 - accuracy: 0.2524 - val_loss: 1.9083 - val_accuracy: 0.2774\n",
      "\n",
      "  32/1258 [..............................]\n",
      " - ETA: 0s - loss: 1.8393 - accuracy: 0.3750\n",
      "                                                                                                                      \n",
      " 768/1258 [=================>............]\n",
      " - ETA: 0s - loss: 1.9168 - accuracy: 0.2773\n",
      "                                                                                                                      \n",
      "1216/1258 [===========================>..]\n",
      " - ETA: 0s - loss: 1.9084 - accuracy: 0.2780\n",
      "                                                                                                                      \n",
      "1258/1258 [==============================]\n",
      " - 0s 105us/sample - loss: 1.9083 - accuracy: 0.2774\n",
      "\n",
      "Test accuracy:\n",
      "0.27742448\n",
      "Train on 2552 samples, validate on 1258 samples\n",
      "Epoch 1/5\n",
      "2552/2552 - 1s - loss: 1.9107 - accuracy: 0.2978 - val_loss: 1.7839 - val_accuracy: 0.3593\n",
      "\n",
      "Epoch 2/5\n",
      "2552/2552 - 0s - loss: 1.7785 - accuracy: 0.3523 - val_loss: 1.7258 - val_accuracy: 0.3633\n",
      "\n",
      "Epoch 3/5\n",
      "2552/2552 - 0s - loss: 1.7416 - accuracy: 0.3766 - val_loss: 1.6963 - val_accuracy: 0.3824\n",
      "\n",
      "Epoch 4/5\n",
      "2552/2552 - 0s - loss: 1.6762 - accuracy: 0.3993 - val_loss: 1.5657 - val_accuracy: 0.4420\n",
      "\n",
      "Epoch 5/5\n",
      "2552/2552 - 0s - loss: 1.6448 - accuracy: 0.4028 - val_loss: 1.5694 - val_accuracy: 0.4634\n",
      "\n",
      "  32/1258 [..............................]\n",
      " - ETA: 0s - loss: 1.5561 - accuracy: 0.4375\n",
      "                                                                                                                      \n",
      " 768/1258 [=================>............]\n",
      " - ETA: 0s - loss: 1.5754 - accuracy: 0.4531\n",
      "                                                                                                                      \n",
      "1258/1258 [==============================]\n",
      " - 0s 83us/sample - loss: 1.5694 - accuracy: 0.4634\n",
      "\n",
      "Test accuracy:\n",
      "0.463434\n",
      "100%|███████████████████████████████████████████████████| 4/4 [00:28<00:00,  6.95s/it, best loss: -0.46343401074409485]\n",
      "Evalutation of best performing model:\n",
      "1258/1258 [==============================] - 0s 57us/sample - loss: 1.5694 - accuracy: 0.4634\n",
      "[1.5693781444112902, 0.463434]\n",
      "Best performing model chosen hyper-parameters:\n",
      "{'Dense': 500, 'Dense_1': 100, 'Dense_2': 20, 'Dense_3': 50, 'Dropout': 0.1532124532686945, 'Dropout_1': 0.17944072462772032, 'activation': 'tanh', 'activation_1': 'relu', 'activation_2': 'elu', 'activation_3': 'true', 'activation_4': 'tanh', 'activation_5': 'true', 'activation_6': 'elu', 'activation_7': 'softmax', 'batch_size': 20, 'optimizer': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "%run -i carhyperas.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('model.h5')\n",
    "best_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2552 samples, validate on 1258 samples\n",
      "Epoch 1/100\n",
      "2552/2552 [==============================] - 0s 116us/sample - loss: 1.9432 - accuracy: 0.2308 - val_loss: 1.9279 - val_accuracy: 0.2393\n",
      "Epoch 2/100\n",
      "2552/2552 [==============================] - 0s 111us/sample - loss: 1.9295 - accuracy: 0.2241 - val_loss: 1.9278 - val_accuracy: 0.2409\n",
      "Epoch 3/100\n",
      "2552/2552 [==============================] - 0s 135us/sample - loss: 1.9268 - accuracy: 0.2328 - val_loss: 1.9327 - val_accuracy: 0.2345\n",
      "Epoch 4/100\n",
      "2552/2552 [==============================] - 0s 121us/sample - loss: 1.9336 - accuracy: 0.2300 - val_loss: 1.9261 - val_accuracy: 0.2480\n",
      "Epoch 5/100\n",
      "2552/2552 [==============================] - 0s 118us/sample - loss: 1.9291 - accuracy: 0.2339 - val_loss: 1.9273 - val_accuracy: 0.2432\n",
      "Epoch 6/100\n",
      "2552/2552 [==============================] - 0s 113us/sample - loss: 1.9256 - accuracy: 0.2390 - val_loss: 1.9192 - val_accuracy: 0.2504\n",
      "Epoch 7/100\n",
      "2552/2552 [==============================] - 0s 111us/sample - loss: 1.9202 - accuracy: 0.2465 - val_loss: 1.9169 - val_accuracy: 0.2512\n",
      "Epoch 8/100\n",
      "2552/2552 [==============================] - 0s 116us/sample - loss: 1.9088 - accuracy: 0.2535 - val_loss: 1.9036 - val_accuracy: 0.2607\n",
      "Epoch 9/100\n",
      "2552/2552 [==============================] - 0s 114us/sample - loss: 1.9083 - accuracy: 0.2633 - val_loss: 1.9141 - val_accuracy: 0.2560\n",
      "Epoch 10/100\n",
      "2552/2552 [==============================] - 0s 113us/sample - loss: 1.8871 - accuracy: 0.2821 - val_loss: 1.9252 - val_accuracy: 0.3315\n",
      "Epoch 11/100\n",
      "2552/2552 [==============================] - 0s 114us/sample - loss: 1.8514 - accuracy: 0.3311 - val_loss: 1.8391 - val_accuracy: 0.3339\n",
      "Epoch 12/100\n",
      "2552/2552 [==============================] - 0s 113us/sample - loss: 1.8444 - accuracy: 0.3201 - val_loss: 1.8335 - val_accuracy: 0.3323\n",
      "Epoch 13/100\n",
      "2552/2552 [==============================] - 0s 113us/sample - loss: 1.8442 - accuracy: 0.3147 - val_loss: 1.8901 - val_accuracy: 0.2798\n",
      "Epoch 14/100\n",
      "2552/2552 [==============================] - 0s 113us/sample - loss: 1.8447 - accuracy: 0.3072 - val_loss: 1.8376 - val_accuracy: 0.3132\n",
      "Epoch 15/100\n",
      "2552/2552 [==============================] - 0s 114us/sample - loss: 1.8311 - accuracy: 0.3084 - val_loss: 1.8570 - val_accuracy: 0.2973\n",
      "Epoch 16/100\n",
      "2552/2552 [==============================] - 0s 132us/sample - loss: 1.8271 - accuracy: 0.3331 - val_loss: 1.8377 - val_accuracy: 0.3323\n",
      "Epoch 17/100\n",
      "2552/2552 [==============================] - 0s 121us/sample - loss: 1.8420 - accuracy: 0.3299 - val_loss: 1.8451 - val_accuracy: 0.3243\n",
      "Epoch 18/100\n",
      "2552/2552 [==============================] - 0s 125us/sample - loss: 1.8331 - accuracy: 0.3295 - val_loss: 1.8208 - val_accuracy: 0.3386\n",
      "Epoch 19/100\n",
      "2552/2552 [==============================] - 0s 116us/sample - loss: 1.8118 - accuracy: 0.3350 - val_loss: 1.8434 - val_accuracy: 0.3243\n",
      "Epoch 20/100\n",
      "2552/2552 [==============================] - 0s 119us/sample - loss: 1.8079 - accuracy: 0.3366 - val_loss: 1.8219 - val_accuracy: 0.3355\n",
      "Epoch 21/100\n",
      "2552/2552 [==============================] - 0s 122us/sample - loss: 1.8316 - accuracy: 0.3150 - val_loss: 1.8026 - val_accuracy: 0.3402\n",
      "Epoch 22/100\n",
      "2552/2552 [==============================] - 0s 132us/sample - loss: 1.8008 - accuracy: 0.3401 - val_loss: 1.7923 - val_accuracy: 0.3450\n",
      "Epoch 23/100\n",
      "2552/2552 [==============================] - 0s 132us/sample - loss: 1.7885 - accuracy: 0.3527 - val_loss: 1.7869 - val_accuracy: 0.3426\n",
      "Epoch 24/100\n",
      "2552/2552 [==============================] - 0s 116us/sample - loss: 1.7847 - accuracy: 0.3464 - val_loss: 1.7807 - val_accuracy: 0.3458\n",
      "Epoch 25/100\n",
      "2552/2552 [==============================] - 0s 114us/sample - loss: 1.7936 - accuracy: 0.3409 - val_loss: 1.7876 - val_accuracy: 0.3458\n",
      "Epoch 26/100\n",
      "2552/2552 [==============================] - 0s 113us/sample - loss: 1.7851 - accuracy: 0.3487 - val_loss: 1.7925 - val_accuracy: 0.3402\n",
      "Epoch 27/100\n",
      "2552/2552 [==============================] - 0s 124us/sample - loss: 1.7832 - accuracy: 0.3437 - val_loss: 1.7809 - val_accuracy: 0.3418\n",
      "Epoch 28/100\n",
      "2552/2552 [==============================] - 0s 119us/sample - loss: 1.7852 - accuracy: 0.3370 - val_loss: 1.7797 - val_accuracy: 0.3418\n",
      "Epoch 29/100\n",
      "2552/2552 [==============================] - 0s 130us/sample - loss: 1.7772 - accuracy: 0.3397 - val_loss: 1.7914 - val_accuracy: 0.3370\n",
      "Epoch 30/100\n",
      "2552/2552 [==============================] - 0s 122us/sample - loss: 1.7859 - accuracy: 0.3374 - val_loss: 1.7584 - val_accuracy: 0.3426\n",
      "Epoch 31/100\n",
      "2552/2552 [==============================] - 0s 118us/sample - loss: 1.7774 - accuracy: 0.3386 - val_loss: 1.7974 - val_accuracy: 0.3188\n",
      "Epoch 32/100\n",
      "2552/2552 [==============================] - 0s 114us/sample - loss: 1.7805 - accuracy: 0.3378 - val_loss: 1.7760 - val_accuracy: 0.3466\n",
      "Epoch 33/100\n",
      "2552/2552 [==============================] - 0s 119us/sample - loss: 1.8041 - accuracy: 0.3229 - val_loss: 1.8183 - val_accuracy: 0.3021\n",
      "Epoch 34/100\n",
      "2552/2552 [==============================] - 0s 113us/sample - loss: 1.7839 - accuracy: 0.3280 - val_loss: 1.7709 - val_accuracy: 0.3275\n",
      "Epoch 35/100\n",
      "2552/2552 [==============================] - 0s 114us/sample - loss: 1.7654 - accuracy: 0.3425 - val_loss: 1.7542 - val_accuracy: 0.3434\n",
      "Epoch 36/100\n",
      "2552/2552 [==============================] - 0s 118us/sample - loss: 1.7736 - accuracy: 0.3413 - val_loss: 1.7476 - val_accuracy: 0.3402\n",
      "Epoch 37/100\n",
      "2552/2552 [==============================] - 0s 122us/sample - loss: 1.7909 - accuracy: 0.3339 - val_loss: 1.7909 - val_accuracy: 0.3275\n",
      "Epoch 38/100\n",
      "2552/2552 [==============================] - 0s 133us/sample - loss: 1.7718 - accuracy: 0.3389 - val_loss: 1.7637 - val_accuracy: 0.3386\n",
      "Epoch 39/100\n",
      "2552/2552 [==============================] - 0s 121us/sample - loss: 1.7716 - accuracy: 0.3362 - val_loss: 1.7646 - val_accuracy: 0.3355\n",
      "Epoch 40/100\n",
      "2552/2552 [==============================] - 0s 118us/sample - loss: 1.7679 - accuracy: 0.3386 - val_loss: 1.7918 - val_accuracy: 0.3196\n",
      "Epoch 41/100\n",
      "2552/2552 [==============================] - 0s 113us/sample - loss: 1.7923 - accuracy: 0.3280 - val_loss: 1.8020 - val_accuracy: 0.3148\n",
      "Epoch 42/100\n",
      "2552/2552 [==============================] - 0s 113us/sample - loss: 1.7927 - accuracy: 0.3162 - val_loss: 1.7586 - val_accuracy: 0.3362\n",
      "Epoch 43/100\n",
      "2552/2552 [==============================] - 0s 119us/sample - loss: 1.7617 - accuracy: 0.3413 - val_loss: 1.7710 - val_accuracy: 0.3418\n",
      "Epoch 44/100\n",
      "2552/2552 [==============================] - 0s 116us/sample - loss: 1.7539 - accuracy: 0.3437 - val_loss: 1.7641 - val_accuracy: 0.3426\n",
      "Epoch 45/100\n",
      "2552/2552 [==============================] - 0s 114us/sample - loss: 1.7597 - accuracy: 0.3440 - val_loss: 1.7578 - val_accuracy: 0.3466\n",
      "Epoch 46/100\n",
      "2552/2552 [==============================] - 0s 116us/sample - loss: 1.7551 - accuracy: 0.3452 - val_loss: 1.7556 - val_accuracy: 0.3402\n",
      "Epoch 47/100\n",
      "2552/2552 [==============================] - 0s 133us/sample - loss: 1.7659 - accuracy: 0.3460 - val_loss: 1.7542 - val_accuracy: 0.3458\n",
      "Epoch 48/100\n",
      "2552/2552 [==============================] - 0s 119us/sample - loss: 1.7599 - accuracy: 0.3495 - val_loss: 1.7556 - val_accuracy: 0.3450\n",
      "Epoch 49/100\n",
      "2552/2552 [==============================] - 0s 119us/sample - loss: 1.7539 - accuracy: 0.3405 - val_loss: 1.7447 - val_accuracy: 0.3434\n",
      "Epoch 50/100\n",
      "2552/2552 [==============================] - 0s 121us/sample - loss: 1.7519 - accuracy: 0.3448 - val_loss: 1.7783 - val_accuracy: 0.3283\n",
      "Epoch 51/100\n",
      "2552/2552 [==============================] - 0s 111us/sample - loss: 1.7753 - accuracy: 0.3440 - val_loss: 1.7741 - val_accuracy: 0.3442\n",
      "Epoch 52/100\n",
      "2552/2552 [==============================] - 0s 111us/sample - loss: 1.7702 - accuracy: 0.3472 - val_loss: 1.7891 - val_accuracy: 0.3426\n",
      "Epoch 53/100\n",
      "2552/2552 [==============================] - 0s 114us/sample - loss: 1.7889 - accuracy: 0.3425 - val_loss: 1.7575 - val_accuracy: 0.3466\n",
      "Epoch 54/100\n",
      "2552/2552 [==============================] - 0s 110us/sample - loss: 1.7693 - accuracy: 0.3480 - val_loss: 1.7586 - val_accuracy: 0.3466\n",
      "Epoch 55/100\n",
      "2552/2552 [==============================] - 0s 113us/sample - loss: 1.7697 - accuracy: 0.3472 - val_loss: 1.7556 - val_accuracy: 0.3458\n",
      "Epoch 56/100\n",
      "2552/2552 [==============================] - 0s 132us/sample - loss: 1.7645 - accuracy: 0.3534 - val_loss: 1.7737 - val_accuracy: 0.3394\n",
      "Epoch 57/100\n",
      "2552/2552 [==============================] - 0s 118us/sample - loss: 1.7653 - accuracy: 0.3456 - val_loss: 1.7605 - val_accuracy: 0.3426\n",
      "Epoch 58/100\n",
      "2552/2552 [==============================] - 0s 118us/sample - loss: 1.7532 - accuracy: 0.3476 - val_loss: 1.7568 - val_accuracy: 0.3426\n",
      "Epoch 59/100\n",
      "2552/2552 [==============================] - 0s 108us/sample - loss: 1.7496 - accuracy: 0.3487 - val_loss: 1.7650 - val_accuracy: 0.3426\n",
      "Epoch 60/100\n",
      "2552/2552 [==============================] - 0s 114us/sample - loss: 1.7555 - accuracy: 0.3433 - val_loss: 1.7699 - val_accuracy: 0.3370\n",
      "Epoch 61/100\n",
      "2552/2552 [==============================] - 0s 111us/sample - loss: 1.7491 - accuracy: 0.3437 - val_loss: 1.7506 - val_accuracy: 0.3426\n",
      "Epoch 62/100\n",
      "2552/2552 [==============================] - 0s 111us/sample - loss: 1.7493 - accuracy: 0.3437 - val_loss: 1.7511 - val_accuracy: 0.3458\n",
      "Epoch 63/100\n",
      "2552/2552 [==============================] - 0s 116us/sample - loss: 1.7515 - accuracy: 0.3480 - val_loss: 1.7700 - val_accuracy: 0.3410\n",
      "Epoch 64/100\n",
      "2552/2552 [==============================] - 0s 113us/sample - loss: 1.7568 - accuracy: 0.3484 - val_loss: 1.7689 - val_accuracy: 0.3339\n",
      "Epoch 65/100\n",
      "2552/2552 [==============================] - 0s 114us/sample - loss: 1.7862 - accuracy: 0.3354 - val_loss: 1.8180 - val_accuracy: 0.3164\n",
      "Epoch 66/100\n",
      "2552/2552 [==============================] - 0s 111us/sample - loss: 1.7937 - accuracy: 0.3437 - val_loss: 1.7895 - val_accuracy: 0.3331\n",
      "Epoch 67/100\n",
      "2552/2552 [==============================] - 0s 110us/sample - loss: 1.7603 - accuracy: 0.3499 - val_loss: 1.7670 - val_accuracy: 0.3370\n",
      "Epoch 68/100\n",
      "2552/2552 [==============================] - 0s 111us/sample - loss: 1.7601 - accuracy: 0.3440 - val_loss: 1.7594 - val_accuracy: 0.3347\n",
      "Epoch 69/100\n",
      "2552/2552 [==============================] - 0s 111us/sample - loss: 1.7573 - accuracy: 0.3491 - val_loss: 1.7645 - val_accuracy: 0.3394\n",
      "Epoch 70/100\n",
      "2552/2552 [==============================] - 0s 130us/sample - loss: 1.7541 - accuracy: 0.3480 - val_loss: 1.7635 - val_accuracy: 0.3426\n",
      "Epoch 71/100\n",
      "2552/2552 [==============================] - 0s 132us/sample - loss: 1.7605 - accuracy: 0.3484 - val_loss: 1.7829 - val_accuracy: 0.3235\n",
      "Epoch 72/100\n",
      "2552/2552 [==============================] - 0s 125us/sample - loss: 1.7780 - accuracy: 0.3354 - val_loss: 1.7652 - val_accuracy: 0.3434\n",
      "Epoch 73/100\n",
      "2552/2552 [==============================] - 0s 113us/sample - loss: 1.7563 - accuracy: 0.3444 - val_loss: 1.7687 - val_accuracy: 0.3370\n",
      "Epoch 74/100\n",
      "2552/2552 [==============================] - 0s 114us/sample - loss: 1.7597 - accuracy: 0.3491 - val_loss: 1.7818 - val_accuracy: 0.3458\n",
      "Epoch 75/100\n",
      "2552/2552 [==============================] - 0s 110us/sample - loss: 1.7554 - accuracy: 0.3444 - val_loss: 1.7741 - val_accuracy: 0.3323\n",
      "Epoch 76/100\n",
      "2552/2552 [==============================] - 0s 110us/sample - loss: 1.7663 - accuracy: 0.3452 - val_loss: 1.8073 - val_accuracy: 0.3323\n",
      "Epoch 77/100\n",
      "2552/2552 [==============================] - 0s 111us/sample - loss: 1.8015 - accuracy: 0.3335 - val_loss: 1.7904 - val_accuracy: 0.3362\n",
      "Epoch 78/100\n",
      "2552/2552 [==============================] - 0s 107us/sample - loss: 1.7739 - accuracy: 0.3413 - val_loss: 1.7690 - val_accuracy: 0.3386\n",
      "Epoch 79/100\n",
      "2552/2552 [==============================] - 0s 110us/sample - loss: 1.7568 - accuracy: 0.3444 - val_loss: 1.7596 - val_accuracy: 0.3418\n",
      "Epoch 80/100\n",
      "2552/2552 [==============================] - 0s 122us/sample - loss: 1.7565 - accuracy: 0.3448 - val_loss: 1.7733 - val_accuracy: 0.3410\n",
      "Epoch 81/100\n",
      "2552/2552 [==============================] - 0s 136us/sample - loss: 1.7609 - accuracy: 0.3460 - val_loss: 1.7693 - val_accuracy: 0.3331\n",
      "Epoch 82/100\n",
      "2552/2552 [==============================] - 0s 141us/sample - loss: 1.7581 - accuracy: 0.3440 - val_loss: 1.7789 - val_accuracy: 0.3283\n",
      "Epoch 83/100\n",
      "2552/2552 [==============================] - 0s 130us/sample - loss: 1.7577 - accuracy: 0.3433 - val_loss: 1.7648 - val_accuracy: 0.3370\n",
      "Epoch 84/100\n",
      "2552/2552 [==============================] - 0s 124us/sample - loss: 1.7561 - accuracy: 0.3511 - val_loss: 1.7608 - val_accuracy: 0.3466\n",
      "Epoch 85/100\n",
      "2552/2552 [==============================] - 0s 136us/sample - loss: 1.7724 - accuracy: 0.3503 - val_loss: 1.7918 - val_accuracy: 0.3370\n",
      "Epoch 86/100\n",
      "2552/2552 [==============================] - 0s 125us/sample - loss: 1.7792 - accuracy: 0.3499 - val_loss: 1.7582 - val_accuracy: 0.3259\n",
      "Epoch 87/100\n",
      "2552/2552 [==============================] - 0s 138us/sample - loss: 1.7689 - accuracy: 0.3409 - val_loss: 1.7595 - val_accuracy: 0.3458\n",
      "Epoch 88/100\n",
      "2552/2552 [==============================] - 0s 133us/sample - loss: 1.7610 - accuracy: 0.3464 - val_loss: 1.7637 - val_accuracy: 0.3386\n",
      "Epoch 89/100\n",
      "2552/2552 [==============================] - 0s 133us/sample - loss: 1.7503 - accuracy: 0.3389 - val_loss: 1.7652 - val_accuracy: 0.3355\n",
      "Epoch 90/100\n",
      "2552/2552 [==============================] - 0s 141us/sample - loss: 1.7648 - accuracy: 0.3448 - val_loss: 1.7604 - val_accuracy: 0.3458\n",
      "Epoch 91/100\n",
      "2552/2552 [==============================] - 0s 154us/sample - loss: 1.7536 - accuracy: 0.3468 - val_loss: 1.7585 - val_accuracy: 0.3434\n",
      "Epoch 92/100\n",
      "2552/2552 [==============================] - 0s 136us/sample - loss: 1.7478 - accuracy: 0.3452 - val_loss: 1.7544 - val_accuracy: 0.3402\n",
      "Epoch 93/100\n",
      "2552/2552 [==============================] - 0s 138us/sample - loss: 1.7549 - accuracy: 0.3456 - val_loss: 1.7683 - val_accuracy: 0.3450\n",
      "Epoch 94/100\n",
      "2552/2552 [==============================] - 0s 133us/sample - loss: 1.7587 - accuracy: 0.3444 - val_loss: 1.7664 - val_accuracy: 0.3378\n",
      "Epoch 95/100\n",
      "2552/2552 [==============================] - 0s 130us/sample - loss: 1.7654 - accuracy: 0.3444 - val_loss: 1.7719 - val_accuracy: 0.3299\n",
      "Epoch 96/100\n",
      "2552/2552 [==============================] - 0s 122us/sample - loss: 1.7515 - accuracy: 0.3460 - val_loss: 1.7632 - val_accuracy: 0.3426\n",
      "Epoch 97/100\n",
      "2552/2552 [==============================] - 0s 133us/sample - loss: 1.7521 - accuracy: 0.3476 - val_loss: 1.7556 - val_accuracy: 0.3402\n",
      "Epoch 98/100\n",
      "2552/2552 [==============================] - 0s 122us/sample - loss: 1.7492 - accuracy: 0.3499 - val_loss: 1.7558 - val_accuracy: 0.3418\n",
      "Epoch 99/100\n",
      "2552/2552 [==============================] - 0s 129us/sample - loss: 1.7484 - accuracy: 0.3444 - val_loss: 1.7802 - val_accuracy: 0.3394\n",
      "Epoch 100/100\n",
      "2552/2552 [==============================] - 0s 121us/sample - loss: 1.7675 - accuracy: 0.3460 - val_loss: 1.7769 - val_accuracy: 0.3347\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cd92372ef0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,Y,batch_size=50, epochs=100, verbose=1, shuffle=True, validation_data=(XV,YV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1258/1258 [==============================] - 0s 60us/sample - loss: 1.7769 - accuracy: 0.3347\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.7768893507213017, 0.33465818]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(XV,YV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "X = np.array(XXX)\n",
    "Y = to_categorical(XXY)\n",
    "testnew = test.drop(columns=['row_id', 'series_id', 'measurement_number'])\n",
    "Z = np.array(testnew.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3810/3810 [==============================] - 147s 39ms/sample - loss: 1.9133 - accuracy: 0.2793\n",
      "Epoch 2/10\n",
      "3810/3810 [==============================] - 150s 39ms/sample - loss: 1.9271 - accuracy: 0.2819\n",
      "Epoch 3/10\n",
      "3810/3810 [==============================] - 153s 40ms/sample - loss: 1.9153 - accuracy: 0.2740\n",
      "Epoch 4/10\n",
      "3810/3810 [==============================] - 150s 39ms/sample - loss: 1.9116 - accuracy: 0.2858\n",
      "Epoch 5/10\n",
      "3810/3810 [==============================] - 151s 40ms/sample - loss: 1.9006 - accuracy: 0.2895\n",
      "Epoch 6/10\n",
      "3810/3810 [==============================] - 151s 40ms/sample - loss: 1.9095 - accuracy: 0.2738\n",
      "Epoch 7/10\n",
      "3810/3810 [==============================] - 150s 39ms/sample - loss: 1.9114 - accuracy: 0.2934\n",
      "Epoch 8/10\n",
      "1428/3810 [==========>...................] - ETA: 1:33 - loss: 1.9166 - accuracy: 0.2745"
     ]
    }
   ],
   "source": [
    "model.fit(X,Y,batch_size=2, epochs=10, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "pred=model.predict_classes(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488443</th>\n",
       "      <td>3815</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488444</th>\n",
       "      <td>3815</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488445</th>\n",
       "      <td>3815</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488446</th>\n",
       "      <td>3815</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488447</th>\n",
       "      <td>3815</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>488448 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0  1\n",
       "0          0  5\n",
       "1          0  5\n",
       "2          0  5\n",
       "3          0  5\n",
       "4          0  5\n",
       "...      ... ..\n",
       "488443  3815  8\n",
       "488444  3815  8\n",
       "488445  3815  8\n",
       "488446  3815  8\n",
       "488447  3815  8\n",
       "\n",
       "[488448 rows x 2 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preddf = pd.DataFrame({'surface':pred})\n",
    "preddf=pd.concat([test[['series_id']].reset_index(drop=True), preddf], ignore_index=True, axis=1)\n",
    "preddf_agg = preddf.groupby([0], as_index=False).agg(lambda x:x.value_counts().index[0]).my_flatten_cols()\n",
    "preddf_agg.columns = ['series_id', 'surface']\n",
    "preddf_agg['surface'] = enc.inverse_transform(preddf_agg['surface'])\n",
    "preddf_agg.to_csv('sub.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
