{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Prediction Notebook\n",
    "\n",
    "- predict suggestions for 2019 set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# initialization\n",
    "\n",
    "%reset -f\n",
    "\n",
    "import sys, pandas as pd, numpy as np, inspect, re as re, functools as functools, pickle, glob, warnings, os\n",
    "\n",
    "# sklearn packages\n",
    "import sklearn.metrics as skm\n",
    "\n",
    "# some options/variables\n",
    "randomseed = 1 # the value for the random state used at various points in the pipeline\n",
    "pd.options.display.max_rows = 50 # specify if you want the full output in cells rather the truncated list\n",
    "pd.options.display.max_columns = 200\n",
    "\n",
    "# to display multiple outputs in a cell without usin print/display\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# append the scripts path to pythonpath\n",
    "sys.path.append('./scripts/')\n",
    "\n",
    "# ignore warnings (only if you are the kind that would code when the world is burning)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# import the various ml modules\n",
    "import xgboost as xgb\n",
    "\n",
    "############################################## import the custom modules ################################\n",
    "import helperfuncs as helper\n",
    "import feateng as fte\n",
    "from misc import ce_encodings, DataFrameImputer, scalers\n",
    "\n",
    "# instantiate the classes\n",
    "helpers = helper.helper_funcs()\n",
    "cust_funcs = fte.custom_funcs()\n",
    "\n",
    "#############################################################################################################\n",
    "# global function to flatten columns after a grouped operation and aggregation\n",
    "# outside all classes since it is added as an attribute to pandas DataFrames\n",
    "def __my_flatten_cols(self, how=\"_\".join, reset_index=True):\n",
    "    how = (lambda iter: list(iter)[-1]) if how == \"last\" else how\n",
    "    self.columns = [how(filter(None, map(str, levels))) for levels in self.columns.values] \\\n",
    "    if isinstance(self.columns, pd.MultiIndex) else self.columns\n",
    "    return self.reset_index(drop=True) if reset_index else self\n",
    "pd.DataFrame.my_flatten_cols = __my_flatten_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%run -i ./scripts/dicts_cols.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from azure.datalake.store import core, lib, multithread\n",
    "\n",
    "tenant = 'cef04b19-7776-4a94-b89b-375c77a8f936'\n",
    "resource = 'https://datalake.azure.net/'\n",
    "client_id = 'e9aaf06a-9856-42a8-ab3c-c8b0d3a9b110'\n",
    "client_secret = 'DlbuV60szYT2U0CQNjzwRA55EsH42oX92AB7vbD2clk='\n",
    "\n",
    "adlcreds = lib.auth(tenant_id = tenant,\n",
    "                   client_secret = client_secret,\n",
    "                   client_id = client_id,\n",
    "                   resource = resource)\n",
    "\n",
    "subs_id = '73f88e6b-3a35-4612-b550-555157e7059f'\n",
    "adls = 'edhadlsanasagbdev'\n",
    "\n",
    "adlsfsc = core.AzureDLFileSystem(adlcreds, store_name=adls)\n",
    "\n",
    "path = '/root/anasandbox/people/opr10x/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "with adlsfsc.open(path + '/2019/Data/Output_Data/ads/final_ads.pickle', 'rb') as f:\n",
    "    ads = pickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "# Final PROCESSING\n",
    "preddf = ads[ads['year']==2019].copy()\n",
    "preddf.dropna(subset=['global_id'], inplace=True, how='any')\n",
    "preddf.reset_index(drop=True, inplace=True)\n",
    "preddf.drop(columns=['opr'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4184, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4080, 37)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the scope ids\n",
    "\n",
    "with adlsfsc.open(path + '/2019/Data/Output_Data/peer_group/peer_group_30april.csv', 'rb') as f:\n",
    "    scope = helpers.csv_read(f, cols_to_keep=['global_id', 'emp_hiring_date'])\n",
    "    f.close()\n",
    "    \n",
    "scope['scopeflag'] = 1\n",
    "preddf['predflag'] = 0\n",
    "pred_scope = preddf.merge(scope, on=['global_id'], how='outer')\n",
    "pred_scope = pred_scope[pred_scope['scopeflag']==1].copy()\n",
    "pred_scope['emp_hiring_date'] = pd.to_datetime(pred_scope['emp_hiring_date'], format='%Y-%m-%d')\n",
    "pred_scope['hire_flag'] = np.where(pred_scope['emp_hiring_date']>pd.to_datetime('2019-01-01', format='%Y-%d-%m'),1,0)\n",
    "pred_scope = pred_scope[pred_scope['hire_flag']==0]\n",
    "scope_ids = pred_scope.global_id\n",
    "preddf = preddf[preddf['global_id'].isin(scope_ids)]\n",
    "preddf.drop(columns=['predflag'], inplace=True)\n",
    "preddf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## DISTRIBUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# DSITRIBUTION SNIPPET\n",
    "\n",
    "## zonal distribution df\n",
    "### use below snippet to use for distribution when doing zone level distribution\n",
    "# distribution_df = ads[['zone', 'year', 'opr', 'global_id']].copy()\n",
    "# distribution_df = distribution_df[distribution_df['year'].isin([2018])]\n",
    "# distribution_df = distribution_df[distribution_df['opr']>0]\n",
    "# distribution_df['opr'] = distribution_df['opr']-1\n",
    "# distribution_df = distribution_df.groupby(['zone', 'year', 'opr'])['global_id'].count().reset_index()\n",
    "# distribution_df = distribution_df.groupby(['zone', 'opr'])['global_id'].mean().reset_index()\n",
    "\n",
    "# global distribution df\n",
    "global_distribution_df = ads[['year', 'opr', 'global_id']].copy()\n",
    "global_distribution_df = global_distribution_df[global_distribution_df['year'].isin([2018])]\n",
    "global_distribution_df = global_distribution_df.groupby(['year', 'opr'])['global_id'].count().reset_index()\n",
    "global_distribution_df = global_distribution_df[global_distribution_df['opr']>0]\n",
    "global_distribution_df['opr'] = global_distribution_df['opr']-1\n",
    "global_distribution_df = global_distribution_df.groupby(['opr'])['global_id'].mean().reset_index()\n",
    "global_distribution_df.columns = ['oprclass', 'distr']\n",
    "global_distribution_df['distr'] = global_distribution_df['distr']/global_distribution_df['distr'].sum()\n",
    "global_distribution_df.sort_values(by='oprclass', inplace=True, ascending=False)\n",
    "global_distribution_df['cumdistr'] = global_distribution_df['distr'].cumsum()\n",
    "global_distribution_df['cumdistr'] = global_distribution_df['cumdistr'].round(4)\n",
    "global_distribution_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# USE BELOW SNIPPETS FOR PREDICTION USING THE ORDINAL APPROACH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%run -i ./scripts/ordinal_classifier_without_valid.py\n",
    "\n",
    "with adlsfsc.open(path + '/2019/Data/Output_Data/ml_prediction_objects/ordinal_classifier_objects.pickle', 'rb') as f:\n",
    "    xgb_ordinal = pickle.load(f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%run -i ./scripts/opr_prediction_ordinal.py\n",
    "\n",
    "probs, preds, clfs_predict_class1 = predict_opr_ordinal(preddf.copy(), xgb_ordinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "clfs_predict_df = pd.DataFrame.from_dict(clfs_predict_class1)\n",
    "clfs_predict_df['global_id'] = np.array(preddf.global_id)\n",
    "probs_df = pd.DataFrame(data=probs, columns=['1A', '3B', '3A', '4B', '4A'])\n",
    "\n",
    "for i in range(4):\n",
    "    clfs_predict_df.sort_values(by=[3-i], inplace=True, ascending=False, kind='mergesort')\n",
    "    clfs_predict_df.reset_index(inplace=True, drop=True)\n",
    "    clfs_predict_df[str(3-i) + '_new_index'] = clfs_predict_df.index\n",
    "    clfs_predict_df[str(3-i) + '_index_perc'] = clfs_predict_df[str(3-i) + '_new_index'].rank(pct=True)\n",
    "    clfs_predict_df[str(3-i) + '_flag'] = np.where(clfs_predict_df[str(3-i) + '_index_perc'] < \n",
    "                                                 global_distribution_df.iloc[i, 2], 1, 0)\n",
    "    \n",
    "clfs_predict_df['predictions'] = np.where(clfs_predict_df['3_flag']==1, 4,\n",
    "                                   np.where(clfs_predict_df['2_flag']==1, 3,\n",
    "                                           np.where(clfs_predict_df['1_flag']==1, 2,\n",
    "                                                   np.where(clfs_predict_df['0_flag']==1, 1, 0))))\n",
    "\n",
    "shape_predictions_df = clfs_predict_df[['global_id', 'predictions']].copy()\n",
    "shape_predictions_df = pd.concat([shape_predictions_df.reset_index(drop=True),\n",
    "                                 probs_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296037"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the pickle and flatfile of the ML predictions from ordinal approach\n",
    "with adlsfsc.open(path + '/2019/Data/Output_Data/ml_output/2019_predictions_probs_ordinal.pickle', 'wb') as f:\n",
    "    pickle.dump(shape_predictions_df, f)\n",
    "    f.close()\n",
    "    \n",
    "with adlsfsc.open(path + '/2019/Data/Output_Data/ml_output/2019_predictions_probs_ordinal.csv', 'wb') as f:\n",
    "    pred_str = shape_predictions_df.to_csv()\n",
    "    f.write(str.encode(pred_str))\n",
    "    f.close()\n",
    "    \n",
    "# with adlsfsc.open(path + '/2019/Data/Output_Data/ml_output/2019_predictions_probs_ordinal.pickle', 'rb') as f:\n",
    "#     shape_predictions_df = pickle.load(f)\n",
    "#     f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%run -i ./scripts/rules_shape_rules.py\n",
    "\n",
    "df = apply_rules(dset=preddf.copy(), predictions=shape_predictions_df.copy(), prev_prev_opr_col='prev_prev_opr', prev_opr_col='prev_opr',\n",
    "                pred_col='predictions', tib_col='emp_time_in_band1', mei_col='engagement_score',\n",
    "                ta_col='net_target', mean_ca_col='mr_pers_compgroup_year_comp_score_mean_leadership_competencies')\n",
    "\n",
    "final_prediction_df = df.copy()\n",
    "final_prediction_df = final_prediction_df.merge(shape_predictions_df[['global_id', 'predictions']].copy(), \n",
    "                                                on='global_id', how='left')\n",
    "final_prediction_df['predictions'] = final_prediction_df['predictions'].map(rev_dep_dict_without1B)\n",
    "final_prediction_df['predictions'] = np.where(final_prediction_df['rules_prediction'],\n",
    "                                             final_prediction_df['predictions'],\n",
    "                                             final_prediction_df['rules_prediction'])\n",
    "final_prediction_df = final_prediction_df[['global_id', 'zone', 'predictions']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "ml_rank_df = clfs_predict_df[['global_id', 'predictions', '3_new_index', '2_new_index', '1_new_index', '0_new_index']].copy()\n",
    "ml_rank_df['rank'] = np.where(ml_rank_df['predictions']==4, 10000+ml_rank_df['3_new_index'],\n",
    "                             np.where(ml_rank_df['predictions']==3, 20000+ml_rank_df['2_new_index'],\n",
    "                                     np.where(ml_rank_df['predictions']==2, 30000+ml_rank_df['1_new_index'], \n",
    "                                              40000+ml_rank_df['0_new_index'])))\n",
    "ml_rank_df.sort_values(by=['rank'], ascending=True, inplace=True)\n",
    "ml_rank_df.reset_index(drop=True, inplace=True)\n",
    "ml_rank_df['rank'] = ml_rank_df.index\n",
    "ml_rank_df['predictions_ML'] = ml_rank_df['predictions'].map(rev_dep_dict_without1B)\n",
    "ml_rank_df.drop(columns=['predictions'], inplace=True)\n",
    "final_prediction_df.rename(columns={'predictions':'predictions_SHAPE_RULES'}, inplace=True)\n",
    "ml_rank_df = ml_rank_df.merge(final_prediction_df, on=['global_id'], how='left')\n",
    "ml_rank_df = ml_rank_df[['global_id', 'zone', 'rank', 'predictions_ML', 'predictions_SHAPE_RULES']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165189"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with adlsfsc.open(path + '/2019/Data/Output_Data/ml_output/2019_rank.csv', 'wb') as f:\n",
    "    mlrank_str = ml_rank_df.to_csv()\n",
    "    f.write(str.encode(mlrank_str))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# USE BELOW SNIPPETS FOR PREDICTION USING THE MULTICLASS APPROACH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# %run -i ./scripts/opr_prediction_multiclass.py\n",
    "\n",
    "# # create the prediction dictionary to append and take mean of all the probabilities\n",
    "# probs={}\n",
    "\n",
    "# for i in model.keys():\n",
    "#     probs[i], pred_ids = predict_opr_multiclass(preddf.copy(), model[i], encoderobj[i], scalerobj[i], featnames[i])\n",
    "# probsfull = pd.concat(probs.values()).groupby(level=0).mean()\n",
    "\n",
    "# # convert the probabilities to labels (classes)\n",
    "# pred_labels = pd.DataFrame(np.argmax(np.array(probsfull), 1))\n",
    "# pred_labels.columns = ['predictions']\n",
    "# pred_labels['global_id'] = pred_ids\n",
    "# predictions_df = pd.concat([probsfull, pred_labels], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# # save the pickle and flatfile of the ML predictions from multiclass approach\n",
    "# with adlsfsc.open(path + '/2019/Data/Output_Data/ml_output/2019_predictions_probs.pickle', 'wb') as f:\n",
    "#     pickle.dump(predictions_df, f)\n",
    "#     f.close()\n",
    "    \n",
    "# with adlsfsc.open(path + '/2019/Data/Output_Data/ml_output/2019_predictions_probs.csv', 'wb') as f:\n",
    "#     pred_str = predictions_df.to_csv()\n",
    "#     f.write(str.encode(pred_str))\n",
    "#     f.close()\n",
    "    \n",
    "# # with adlsfsc.open(path + '/2019/Data/Output_Data/ml_output/2019_predictions_probs.pickle', 'rb') as f:\n",
    "# #     predictions_df = pickle.load(f)\n",
    "# #     f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## RULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# %run -i ./scripts/rules_shape_rules.py\n",
    "\n",
    "# df = apply_rules(dset=preddf.copy(), predictions=predictions_df.copy(), prev_prev_opr_col='prev_prev_opr', prev_opr_col='prev_opr',\n",
    "#                 pred_col='predictions', tib_col='emp_time_in_band1', mei_col='engagement_score',\n",
    "#                 ta_col='net_target', mean_ca_col='mr_pers_compgroup_year_comp_score_mean_leadership_competencies')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## WEIGHTED SHAPE LOGIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# pred_withzone = predictions_df.merge(preddf[['global_id', 'zone']], how='left', on=['global_id'])\n",
    "# pred_withzone['score'] = (pred_withzone['1A']*120567.4303 + \n",
    "#                           pred_withzone['3B']*120570.5456 + \n",
    "#                           pred_withzone['3A']*120572.7815 +\n",
    "#                           pred_withzone['4B']*120575.186 + \n",
    "#                           pred_withzone['4A']*120578.4064)\n",
    "\n",
    "# # use the distribution to apply shape\n",
    "# pred_withzone.sort_values(by=['score'], ascending=False, inplace=True)\n",
    "# pred_withzone.reset_index(drop=True, inplace=True)\n",
    "# pred_withzone['newindex'] = pred_withzone.index\n",
    "# pred_withzone['rank'] = pred_withzone['newindex'].rank(pct=True)\n",
    "# pred_withzone['flag'] = np.where(pred_withzone['rank'] < global_distribution_df.iloc[0,2], 4,\n",
    "#                         np.where(pred_withzone['rank'] < global_distribution_df.iloc[1,2], 3,\n",
    "#                                 np.where(pred_withzone['rank'] < global_distribution_df.iloc[2,2], 2,\n",
    "#                                         np.where(pred_withzone['rank'] < global_distribution_df.iloc[3,2], 1, 0))))\n",
    "\n",
    "# # merge the output from rules and the shape modules giving precedence to rules\n",
    "# df = df.merge(pred_withzone[['global_id', 'flag']], on=['global_id'], how='left')\n",
    "# df['rules_prediction'] = df['rules_prediction'].map(dep_dict_without1B)\n",
    "# df['predictions'] = np.where(df['rules_prediction'].isna, df['flag'], df['rules_prediction'])\n",
    "# df['predictions'] = df['predictions'].astype(int)\n",
    "# df.drop(columns=['rules_prediction', 'flag'], inplace=True)\n",
    "# df['predictions'] = df['predictions'].map(rev_dep_dict_without1B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## RULES again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# %run -i ./scripts/rules_shape_rules.py\n",
    "\n",
    "# df = apply_rules(dset=df.copy(), prev_prev_opr_col='prev_prev_opr', prev_opr_col='prev_opr',\n",
    "#                 pred_col='predictions', tib_col='emp_time_in_band1', mei_col='engagement_score',\n",
    "#                 ta_col='net_target', mean_ca_col='mr_pers_compgroup_year_comp_score_mean_leadership_competencies',\n",
    "#                 iteration='second')\n",
    "\n",
    "# final_prediction_df = df.copy()\n",
    "# final_prediction_df['predictions'] = np.where(final_prediction_df['rules_prediction'].isna,\n",
    "#                                              final_prediction_df['predictions'],\n",
    "#                                              final_prediction_df['rules_prediction'])\n",
    "# final_prediction_df = final_prediction_df[['global_id', 'zone', 'predictions']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# FIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "with adlsfsc.open(path + '/2019/Data/Output_Data/ml_output/final_predictions_df.csv', 'wb') as f:\n",
    "    fpdf_str = final_prediction_df.to_csv()\n",
    "    f.write(str.encode(fpdf_str))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
